{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 Hands-on Lab: Palawan Land Cover Classification with Random Forest\n",
    "# INSTRUCTOR VERSION\n",
    "\n",
    "**Duration:** 90 minutes (1.5 hours)\n",
    "\n",
    "**Instructor:** CopPhil Advanced Training\n",
    "\n",
    "---\n",
    "\n",
    "## 📚 Instructor Notes\n",
    "\n",
    "### Session Structure (90 minutes)\n",
    "\n",
    "- **A-B: Setup & Study Area** (15 min) - Ensure all participants authenticate successfully\n",
    "- **C: Data Acquisition** (20 min) - Emphasize cloud masking importance\n",
    "- **D: Spectral Indices** (15 min) - Connect to physical properties\n",
    "- **E: Feature Stack** (10 min) - Quick transition\n",
    "- **F: Training Data** (20 min) - CRITICAL - stress data quality\n",
    "- **G: RF Training** (20 min) - Explain hyperparameters clearly\n",
    "- **H: Classification** (15 min) - Visual interpretation exercise\n",
    "- **I: Accuracy Assessment** (25 min) - Deep dive into confusion matrix\n",
    "- **J: Area Statistics** (10 min) - Connect to policy/management\n",
    "- **K: Export** (10 min) - Quick demo\n",
    "- **L: Advanced Exercises** (as time permits)\n",
    "\n",
    "### Key Teaching Points\n",
    "\n",
    "1. **Data quality > Model complexity**: Emphasize throughout\n",
    "2. **Explainability matters**: Feature importance, visual inspection\n",
    "3. **Context is critical**: Connect to Philippine NRM challenges\n",
    "4. **Reproducibility**: Stress the importance of random seeds, documentation\n",
    "\n",
    "### Common Participant Questions\n",
    "\n",
    "**Q: Why Random Forest instead of deep learning?**\n",
    "A: RF is interpretable, requires less training data, computationally efficient, and performs excellently for this problem. Deep learning benefits emerge with larger datasets and more complex features.\n",
    "\n",
    "**Q: How much training data is enough?**\n",
    "A: Rule of thumb: 50-100 pixels per class minimum. More for heterogeneous classes. Quality > quantity.\n",
    "\n",
    "**Q: Why is accuracy assessment necessary if classification looks good?**\n",
    "A: Visual inspection is subjective and biased. Quantitative metrics provide objective, reproducible performance measures required for scientific rigor and operational deployment.\n",
    "\n",
    "**Q: Can we use this for change detection?**\n",
    "A: Yes! Classify two time periods and compare. But be careful about seasonal effects, sensor calibration, and atmospheric conditions.\n",
    "\n",
    "### Potential Issues\n",
    "\n",
    "1. **Authentication problems**: Have backup authentication instructions ready\n",
    "2. **Slow computation**: Remind participants GEE is server-side (their laptop speed doesn't matter)\n",
    "3. **Memory errors**: Pre-prepared solutions with tileScale adjustments\n",
    "4. **No images found**: Have backup date ranges ready\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this hands-on lab, participants will be able to:\n",
    "\n",
    "1. **Set up and authenticate** Google Earth Engine (GEE) in Google Colab\n",
    "2. **Acquire and preprocess** Sentinel-2 satellite imagery for a Philippine study area\n",
    "3. **Calculate spectral indices** (NDVI, NDWI, NDBI, EVI) for land cover discrimination\n",
    "4. **Create training datasets** by defining land cover classes and sampling spectral signatures\n",
    "5. **Train a Random Forest classifier** using GEE's machine learning capabilities\n",
    "6. **Perform land cover classification** on Sentinel-2 imagery\n",
    "7. **Assess accuracy** using confusion matrices and statistical metrics\n",
    "8. **Generate area statistics** for each land cover class\n",
    "9. **Export results** for further analysis and visualization\n",
    "10. **Apply classification** to real-world Natural Resource Management (NRM) challenges in the Philippines\n",
    "\n",
    "---\n",
    "\n",
    "## Study Area: Palawan Province\n",
    "\n",
    "**Why Palawan?**\n",
    "\n",
    "- **UNESCO Biosphere Reserve**: Home to exceptional biodiversity and endemic species\n",
    "- **Conservation Priority**: Contains the Puerto Princesa Subterranean River National Park (UNESCO World Heritage Site)\n",
    "- **Environmental Challenges**: Deforestation, mining, agricultural expansion, tourism impacts\n",
    "- **NRM Relevance**: Critical for monitoring forest cover, mangroves, agricultural land conversion\n",
    "- **Policy Context**: Palawan Strategic Environmental Plan (SEP) requires regular land cover monitoring\n",
    "\n",
    "Palawan represents a critical case study where accurate land cover classification directly supports conservation planning and sustainable development decisions.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook Overview\n",
    "\n",
    "This notebook guides participants through a complete supervised classification workflow using Random Forest:\n",
    "\n",
    "```\n",
    "Data Acquisition → Preprocessing → Feature Engineering → Training Data → Model Training → Classification → Validation → Export\n",
    "```\n",
    "\n",
    "**Key Concepts Covered:**\n",
    "- Cloud computing for Earth Observation (Google Earth Engine)\n",
    "- Spectral signatures and feature extraction\n",
    "- Supervised machine learning (Random Forest)\n",
    "- Model explainability (feature importance)\n",
    "- Accuracy assessment and validation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Setup and Authentication (10 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Walk through authentication process step-by-step\n",
    "- Have participants raise hands when successfully authenticated\n",
    "- Common issue: Browser blocking popups - suggest allowing them\n",
    "- Backup: Pre-authenticated notebook if time is constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages (run only once)\n",
    "!pip install earthengine-api geemap pandas numpy matplotlib seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")\n",
    "print(f\"Earth Engine API version: {ee.__version__}\")\n",
    "print(f\"Geemap version: {geemap.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and initialize Earth Engine\n",
    "try:\n",
    "    ee.Initialize()\n",
    "    print(\"✓ Earth Engine initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(\"First-time authentication required...\")\n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "    print(\"✓ Earth Engine authenticated and initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test connection with a simple query\n",
    "test_image = ee.Image('COPERNICUS/S2_SR/20240115T015701_20240115T020226_T51PUS')\n",
    "image_info = test_image.getInfo()\n",
    "\n",
    "print(\"✓ Connection successful!\")\n",
    "print(f\"Test Image ID: {image_info['id']}\")\n",
    "print(f\"Available bands: {len(image_info['bands'])} bands\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive map centered on Palawan\n",
    "# Palawan center coordinates: approximately 10.5°N, 118.8°E\n",
    "Map = geemap.Map(center=[10.5, 118.8], zoom=8, height='600px')\n",
    "\n",
    "# Add basemap options\n",
    "Map.add_basemap('SATELLITE')\n",
    "\n",
    "print(\"✓ Interactive map created\")\n",
    "print(\"Use the map controls to pan, zoom, and explore Palawan\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B. Study Area Definition (5 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Explain FAO GAUL dataset (global administrative boundaries)\n",
    "- Note: Palawan may appear subdivided in recent data (Palawan province was split)\n",
    "- Backup: Manual polygon if GAUL filter doesn't work\n",
    "- Point out that study area definition significantly impacts computational cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Palawan boundary using FAO GAUL dataset\n",
    "philippines = ee.FeatureCollection('FAO/GAUL/2015/level1')\n",
    "\n",
    "# Filter for Palawan province\n",
    "palawan = philippines.filter(ee.Filter.eq('ADM1_NAME', 'Palawan'))\n",
    "\n",
    "# Fallback: Manual boundary if needed\n",
    "# palawan_coords = [\n",
    "#     [117.5, 9.5], [117.5, 12.0], [119.5, 12.0], [119.5, 9.5], [117.5, 9.5]\n",
    "# ]\n",
    "# palawan = ee.Geometry.Polygon(palawan_coords)\n",
    "\n",
    "print(\"✓ Palawan boundary defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the boundary on the map\n",
    "Map.addLayer(palawan, {'color': 'red'}, 'Palawan Boundary')\n",
    "Map.centerObject(palawan, 8)\n",
    "\n",
    "# Display basic information\n",
    "area_km2 = palawan.geometry().area().divide(1e6).getInfo()\n",
    "bounds = palawan.geometry().bounds().getInfo()\n",
    "\n",
    "print(f\"Study Area: Palawan Province\")\n",
    "print(f\"Approximate Area: {area_km2:,.0f} km²\")\n",
    "print(f\"Bounding Box: {bounds['coordinates']}\")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C. Sentinel-2 Data Acquisition (20 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Emphasize S2_SR (Level-2A) vs S2 (Level-1C) difference\n",
    "- Discuss cloud cover threshold trade-off (lower = fewer images, higher = more cloud artifacts)\n",
    "- Explain bitwise operations in cloud masking (many participants find this confusing)\n",
    "- Show why median is preferred over mean for tropical regions\n",
    "- Demo: Toggle between masked/unmasked to show cloud removal effectiveness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define date range for imagery\n",
    "start_date = '2024-01-01'\n",
    "end_date = '2024-12-31'\n",
    "\n",
    "print(f\"Date range: {start_date} to {end_date}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Sentinel-2 Surface Reflectance collection\n",
    "s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "                 .filterBounds(palawan)\n",
    "                 .filterDate(start_date, end_date)\n",
    "                 .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20)))\n",
    "\n",
    "collection_size = s2_collection.size().getInfo()\n",
    "print(f\"✓ Sentinel-2 collection loaded\")\n",
    "print(f\"Number of images: {collection_size}\")\n",
    "\n",
    "if collection_size == 0:\n",
    "    print(\"⚠️ Warning: No images found. Trying relaxed filter...\")\n",
    "    # Fallback with relaxed filter\n",
    "    s2_collection = (ee.ImageCollection('COPERNICUS/S2_SR')\n",
    "                     .filterBounds(palawan)\n",
    "                     .filterDate(start_date, end_date)\n",
    "                     .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)))\n",
    "    collection_size = s2_collection.size().getInfo()\n",
    "    print(f\"Relaxed filter: {collection_size} images found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cloud masking function\n",
    "def mask_s2_clouds(image):\n",
    "    \"\"\"\n",
    "    Masks clouds and cirrus from Sentinel-2 imagery using the QA60 band.\n",
    "    \"\"\"\n",
    "    qa = image.select('QA60')\n",
    "    \n",
    "    # Bits 10 and 11 are clouds and cirrus\n",
    "    cloud_bit_mask = 1 << 10  # Binary: 10000000000 (bit 10)\n",
    "    cirrus_bit_mask = 1 << 11  # Binary: 100000000000 (bit 11)\n",
    "    \n",
    "    # Both flags should be zero (clear conditions)\n",
    "    mask = (qa.bitwiseAnd(cloud_bit_mask).eq(0)\n",
    "            .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0)))\n",
    "    \n",
    "    # Return masked image, scaled to reflectance [0, 1]\n",
    "    return image.updateMask(mask).divide(10000)\n",
    "\n",
    "print(\"✓ Cloud masking function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cloud masking to the collection\n",
    "s2_masked = s2_collection.map(mask_s2_clouds)\n",
    "\n",
    "print(\"✓ Cloud masking applied to collection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create median composite\n",
    "s2_composite = s2_masked.median().clip(palawan)\n",
    "\n",
    "# Select bands for analysis\n",
    "bands = ['B2', 'B3', 'B4', 'B8', 'B11', 'B12']\n",
    "s2_composite = s2_composite.select(bands)\n",
    "\n",
    "print(\"✓ Median composite created\")\n",
    "print(f\"Selected bands: {bands}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize RGB composite\n",
    "rgb_vis = {\n",
    "    'bands': ['B4', 'B3', 'B2'],\n",
    "    'min': 0.0,\n",
    "    'max': 0.3,\n",
    "    'gamma': 1.4\n",
    "}\n",
    "\n",
    "Map.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB (True Color)')\n",
    "\n",
    "print(\"✓ RGB composite added to map\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize false color composite (NIR-Red-Green)\n",
    "false_color_vis = {\n",
    "    'bands': ['B8', 'B4', 'B3'],\n",
    "    'min': 0.0,\n",
    "    'max': 0.4,\n",
    "    'gamma': 1.2\n",
    "}\n",
    "\n",
    "Map.addLayer(s2_composite, false_color_vis, 'Sentinel-2 False Color (NIR-R-G)')\n",
    "\n",
    "print(\"✓ False color composite added to map\")\n",
    "print(\"Red areas = healthy vegetation\")\n",
    "print(\"Green/brown areas = bare soil, urban\")\n",
    "print(\"Dark blue/black areas = water\")\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Discussion Point: Composite Types\n",
    "\n",
    "**Instructor Demo**: Show mean vs median composites side-by-side\n",
    "\n",
    "**Expected observations:**\n",
    "- Median: Sharper, fewer artifacts, better for classification\n",
    "- Mean: Smoother, may retain cloud shadows\n",
    "- Percentile: Useful for specific applications (e.g., 10th percentile for dark features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR SOLUTION: Exercise 1 - Different composites\n",
    "\n",
    "# Mean composite\n",
    "s2_mean = s2_masked.mean().clip(palawan).select(bands)\n",
    "\n",
    "# 25th percentile\n",
    "s2_p25 = s2_masked.reduce(ee.Reducer.percentile([25])).clip(palawan)\n",
    "\n",
    "# Visualize comparison\n",
    "Map_composites = geemap.Map(center=[10.5, 118.8], zoom=9, height='600px')\n",
    "Map_composites.addLayer(s2_composite, rgb_vis, 'Median (Best for classification)')\n",
    "Map_composites.addLayer(s2_mean, rgb_vis, 'Mean', False)\n",
    "Map_composites.addLayer(s2_p25, {'bands': ['B4_p25', 'B3_p25', 'B2_p25'], 'min': 0, 'max': 0.3}, '25th Percentile', False)\n",
    "Map_composites.add_layer_control()\n",
    "\n",
    "print(\"✓ Composite comparison ready\")\n",
    "print(\"Toggle layers to compare different compositing methods\")\n",
    "\n",
    "# Map_composites  # Uncomment to display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D. Spectral Indices Calculation (15 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Use physical analogy: \"Spectral indices are like medical tests - each reveals specific information\"\n",
    "- Draw connection to plant physiology (chlorophyll absorption, leaf structure)\n",
    "- Show real examples on map: point out forested areas (high NDVI), water bodies (high NDWI), cities (high NDBI)\n",
    "- Emphasize normalized indices are scale-invariant (work across sensors, dates)\n",
    "- Common question: \"Why normalize?\" Answer: Reduces illumination effects, makes values comparable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDVI\n",
    "ndvi = s2_composite.normalizedDifference(['B8', 'B4']).rename('NDVI')\n",
    "\n",
    "ndvi_vis = {\n",
    "    'min': -0.2,\n",
    "    'max': 0.8,\n",
    "    'palette': ['blue', 'white', 'green', 'darkgreen']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndvi, ndvi_vis, 'NDVI')\n",
    "print(\"✓ NDVI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDWI\n",
    "ndwi = s2_composite.normalizedDifference(['B3', 'B8']).rename('NDWI')\n",
    "\n",
    "ndwi_vis = {\n",
    "    'min': -0.5,\n",
    "    'max': 0.5,\n",
    "    'palette': ['brown', 'white', 'lightblue', 'darkblue']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndwi, ndwi_vis, 'NDWI')\n",
    "print(\"✓ NDWI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate NDBI\n",
    "ndbi = s2_composite.normalizedDifference(['B11', 'B8']).rename('NDBI')\n",
    "\n",
    "ndbi_vis = {\n",
    "    'min': -0.3,\n",
    "    'max': 0.3,\n",
    "    'palette': ['green', 'white', 'red', 'darkred']\n",
    "}\n",
    "\n",
    "Map.addLayer(ndbi, ndbi_vis, 'NDBI')\n",
    "print(\"✓ NDBI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate EVI\n",
    "evi = s2_composite.expression(\n",
    "    '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n",
    "    {\n",
    "        'NIR': s2_composite.select('B8'),\n",
    "        'RED': s2_composite.select('B4'),\n",
    "        'BLUE': s2_composite.select('B2')\n",
    "    }\n",
    ").rename('EVI')\n",
    "\n",
    "evi_vis = {\n",
    "    'min': -0.2,\n",
    "    'max': 0.8,\n",
    "    'palette': ['blue', 'white', 'lightgreen', 'darkgreen']\n",
    "}\n",
    "\n",
    "Map.addLayer(evi, evi_vis, 'EVI')\n",
    "print(\"✓ EVI calculated and visualized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "Map_indices = geemap.Map(center=[10.5, 118.8], zoom=9, height='600px')\n",
    "\n",
    "Map_indices.addLayer(ndvi, ndvi_vis, 'NDVI')\n",
    "Map_indices.addLayer(ndwi, ndwi_vis, 'NDWI')\n",
    "Map_indices.addLayer(ndbi, ndbi_vis, 'NDBI')\n",
    "Map_indices.addLayer(evi, evi_vis, 'EVI')\n",
    "Map_indices.add_layer_control()\n",
    "\n",
    "print(\"✓ All spectral indices visualized\")\n",
    "Map_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Discussion: Index Interpretation\n",
    "\n",
    "**Ask participants:**\n",
    "1. \"Where do you see highest NDVI?\" → Expected: Mountain forests\n",
    "2. \"Where is NDWI most positive?\" → Expected: Rivers, bays, lakes\n",
    "3. \"Which index best separates forest from agriculture?\" → Expected: NDVI, EVI\n",
    "\n",
    "**Teaching point**: Spectral indices transform data into more discriminative feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR SOLUTION: Exercise 2 - Additional Indices\n",
    "\n",
    "# SAVI (Soil-Adjusted Vegetation Index)\n",
    "L = 0.5  # Soil brightness correction factor\n",
    "savi = s2_composite.expression(\n",
    "    '((NIR - RED) * (1 + L)) / (NIR + RED + L)',\n",
    "    {\n",
    "        'NIR': s2_composite.select('B8'),\n",
    "        'RED': s2_composite.select('B4'),\n",
    "        'L': L\n",
    "    }\n",
    ").rename('SAVI')\n",
    "\n",
    "# GNDVI (Green NDVI)\n",
    "gndvi = s2_composite.normalizedDifference(['B8', 'B3']).rename('GNDVI')\n",
    "\n",
    "print(\"✓ SAVI and GNDVI calculated\")\n",
    "print(\"SAVI is useful for sparse vegetation (reduces soil background effect)\")\n",
    "print(\"GNDVI is sensitive to chlorophyll concentration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E. Feature Stack Preparation (10 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Explain: \"Feature stack = multi-band image where each band is a feature\"\n",
    "- Analogy: \"Like a medical patient record with multiple test results\"\n",
    "- Discuss curse of dimensionality briefly (too many features can hurt performance)\n",
    "- Random Forest handles high dimensionality well compared to other algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive feature stack\n",
    "feature_stack = (s2_composite\n",
    "                 .addBands(ndvi)\n",
    "                 .addBands(ndwi)\n",
    "                 .addBands(ndbi)\n",
    "                 .addBands(evi))\n",
    "\n",
    "# List all feature names\n",
    "feature_names = feature_stack.bandNames().getInfo()\n",
    "\n",
    "print(\"✓ Feature stack created\")\n",
    "print(f\"Total features: {len(feature_names)}\")\n",
    "print(f\"Feature list: {feature_names}\")\n",
    "print(\"\\nFeature categories:\")\n",
    "print(f\"  - Spectral bands: 6 (B2, B3, B4, B8, B11, B12)\")\n",
    "print(f\"  - Spectral indices: 4 (NDVI, NDWI, NDBI, EVI)\")\n",
    "print(f\"  - Total: {len(feature_names)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify feature completeness\n",
    "sample_point = ee.Geometry.Point([118.8, 10.5])\n",
    "sample_values = feature_stack.reduceRegion(\n",
    "    reducer=ee.Reducer.first(),\n",
    "    geometry=sample_point,\n",
    "    scale=10\n",
    ").getInfo()\n",
    "\n",
    "print(\"Sample feature values at test point (Central Palawan):\")\n",
    "for feature, value in sample_values.items():\n",
    "    print(f\"  {feature}: {value:.4f}\" if value is not None else f\"  {feature}: NULL\")\n",
    "\n",
    "null_features = [f for f, v in sample_values.items() if v is None]\n",
    "if null_features:\n",
    "    print(f\"⚠️ Warning: Null values found in {null_features}\")\n",
    "else:\n",
    "    print(\"\\n✓ All features have valid values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F. Training Data Preparation (20 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- **CRITICAL SECTION** - Stress that training data quality determines success\n",
    "- Show examples of good vs bad training samples on map\n",
    "- Discuss common errors:\n",
    "  - Mixed pixels (polygon overlaps multiple classes)\n",
    "  - Seasonal mismatch (training data from different time than imagery)\n",
    "  - Class definition ambiguity (what counts as \"forest\" vs \"agriculture\"?)\n",
    "- Mention data-centric AI: Improving data > improving model\n",
    "- Interactive activity: Have participants suggest where to place training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class properties\n",
    "class_info = {\n",
    "    1: {'name': 'Forest', 'color': '006400'},\n",
    "    2: {'name': 'Agriculture', 'color': 'FFFF00'},\n",
    "    3: {'name': 'Water', 'color': '0000FF'},\n",
    "    4: {'name': 'Urban', 'color': 'FF0000'},\n",
    "    5: {'name': 'Bare Soil', 'color': '8B4513'}\n",
    "}\n",
    "\n",
    "print(\"Land Cover Classification Scheme:\")\n",
    "for class_id, info in class_info.items():\n",
    "    print(f\"  {class_id}: {info['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pre-defined training samples\n",
    "# These coordinates are carefully selected based on visual interpretation\n",
    "# In operational workflow, these would come from field surveys or expert digitization\n",
    "\n",
    "# Forest samples (mountainous interior, dense vegetation)\n",
    "forest_coords = [\n",
    "    [[118.5, 10.5], [118.5, 10.52], [118.52, 10.52], [118.52, 10.5]],\n",
    "    [[118.7, 10.8], [118.7, 10.82], [118.72, 10.82], [118.72, 10.8]],\n",
    "    [[119.0, 11.0], [119.0, 11.02], [119.02, 11.02], [119.02, 11.0]],\n",
    "    [[118.3, 9.8], [118.3, 9.82], [118.32, 9.82], [118.32, 9.8]],\n",
    "    [[118.85, 10.3], [118.85, 10.32], [118.87, 10.32], [118.87, 10.3]],\n",
    "]\n",
    "\n",
    "# Agriculture samples (coastal plains, river valleys)\n",
    "agriculture_coords = [\n",
    "    [[118.7, 9.75], [118.7, 9.77], [118.72, 9.77], [118.72, 9.75]],\n",
    "    [[118.9, 10.2], [118.9, 10.22], [118.92, 10.22], [118.92, 10.2]],\n",
    "    [[118.55, 10.0], [118.55, 10.02], [118.57, 10.02], [118.57, 10.0]],\n",
    "    [[119.15, 10.9], [119.15, 10.92], [119.17, 10.92], [119.17, 10.9]],\n",
    "]\n",
    "\n",
    "# Water samples (bays, rivers, lakes)\n",
    "water_coords = [\n",
    "    [[118.73, 9.73], [118.73, 9.75], [118.75, 9.75], [118.75, 9.73]],  # Puerto Princesa Bay\n",
    "    [[119.3, 10.5], [119.3, 10.52], [119.32, 10.52], [119.32, 10.5]],  # Coastal water\n",
    "    [[118.4, 10.3], [118.4, 10.32], [118.42, 10.32], [118.42, 10.3]],\n",
    "    [[118.95, 9.6], [118.95, 9.62], [118.97, 9.62], [118.97, 9.6]],\n",
    "]\n",
    "\n",
    "# Urban samples (Puerto Princesa, towns)\n",
    "urban_coords = [\n",
    "    [[118.74, 9.74], [118.74, 9.76], [118.76, 9.76], [118.76, 9.74]],  # Puerto Princesa City\n",
    "    [[119.08, 10.82], [119.08, 10.84], [119.10, 10.84], [119.10, 10.82]],  # Taytay\n",
    "    [[118.77, 9.77], [118.77, 9.79], [118.79, 9.79], [118.79, 9.77]],\n",
    "]\n",
    "\n",
    "# Bare soil samples (mining, cleared land)\n",
    "bare_coords = [\n",
    "    [[117.95, 9.4], [117.95, 9.42], [117.97, 9.42], [117.97, 9.4]],\n",
    "    [[118.2, 10.1], [118.2, 10.12], [118.22, 10.12], [118.22, 10.1]],\n",
    "    [[118.6, 10.6], [118.6, 10.62], [118.62, 10.62], [118.62, 10.6]],\n",
    "]\n",
    "\n",
    "# Convert to ee.FeatureCollection\n",
    "def create_training_features(coords_list, class_value):\n",
    "    \"\"\"Convert coordinate list to ee.FeatureCollection with class label.\"\"\"\n",
    "    features = []\n",
    "    for coords in coords_list:\n",
    "        polygon = ee.Geometry.Polygon(coords)\n",
    "        feature = ee.Feature(polygon, {'landcover': class_value})\n",
    "        features.append(feature)\n",
    "    return ee.FeatureCollection(features)\n",
    "\n",
    "forest_fc = create_training_features(forest_coords, 1)\n",
    "agriculture_fc = create_training_features(agriculture_coords, 2)\n",
    "water_fc = create_training_features(water_coords, 3)\n",
    "urban_fc = create_training_features(urban_coords, 4)\n",
    "bare_fc = create_training_features(bare_coords, 5)\n",
    "\n",
    "# Merge all training samples\n",
    "training_polygons = (forest_fc\n",
    "                     .merge(agriculture_fc)\n",
    "                     .merge(water_fc)\n",
    "                     .merge(urban_fc)\n",
    "                     .merge(bare_fc))\n",
    "\n",
    "print(\"✓ Training polygons created\")\n",
    "print(f\"Total training polygons: {training_polygons.size().getInfo()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize training polygons\n",
    "Map_training = geemap.Map(center=[10.5, 118.8], zoom=8, height='600px')\n",
    "\n",
    "Map_training.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB')\n",
    "\n",
    "for class_id, info in class_info.items():\n",
    "    class_polygons = training_polygons.filter(ee.Filter.eq('landcover', class_id))\n",
    "    Map_training.addLayer(\n",
    "        class_polygons,\n",
    "        {'color': info['color']},\n",
    "        f\"Training: {info['name']}\"\n",
    "    )\n",
    "\n",
    "print(\"✓ Training polygons visualized\")\n",
    "Map_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample training data from feature stack\n",
    "training_samples = feature_stack.sampleRegions(\n",
    "    collection=training_polygons,\n",
    "    properties=['landcover'],\n",
    "    scale=10,\n",
    "    geometries=False,\n",
    "    tileScale=4\n",
    ")\n",
    "\n",
    "sample_count = training_samples.size().getInfo()\n",
    "print(f\"✓ Training samples extracted\")\n",
    "print(f\"Total training pixels: {sample_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect sample distribution by class\n",
    "class_counts = {}\n",
    "for class_id in range(1, 6):\n",
    "    class_samples = training_samples.filter(ee.Filter.eq('landcover', class_id))\n",
    "    count = class_samples.size().getInfo()\n",
    "    class_counts[class_id] = count\n",
    "\n",
    "print(\"\\nSample distribution by class:\")\n",
    "for class_id, count in class_counts.items():\n",
    "    class_name = class_info[class_id]['name']\n",
    "    print(f\"  {class_name}: {count} pixels\")\n",
    "\n",
    "max_count = max(class_counts.values())\n",
    "min_count = min(class_counts.values())\n",
    "imbalance_ratio = max_count / min_count if min_count > 0 else float('inf')\n",
    "\n",
    "if imbalance_ratio > 3:\n",
    "    print(f\"\\n⚠️ Warning: Class imbalance detected (ratio: {imbalance_ratio:.1f}:1)\")\n",
    "    print(\"Consider adding more samples for underrepresented classes\")\n",
    "else:\n",
    "    print(f\"\\n✓ Class distribution is balanced (ratio: {imbalance_ratio:.1f}:1)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Discussion: Training Data Quality\n",
    "\n",
    "**Ask participants:**\n",
    "- \"Is this enough training data?\" → Context-dependent, but more is generally better\n",
    "- \"How would you collect training data in the field?\" → GPS surveys, local knowledge\n",
    "- \"What if classes are imbalanced?\" → Options: collect more samples, resampling, class weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore training data\n",
    "sample_limit = training_samples.limit(100)\n",
    "sample_list = sample_limit.getInfo()['features']\n",
    "\n",
    "sample_data = [feature['properties'] for feature in sample_list]\n",
    "df_samples = pd.DataFrame(sample_data)\n",
    "\n",
    "print(\"Sample training data (first 10 rows):\")\n",
    "print(df_samples.head(10))\n",
    "\n",
    "print(\"\\nFeature statistics by class:\")\n",
    "print(df_samples.groupby('landcover')[['NDVI', 'NDWI', 'B4', 'B8']].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## G. Random Forest Training (20 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Draw Random Forest diagram on whiteboard/slide: multiple trees → majority vote\n",
    "- Explain bagging (bootstrap aggregating): each tree sees random subset\n",
    "- Explain feature randomness: each split considers random subset of features\n",
    "- Discuss hyperparameters:\n",
    "  - **numberOfTrees**: More = better (diminishing returns after ~100-200)\n",
    "  - **variablesPerSplit**: Auto = sqrt(n) is theoretically optimal\n",
    "  - **minLeafPopulation**: Controls tree depth (overfitting prevention)\n",
    "- Mention: RF is embarrassingly parallel (scales well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Random Forest classifier\n",
    "rf_classifier = ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=None,  # Auto: sqrt(10) ≈ 3 features per split\n",
    "    minLeafPopulation=1,\n",
    "    bagFraction=0.632,  # Out-of-bag fraction\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(\"✓ Random Forest classifier configured\")\n",
    "print(\"Configuration:\")\n",
    "print(f\"  - Number of trees: 100\")\n",
    "print(f\"  - Variables per split: auto (~{int(np.sqrt(len(feature_names)))} features)\")\n",
    "print(f\"  - Min leaf population: 1\")\n",
    "print(f\"  - Random seed: 42 (for reproducibility)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the classifier\n",
    "print(\"Training Random Forest classifier...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "trained_classifier = rf_classifier.train(\n",
    "    features=training_samples,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "print(\"✓ Random Forest training complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance (if available)\n",
    "try:\n",
    "    importance = trained_classifier.explain().get('importance')\n",
    "    importance_dict = importance.getInfo()\n",
    "    \n",
    "    df_importance = pd.DataFrame({\n",
    "        'Feature': list(importance_dict.keys()),\n",
    "        'Importance': list(importance_dict.values())\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(df_importance['Feature'], df_importance['Importance'])\n",
    "    plt.xlabel('Importance', fontsize=12)\n",
    "    plt.ylabel('Feature', fontsize=12)\n",
    "    plt.title('Random Forest Feature Importance', fontsize=14, fontweight='bold')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nTop 5 most important features:\")\n",
    "    print(df_importance.head(5).to_string(index=False))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"⚠️ Feature importance not available from GEE smileRandomForest\")\n",
    "    print(\"\\n🎓 INSTRUCTOR NOTE: This is expected - GEE's SMILE implementation doesn't expose importance\")\n",
    "    print(\"\\nExpected important features (based on EO literature):\")\n",
    "    print(\"  1. NIR band (B8) - vegetation discrimination\")\n",
    "    print(\"  2. NDVI - vegetation index\")\n",
    "    print(\"  3. SWIR bands (B11, B12) - moisture, urban\")\n",
    "    print(\"  4. Red band (B4) - vegetation contrast\")\n",
    "    print(\"  5. NDWI - water detection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Discussion: Why Random Forest?\n",
    "\n",
    "**Ask participants:** \"What are advantages of Random Forest over a single decision tree?\"\n",
    "\n",
    "**Expected answers:**\n",
    "- More stable (less sensitive to training data)\n",
    "- Less prone to overfitting\n",
    "- Better generalization\n",
    "- Provides feature importance\n",
    "\n",
    "**Follow-up:** \"When might a single tree be better?\"\n",
    "- When interpretability is critical (single tree is easier to visualize)\n",
    "- When computational resources are very limited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR SOLUTION: Exercise 4 - Different tree counts\n",
    "\n",
    "# Train with 50 trees\n",
    "rf_50 = ee.Classifier.smileRandomForest(numberOfTrees=50, seed=42)\n",
    "trained_rf_50 = rf_50.train(\n",
    "    features=training_samples,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "# Train with 200 trees\n",
    "rf_200 = ee.Classifier.smileRandomForest(numberOfTrees=200, seed=42)\n",
    "trained_rf_200 = rf_200.train(\n",
    "    features=training_samples,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "print(\"✓ Trained RF with 50 trees\")\n",
    "print(\"✓ Trained RF with 200 trees\")\n",
    "print(\"\\n🎓 INSTRUCTOR NOTE: Performance difference is usually <5% beyond 100 trees\")\n",
    "print(\"Computational cost increases linearly with tree count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## H. Image Classification (15 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Explain: Classification applies trained model to every pixel\n",
    "- Show before/after: RGB → classified image\n",
    "- Interactive activity: Have participants zoom to different areas and assess visually\n",
    "- Point out common patterns:\n",
    "  - Forest in mountains\n",
    "  - Agriculture in plains\n",
    "  - Water clearly delineated\n",
    "  - Urban concentrated in Puerto Princesa\n",
    "- Discuss visual artifacts (isolated pixels, boundary effects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply classifier to feature stack\n",
    "print(\"Classifying image...\")\n",
    "print(\"This may take 1-2 minutes...\")\n",
    "\n",
    "classified_image = feature_stack.classify(trained_classifier)\n",
    "\n",
    "print(\"✓ Classification complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define color palette\n",
    "class_palette = [class_info[i]['color'] for i in sorted(class_info.keys())]\n",
    "print(f\"Classification palette: {class_palette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize classification result\n",
    "Map_classified = geemap.Map(center=[10.5, 118.8], zoom=8, height='700px')\n",
    "\n",
    "Map_classified.addLayer(s2_composite, rgb_vis, 'Sentinel-2 RGB', False)\n",
    "Map_classified.addLayer(s2_composite, false_color_vis, 'False Color', False)\n",
    "\n",
    "Map_classified.addLayer(\n",
    "    classified_image,\n",
    "    {'min': 1, 'max': 5, 'palette': class_palette},\n",
    "    'Land Cover Classification'\n",
    ")\n",
    "\n",
    "for class_id, info in class_info.items():\n",
    "    class_polygons = training_polygons.filter(ee.Filter.eq('landcover', class_id))\n",
    "    Map_classified.addLayer(\n",
    "        class_polygons,\n",
    "        {'color': info['color']},\n",
    "        f\"Training: {info['name']}\",\n",
    "        False\n",
    "    )\n",
    "\n",
    "Map_classified.add_layer_control()\n",
    "\n",
    "print(\"✓ Classification visualized\")\n",
    "print(\"\\nLegend:\")\n",
    "for class_id, info in class_info.items():\n",
    "    print(f\"  {info['name']}: #{info['color']}\")\n",
    "\n",
    "Map_classified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Interactive Activity: Visual Assessment\n",
    "\n",
    "**Instructor-led exploration (5-10 minutes):**\n",
    "\n",
    "1. **Puerto Princesa City** (9.74°N, 118.74°E)\n",
    "   - Toggle RGB and classification\n",
    "   - Is urban area correctly identified?\n",
    "   - Any confusion with bare soil?\n",
    "\n",
    "2. **Mount Mantalingahan** (9°N, 118.5°E) - highest peak\n",
    "   - Primary forest should dominate\n",
    "   - Check for misclassification at cloud shadows\n",
    "\n",
    "3. **Coastal mangroves** (10.3°N, 119.3°E)\n",
    "   - Should be classified as forest or water?\n",
    "   - Discuss spectral similarity to terrestrial forest\n",
    "\n",
    "4. **Agricultural plains** (10°N, 118.7°E)\n",
    "   - Rice paddies vs. bare soil confusion\n",
    "   - Seasonal effects (planting vs. harvest)\n",
    "\n",
    "**Ask participants to note 3 misclassifications for discussion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## I. Accuracy Assessment (25 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- **CRITICAL SECTION** - Participants often skip proper validation\n",
    "- Emphasize: Visual inspection ≠ accuracy assessment\n",
    "- Explain confusion matrix carefully:\n",
    "  - Draw on board: rows = reference, columns = predicted\n",
    "  - Diagonal = correct, off-diagonal = errors\n",
    "- Discuss metrics:\n",
    "  - Overall accuracy: Simple but can be misleading with imbalance\n",
    "  - Producer's accuracy: \"How complete is the map?\" (recall)\n",
    "  - User's accuracy: \"How reliable is the map?\" (precision)\n",
    "  - Kappa: Accounts for chance agreement\n",
    "- Common question: \"What accuracy is good enough?\" → Context-dependent, but >80% overall is typical target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-validation split\n",
    "training_samples = training_samples.randomColumn('random', seed=42)\n",
    "\n",
    "split = 0.8\n",
    "training_set = training_samples.filter(ee.Filter.lt('random', split))\n",
    "validation_set = training_samples.filter(ee.Filter.gte('random', split))\n",
    "\n",
    "train_count = training_set.size().getInfo()\n",
    "val_count = validation_set.size().getInfo()\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"  Training samples: {train_count} ({train_count/(train_count+val_count)*100:.1f}%)\")\n",
    "print(f\"  Validation samples: {val_count} ({val_count/(train_count+val_count)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrain on training set only\n",
    "print(\"Retraining classifier on training set...\")\n",
    "\n",
    "rf_final = ee.Classifier.smileRandomForest(\n",
    "    numberOfTrees=100,\n",
    "    variablesPerSplit=None,\n",
    "    minLeafPopulation=1,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trained_final = rf_final.train(\n",
    "    features=training_set,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "print(\"✓ Retraining complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify validation set\n",
    "validation_classified = validation_set.classify(trained_final)\n",
    "print(\"✓ Validation set classified\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "confusion_matrix = validation_classified.errorMatrix('landcover', 'classification')\n",
    "matrix_array = confusion_matrix.array().getInfo()\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(\"Rows = Reference (True), Columns = Predicted\")\n",
    "print(matrix_array)\n",
    "print(\"\\n🎓 INSTRUCTOR NOTE: Walk through matrix interpretation with participants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix as heatmap\n",
    "class_names = [class_info[i]['name'] for i in sorted(class_info.keys())]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    matrix_array,\n",
    "    annot=True,\n",
    "    fmt='g',\n",
    "    cmap='Blues',\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    cbar_kws={'label': 'Count'}\n",
    ")\n",
    "plt.xlabel('Predicted Class', fontsize=12)\n",
    "plt.ylabel('Reference Class', fontsize=12)\n",
    "plt.title('Confusion Matrix - Palawan Land Cover Classification', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎓 INSTRUCTOR PROMPT: Ask participants to identify:\")\n",
    "print(\"1. Which classes have highest accuracy? (look at diagonal)\")\n",
    "print(\"2. Which classes are most confused? (look at off-diagonal)\")\n",
    "print(\"3. Are there systematic errors? (e.g., consistent confusion between two classes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy metrics\n",
    "overall_accuracy = confusion_matrix.accuracy().getInfo()\n",
    "print(f\"Overall Accuracy: {overall_accuracy*100:.2f}%\")\n",
    "\n",
    "kappa = confusion_matrix.kappa().getInfo()\n",
    "print(f\"Kappa Coefficient: {kappa:.4f}\")\n",
    "\n",
    "if kappa > 0.8:\n",
    "    kappa_interp = \"Excellent agreement\"\n",
    "elif kappa > 0.6:\n",
    "    kappa_interp = \"Substantial agreement\"\n",
    "elif kappa > 0.4:\n",
    "    kappa_interp = \"Moderate agreement\"\n",
    "else:\n",
    "    kappa_interp = \"Poor agreement\"\n",
    "\n",
    "print(f\"Interpretation: {kappa_interp}\")\n",
    "\n",
    "print(\"\\n🎓 INSTRUCTOR NOTE:\")\n",
    "if overall_accuracy > 0.85:\n",
    "    print(\"Excellent accuracy! Likely due to well-chosen training samples.\")\n",
    "elif overall_accuracy > 0.7:\n",
    "    print(\"Good accuracy. Typical for initial classification attempt.\")\n",
    "else:\n",
    "    print(\"Low accuracy. Discuss potential causes:\")\n",
    "    print(\"  - Insufficient training samples\")\n",
    "    print(\"  - Poor quality training data\")\n",
    "    print(\"  - Class confusion (need to refine definitions)\")\n",
    "    print(\"  - Need more discriminative features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-class accuracy\n",
    "producers_accuracy = confusion_matrix.producersAccuracy().getInfo()\n",
    "users_accuracy = confusion_matrix.consumersAccuracy().getInfo()\n",
    "\n",
    "print(\"\\nProducer's Accuracy (Recall):\")\n",
    "for i, acc in enumerate(producers_accuracy):\n",
    "    class_name = class_info[i+1]['name']\n",
    "    print(f\"  {class_name}: {acc*100:.2f}%\")\n",
    "\n",
    "print(\"\\nUser's Accuracy (Precision):\")\n",
    "for i, acc in enumerate(users_accuracy):\n",
    "    class_name = class_info[i+1]['name']\n",
    "    print(f\"  {class_name}: {acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary DataFrame\n",
    "df_accuracy = pd.DataFrame({\n",
    "    'Class': class_names,\n",
    "    'Producer\\'s Accuracy (%)': [acc*100 for acc in producers_accuracy],\n",
    "    'User\\'s Accuracy (%)': [acc*100 for acc in users_accuracy]\n",
    "})\n",
    "\n",
    "print(\"\\nAccuracy Summary by Class:\")\n",
    "print(df_accuracy.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class accuracy\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "x = np.arange(len(class_names))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x - width/2, df_accuracy['Producer\\'s Accuracy (%)'], width, label='Producer\\'s Accuracy', alpha=0.8)\n",
    "ax.bar(x + width/2, df_accuracy['User\\'s Accuracy (%)'], width, label='User\\'s Accuracy', alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('Land Cover Class', fontsize=12)\n",
    "ax.set_ylabel('Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Per-Class Accuracy Metrics', fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(class_names)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 105])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎓 INSTRUCTOR DISCUSSION PROMPT:\")\n",
    "print(\"Analyze accuracy differences:\")\n",
    "print(\"- High producer's, low user's = over-prediction (too many false positives)\")\n",
    "print(\"- Low producer's, high user's = under-prediction (too many false negatives)\")\n",
    "print(\"- Both low = poor discrimination from other classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎓 Teaching Point: Error Analysis\n",
    "\n",
    "**Common confusion patterns:**\n",
    "\n",
    "1. **Agriculture ↔ Bare Soil**\n",
    "   - Cause: Bare agricultural fields (post-harvest, pre-planting)\n",
    "   - Solution: Multi-temporal data (capture full phenological cycle)\n",
    "\n",
    "2. **Forest ↔ Agriculture**\n",
    "   - Cause: High-biomass crops (sugarcane, perennial crops)\n",
    "   - Solution: Add texture features, time series\n",
    "\n",
    "3. **Urban ↔ Bare Soil**\n",
    "   - Cause: Similar spectral response (concrete vs. soil)\n",
    "   - Solution: Texture, spatial context, NDBI weighting\n",
    "\n",
    "4. **Water ↔ Shadow**\n",
    "   - Cause: Cloud shadows have low reflectance\n",
    "   - Solution: Better cloud masking, topographic correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSTRUCTOR SOLUTION: Exercise 6 - Different splits\n",
    "\n",
    "print(\"🎓 INSTRUCTOR DEMO: Testing 70-30 split\\n\")\n",
    "\n",
    "split_70 = 0.7\n",
    "training_set_70 = training_samples.filter(ee.Filter.lt('random', split_70))\n",
    "validation_set_70 = training_samples.filter(ee.Filter.gte('random', split_70))\n",
    "\n",
    "# Retrain\n",
    "rf_70 = ee.Classifier.smileRandomForest(numberOfTrees=100, seed=42)\n",
    "trained_70 = rf_70.train(\n",
    "    features=training_set_70,\n",
    "    classProperty='landcover',\n",
    "    inputProperties=feature_names\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "validation_classified_70 = validation_set_70.classify(trained_70)\n",
    "confusion_70 = validation_classified_70.errorMatrix('landcover', 'classification')\n",
    "accuracy_70 = confusion_70.accuracy().getInfo()\n",
    "\n",
    "print(f\"80-20 split accuracy: {overall_accuracy*100:.2f}%\")\n",
    "print(f\"70-30 split accuracy: {accuracy_70*100:.2f}%\")\n",
    "print(\"\\nExpected outcome: Similar accuracy, larger validation set gives more reliable estimate\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## J. Area Statistics (10 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Connect to policy/management: \"These numbers inform decision-making\"\n",
    "- Discuss uncertainty: \"Accuracy affects area estimates - propagate error!\"\n",
    "- Compare with official statistics if available\n",
    "- Philippine context: DENR requires regular forest cover reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate area per class\n",
    "pixel_area = ee.Image.pixelArea()\n",
    "area_image = pixel_area.addBands(classified_image)\n",
    "\n",
    "area_stats = area_image.reduceRegion(\n",
    "    reducer=ee.Reducer.sum().group(\n",
    "        groupField=1,\n",
    "        groupName='landcover'\n",
    "    ),\n",
    "    geometry=palawan,\n",
    "    scale=10,\n",
    "    maxPixels=1e10,\n",
    "    tileScale=4\n",
    ")\n",
    "\n",
    "print(\"Calculating area statistics...\")\n",
    "print(\"This may take 2-3 minutes...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and process results\n",
    "area_results = area_stats.getInfo()\n",
    "area_groups = area_results['groups']\n",
    "\n",
    "area_data = []\n",
    "for group in area_groups:\n",
    "    class_id = group['landcover']\n",
    "    area_m2 = group['sum']\n",
    "    area_km2 = area_m2 / 1e6\n",
    "    area_ha = area_m2 / 1e4\n",
    "    \n",
    "    area_data.append({\n",
    "        'Class ID': class_id,\n",
    "        'Class Name': class_info[class_id]['name'],\n",
    "        'Area (km²)': area_km2,\n",
    "        'Area (ha)': area_ha\n",
    "    })\n",
    "\n",
    "df_area = pd.DataFrame(area_data).sort_values('Area (km²)', ascending=False)\n",
    "\n",
    "total_area = df_area['Area (km²)'].sum()\n",
    "df_area['Percentage (%)'] = (df_area['Area (km²)'] / total_area) * 100\n",
    "\n",
    "print(\"\\nLand Cover Area Statistics:\")\n",
    "print(df_area.to_string(index=False))\n",
    "print(f\"\\nTotal classified area: {total_area:,.0f} km²\")\n",
    "print(f\"Palawan total area: ~14,649 km²\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize area distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "colors = [f\"#{class_info[row['Class ID']]['color']}\" for _, row in df_area.iterrows()]\n",
    "\n",
    "# Bar chart\n",
    "ax1.bar(df_area['Class Name'], df_area['Area (km²)'], color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Land Cover Class', fontsize=12)\n",
    "ax1.set_ylabel('Area (km²)', fontsize=12)\n",
    "ax1.set_title('Land Cover Distribution', fontsize=14, fontweight='bold')\n",
    "ax1.tick_params(axis='x', rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(\n",
    "    df_area['Percentage (%)'],\n",
    "    labels=df_area['Class Name'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=colors,\n",
    "    startangle=90\n",
    ")\n",
    "ax2.set_title('Land Cover Percentage', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n🎓 INSTRUCTOR DISCUSSION:\")\n",
    "print(\"Compare results with expected patterns:\")\n",
    "print(\"- Palawan is ~50-60% forested (DENR estimates)\")\n",
    "print(\"- Agriculture mainly coastal plains (<15%)\")\n",
    "print(\"- Urban very small (<2%)\")\n",
    "print(\"\\nDiscuss potential discrepancies and their causes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## K. Export Results (10 minutes)\n",
    "\n",
    "### 🎓 Teaching Notes:\n",
    "- Quick section - focus on export parameters\n",
    "- Emphasize: Exports run asynchronously (don't block)\n",
    "- Common issues: Memory limits, quota exceeded, file size\n",
    "- Show task manager: https://code.earthengine.google.com/tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export classification\n",
    "export_classification = ee.batch.Export.image.toDrive(\n",
    "    image=classified_image,\n",
    "    description='Palawan_LandCover_Classification',\n",
    "    folder='EarthEngine',\n",
    "    fileNamePrefix='palawan_landcover_2024',\n",
    "    region=palawan.geometry(),\n",
    "    scale=10,\n",
    "    crs='EPSG:4326',\n",
    "    maxPixels=1e10,\n",
    "    fileFormat='GeoTIFF'\n",
    ")\n",
    "\n",
    "export_classification.start()\n",
    "\n",
    "print(\"✓ Classification export task started\")\n",
    "print(f\"Task: {export_classification.status()['description']}\")\n",
    "print(f\"State: {export_classification.status()['state']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export training samples\n",
    "export_training = ee.batch.Export.table.toDrive(\n",
    "    collection=training_samples,\n",
    "    description='Palawan_Training_Samples',\n",
    "    folder='EarthEngine',\n",
    "    fileNamePrefix='palawan_training_samples',\n",
    "    fileFormat='CSV'\n",
    ")\n",
    "\n",
    "export_training.start()\n",
    "print(\"✓ Training samples export started\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save local files\n",
    "df_confusion = pd.DataFrame(matrix_array, index=class_names, columns=class_names)\n",
    "df_confusion.to_csv('palawan_confusion_matrix.csv')\n",
    "\n",
    "df_area.to_csv('palawan_area_statistics.csv', index=False)\n",
    "\n",
    "print(\"✓ Local files saved\")\n",
    "print(\"  - palawan_confusion_matrix.csv\")\n",
    "print(\"  - palawan_area_statistics.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Wrap-up (5 minutes)\n",
    "\n",
    "### 🎓 Closing Discussion\n",
    "\n",
    "**Ask participants:**\n",
    "1. \"What was the most challenging part?\" → Common: Training data creation\n",
    "2. \"What surprised you about the results?\" → Varies\n",
    "3. \"How would you apply this in your work?\" → Encourage specific applications\n",
    "\n",
    "**Key takeaways to emphasize:**\n",
    "- Training data quality is paramount\n",
    "- Random Forest is powerful but not magic\n",
    "- Accuracy assessment is non-negotiable\n",
    "- GEE enables scalable analysis\n",
    "- Operational deployment requires iteration\n",
    "\n",
    "**Preview next sessions:**\n",
    "- Tomorrow: Deep learning for more complex problems\n",
    "- Day 3: Change detection, time series analysis\n",
    "- Day 4: Operational deployment\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Teaching Resources\n",
    "\n",
    "### Backup Exercises (if time permits)\n",
    "\n",
    "1. **Texture features**: Add GLCM (Gray-Level Co-occurrence Matrix) texture\n",
    "2. **Topography**: Add elevation, slope, aspect from SRTM\n",
    "3. **Multi-temporal**: Compare dry vs wet season\n",
    "4. **Other algorithms**: Compare with SVM, CART\n",
    "5. **Post-processing**: Majority filter, morphological operations\n",
    "\n",
    "### Common Issues and Solutions\n",
    "\n",
    "**Issue: \"No images found\"**\n",
    "- Solution: Use fallback date range, relax cloud filter\n",
    "\n",
    "**Issue: \"Memory limit exceeded\"**\n",
    "- Solution: Add `tileScale=4` or `tileScale=8`\n",
    "\n",
    "**Issue: \"Very low accuracy\"**\n",
    "- Check training data quality visually\n",
    "- Ensure class definitions are clear\n",
    "- Add more training samples\n",
    "\n",
    "**Issue: \"Classification has many isolated pixels\"**\n",
    "- Normal for pixel-based classification\n",
    "- Solution: Apply majority filter (post-processing)\n",
    "\n",
    "### Assessment Questions\n",
    "\n",
    "**Knowledge check:**\n",
    "1. Why use median composite instead of mean?\n",
    "2. What does NDVI measure physically?\n",
    "3. What's the difference between producer's and user's accuracy?\n",
    "4. Why split data into training and validation sets?\n",
    "5. How does Random Forest prevent overfitting?\n",
    "\n",
    "**Application:**\n",
    "1. How would you adapt this for change detection?\n",
    "2. What additional features would help separate agriculture from bare soil?\n",
    "3. How would you validate results without field data?\n",
    "\n",
    "---\n",
    "\n",
    "**END OF INSTRUCTOR VERSION**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

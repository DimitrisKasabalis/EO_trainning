{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Session 1 Theory: Understanding Random Forest for Earth Observation\n",
    "\n",
    "**CopPhil 4-Day Advanced Online Training**  \n",
    "**DAY 2 - Session 1: Supervised Machine Learning - Part 1**\n",
    "\n",
    "**INSTRUCTOR VERSION - Complete Solutions**\n",
    "\n",
    "---\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. **Understand Decision Trees**: Explain how a single decision tree makes predictions through recursive splitting\n",
    "2. **Grasp Ensemble Learning**: Describe how Random Forest combines multiple trees through bootstrap sampling and random feature selection\n",
    "3. **Interpret Feature Importance**: Analyze which spectral bands or derived indices contribute most to classification\n",
    "4. **Evaluate Model Performance**: Read and interpret confusion matrices to assess classification accuracy\n",
    "5. **Apply to EO Context**: Connect these concepts to satellite image classification tasks\n",
    "\n",
    "---\n",
    "\n",
    "## Why Random Forest for Earth Observation?\n",
    "\n",
    "Random Forest is one of the most popular algorithms for land cover classification because:\n",
    "\n",
    "- **Handles high-dimensional data**: Works well with many spectral bands (Sentinel-2 has 13 bands)\n",
    "- **Robust to overfitting**: Ensemble approach reduces variance\n",
    "- **Feature importance**: Reveals which bands are most informative\n",
    "- **No feature scaling required**: Unlike neural networks\n",
    "- **Fast training**: Efficient even with large datasets\n",
    "- **Interpretable**: Can visualize decision rules\n",
    "\n",
    "---\n",
    "\n",
    "**Estimated Time**: 70 minutes  \n",
    "**Teaching Notes**: This notebook builds from simple concepts to complex applications. Encourage hands-on exploration of parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Introduction and Setup (5 minutes)\n",
    "\n",
    "Let's start by importing the necessary libraries and setting up our environment for reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core scientific computing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn for machine learning\n",
    "from sklearn.datasets import make_moons, make_circles, make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Configure plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"colorblind\")  # Color-blind friendly palette\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"✓ Libraries imported successfully!\")\n",
    "print(f\"✓ Random state set to: {RANDOM_STATE}\")\n",
    "print(f\"✓ NumPy version: {np.__version__}\")\n",
    "print(f\"✓ Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## B. Decision Trees Interactive Demo (15 minutes)\n",
    "\n",
    "### What is a Decision Tree?\n",
    "\n",
    "A **Decision Tree** is a supervised learning algorithm that makes predictions by learning a series of if-then-else decision rules from data. Think of it like a flowchart:\n",
    "\n",
    "```\n",
    "Is NDVI > 0.3?\n",
    "├─ Yes: Is NIR > 0.5?\n",
    "│  ├─ Yes: Forest\n",
    "│  └─ No: Grassland\n",
    "└─ No: Is SWIR < 0.2?\n",
    "   ├─ Yes: Water\n",
    "   └─ No: Urban\n",
    "```\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "- **Root Node**: The first decision point (top of the tree)\n",
    "- **Internal Nodes**: Intermediate decision points\n",
    "- **Leaf Nodes**: Final predictions (bottom of the tree)\n",
    "- **Splitting**: How the algorithm decides which feature and threshold to use\n",
    "- **Depth**: Number of levels in the tree (deeper = more complex)\n",
    "\n",
    "### Let's Build a Simple Example\n",
    "\n",
    "**Teaching Tip**: Use this section to explain the greedy, top-down approach of tree building."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple 2D classification dataset\n",
    "# This simulates two spectral bands (e.g., NIR and Red)\n",
    "X, y = make_moons(n_samples=200, noise=0.25, random_state=RANDOM_STATE)\n",
    "\n",
    "# Add feature names for EO context\n",
    "feature_names = ['NIR Reflectance', 'Red Reflectance']\n",
    "class_names = ['Water/Urban', 'Vegetation']\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Number of samples: {X.shape[0]}\")\n",
    "print(f\"Number of features: {X.shape[1]}\")\n",
    "print(f\"Classes: {np.unique(y)}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "                     s=50, alpha=0.7, edgecolors='k', linewidth=0.5)\n",
    "plt.xlabel(feature_names[0], fontsize=12)\n",
    "plt.ylabel(feature_names[1], fontsize=12)\n",
    "plt.title('Training Data: Two Spectral Bands', fontsize=14, fontweight='bold')\n",
    "plt.colorbar(scatter, label='Class', ticks=[0, 1])\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TIP: In real EO applications, each point would represent a pixel with its spectral reflectance values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a Single Decision Tree\n",
    "\n",
    "Let's train a decision tree and visualize how it splits the feature space.\n",
    "\n",
    "**Teaching Point**: Emphasize that decision trees create rectangular partitions (axis-aligned splits)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a decision tree with limited depth\n",
    "tree = DecisionTreeClassifier(max_depth=3, random_state=RANDOM_STATE)\n",
    "tree.fit(X, y)\n",
    "\n",
    "# Calculate training accuracy\n",
    "train_accuracy = tree.score(X, y)\n",
    "print(f\"Training Accuracy: {train_accuracy:.3f}\")\n",
    "print(f\"Tree Depth: {tree.get_depth()}\")\n",
    "print(f\"Number of Leaves: {tree.get_n_leaves()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize decision boundaries\n",
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\"):\n",
    "    \"\"\"\n",
    "    Plot decision boundary for a 2D classification problem.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    model : trained classifier\n",
    "    X : array-like, shape (n_samples, 2)\n",
    "    y : array-like, shape (n_samples,)\n",
    "    title : str\n",
    "    \"\"\"\n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Predict on mesh grid\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.3, cmap='viridis', levels=1)\n",
    "    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "                         s=50, alpha=0.8, edgecolors='k', linewidth=0.5)\n",
    "    plt.xlabel(feature_names[0], fontsize=12)\n",
    "    plt.ylabel(feature_names[1], fontsize=12)\n",
    "    plt.title(title, fontsize=14, fontweight='bold')\n",
    "    plt.colorbar(scatter, label='Class', ticks=[0, 1])\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary(tree, X, y, \n",
    "                      title=\"Decision Tree: How It Splits the Feature Space\")\n",
    "\n",
    "print(\"\\n💡 TIP: Notice the rectangular decision boundaries. Trees can only make\")\n",
    "print(\"   axis-aligned splits (e.g., 'NIR > 0.5'), not diagonal lines.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Tree Structure\n",
    "\n",
    "Let's look inside the tree to see the actual decision rules it learned.\n",
    "\n",
    "**Teaching Tip**: Walk through the tree from root to leaf, explaining Gini impurity and sample counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the tree structure\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, \n",
    "         feature_names=feature_names,\n",
    "         class_names=class_names,\n",
    "         filled=True,\n",
    "         rounded=True,\n",
    "         fontsize=10)\n",
    "plt.title('Decision Tree Structure', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow to Read This Tree:\")\n",
    "print(\"━\" * 60)\n",
    "print(\"• Each box is a node with a decision rule (e.g., 'NIR <= 0.5')\")\n",
    "print(\"• 'gini' measures impurity (0 = pure, 0.5 = mixed)\")\n",
    "print(\"• 'samples' shows how many training points reach this node\")\n",
    "print(\"• 'value' shows class distribution [class 0, class 1]\")\n",
    "print(\"• Color intensity indicates class majority (darker = more confident)\")\n",
    "print(\"• Leaf nodes (bottom) make the final prediction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Interactive Exercise: Effect of Tree Depth (SOLUTION)\n",
    "\n",
    "**Task**: Experiment with different `max_depth` values and observe how the decision boundary changes.\n",
    "\n",
    "**Questions to consider**:\n",
    "1. What happens with `max_depth=1` (a \"decision stump\")?\n",
    "2. What happens with `max_depth=10` (very deep tree)?\n",
    "3. Which depth seems to balance simplicity and accuracy?\n",
    "4. Can you identify overfitting?\n",
    "\n",
    "**Teaching Note**: Have students run this multiple times with different values. Discuss the bias-variance tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Compare different max_depth values\n",
    "depths_to_test = [1, 2, 3, 5, 10, None]\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, depth in enumerate(depths_to_test):\n",
    "    tree_experiment = DecisionTreeClassifier(max_depth=depth, \n",
    "                                            random_state=RANDOM_STATE)\n",
    "    tree_experiment.fit(X, y)\n",
    "    \n",
    "    accuracy = tree_experiment.score(X, y)\n",
    "    actual_depth = tree_experiment.get_depth()\n",
    "    n_leaves = tree_experiment.get_n_leaves()\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    Z = tree_experiment.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    ax = axes[idx]\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='viridis', levels=1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "              s=30, alpha=0.7, edgecolors='k', linewidth=0.3)\n",
    "    ax.set_xlabel(feature_names[0])\n",
    "    ax.set_ylabel(feature_names[1])\n",
    "    \n",
    "    depth_str = str(depth) if depth is not None else \"Unlimited\"\n",
    "    ax.set_title(f'max_depth={depth_str}\\nAcc={accuracy:.3f}, Depth={actual_depth}, Leaves={n_leaves}',\n",
    "                fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Effect of Tree Depth on Decision Boundaries', \n",
    "            fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 OBSERVATIONS:\")\n",
    "print(\"━\" * 60)\n",
    "print(\"• max_depth=1: Very simple (underfitting), straight line split\")\n",
    "print(\"• max_depth=2-3: Balanced complexity, generalizes well\")\n",
    "print(\"• max_depth=10: High training accuracy but overfits (jagged boundaries)\")\n",
    "print(\"• max_depth=None: Severe overfitting, memorizes training data\")\n",
    "print(\"\\n⚠️ OVERFITTING SIGNS: Perfect training accuracy + complex boundaries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## C. Random Forest Voting Mechanism (15 minutes)\n",
    "\n",
    "### The Power of Ensemble Learning\n",
    "\n",
    "A single decision tree can be unstable:\n",
    "- Small changes in data can lead to completely different trees\n",
    "- Prone to overfitting (memorizing training data)\n",
    "- High variance in predictions\n",
    "\n",
    "**Random Forest** solves this by combining many trees:\n",
    "\n",
    "1. **Bootstrap Sampling**: Each tree trains on a random subset of data (sampling with replacement)\n",
    "2. **Random Feature Selection**: Each split only considers a random subset of features\n",
    "3. **Majority Voting**: Final prediction is the class chosen by most trees\n",
    "\n",
    "**Analogy**: Instead of asking one expert (one tree), you ask a committee of experts (forest) and take a vote. This \"wisdom of the crowd\" is more robust!\n",
    "\n",
    "**Teaching Tip**: Draw a diagram showing bootstrap sampling and aggregation on the board/screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a Random Forest with just 5 trees (for visualization)\n",
    "n_trees = 5\n",
    "rf_small = RandomForestClassifier(n_estimators=n_trees, \n",
    "                                 max_depth=3,\n",
    "                                 random_state=RANDOM_STATE)\n",
    "rf_small.fit(X, y)\n",
    "\n",
    "rf_accuracy = rf_small.score(X, y)\n",
    "print(f\"Random Forest Accuracy (5 trees): {rf_accuracy:.3f}\")\n",
    "print(f\"Single Tree Accuracy (from before): {train_accuracy:.3f}\")\n",
    "print(f\"\\nImprovement: {rf_accuracy - train_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Individual Trees in the Forest\n",
    "\n",
    "Let's see how each tree makes different decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot decision boundaries for each individual tree\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "# Plot each individual tree\n",
    "for idx, tree in enumerate(rf_small.estimators_):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create mesh grid\n",
    "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                         np.linspace(y_min, y_max, 200))\n",
    "    \n",
    "    # Predict\n",
    "    Z = tree.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot\n",
    "    ax.contourf(xx, yy, Z, alpha=0.3, cmap='viridis', levels=1)\n",
    "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "              s=30, alpha=0.6, edgecolors='k', linewidth=0.3)\n",
    "    ax.set_xlabel(feature_names[0])\n",
    "    ax.set_ylabel(feature_names[1])\n",
    "    ax.set_title(f'Tree {idx + 1}', fontweight='bold')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot the ensemble (Random Forest)\n",
    "ax = axes[5]\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "Z = rf_small.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "ax.contourf(xx, yy, Z, alpha=0.3, cmap='viridis', levels=1)\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "          s=30, alpha=0.6, edgecolors='k', linewidth=0.3)\n",
    "ax.set_xlabel(feature_names[0])\n",
    "ax.set_ylabel(feature_names[1])\n",
    "ax.set_title('Random Forest (Ensemble)', fontweight='bold', color='red')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Individual Trees vs. Ensemble Decision', \n",
    "            fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TIP: Notice how each tree is slightly different due to bootstrap\")\n",
    "print(\"   sampling and random feature selection. The ensemble smooths out\")\n",
    "print(\"   individual errors and creates more stable boundaries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Voting Confidence\n",
    "\n",
    "Random Forest can provide prediction probabilities based on the proportion of trees voting for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get prediction probabilities\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 200),\n",
    "                     np.linspace(y_min, y_max, 200))\n",
    "\n",
    "# Predict probabilities for class 1 (Vegetation)\n",
    "Z_proba = rf_small.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
    "Z_proba = Z_proba.reshape(xx.shape)\n",
    "\n",
    "# Plot confidence\n",
    "plt.figure(figsize=(12, 7))\n",
    "contour = plt.contourf(xx, yy, Z_proba, levels=20, cmap='RdYlGn', alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap='viridis', \n",
    "           s=50, alpha=0.7, edgecolors='k', linewidth=0.5)\n",
    "plt.colorbar(contour, label='Confidence for Vegetation Class')\n",
    "plt.xlabel(feature_names[0], fontsize=12)\n",
    "plt.ylabel(feature_names[1], fontsize=12)\n",
    "plt.title('Random Forest Prediction Confidence\\n(Based on Voting Proportions)', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpreting Confidence:\")\n",
    "print(\"━\" * 60)\n",
    "print(\"• Green (high values): Most trees vote for 'Vegetation'\")\n",
    "print(\"• Red (low values): Most trees vote for 'Water/Urban'\")\n",
    "print(\"• Yellow (middle values): Trees are uncertain (mixed votes)\")\n",
    "print(\"\\n💡 TIP: Low confidence regions often indicate:\")\n",
    "print(\"   - Class boundaries\")\n",
    "print(\"   - Mixed pixels (in EO context)\")\n",
    "print(\"   - Need for more training data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Interactive Exercise: Effect of Number of Trees (SOLUTION)\n",
    "\n",
    "**Task**: Test how the number of trees affects model stability and accuracy.\n",
    "\n",
    "**Hypothesis**: More trees → more stable predictions, but diminishing returns after a certain point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: Test different numbers of trees\n",
    "tree_counts = [1, 5, 10, 50, 100, 200]\n",
    "accuracies = []\n",
    "\n",
    "for n in tree_counts:\n",
    "    rf = RandomForestClassifier(n_estimators=n, \n",
    "                               max_depth=3,\n",
    "                               random_state=RANDOM_STATE)\n",
    "    rf.fit(X, y)\n",
    "    acc = rf.score(X, y)\n",
    "    accuracies.append(acc)\n",
    "    print(f\"n_estimators={n:3d} → Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Plot accuracy vs. number of trees\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(tree_counts, accuracies, marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Trees', fontsize=12)\n",
    "plt.ylabel('Training Accuracy', fontsize=12)\n",
    "plt.title('Effect of Ensemble Size on Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n📊 OBSERVATIONS:\")\n",
    "print(\"━\" * 60)\n",
    "print(\"• Single tree (n=1): High variance, unstable\")\n",
    "print(\"• Few trees (n=5-10): Improvement but still some variance\")\n",
    "print(\"• Many trees (n=50-100): Accuracy stabilizes\")\n",
    "print(\"• More trees (n=200): Minimal additional improvement\")\n",
    "print(\"\\n💡 PRACTICAL RECOMMENDATION: 100-500 trees balances accuracy and speed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## D. Feature Importance Analysis (10 minutes)\n",
    "\n",
    "### Why Feature Importance Matters in EO\n",
    "\n",
    "Feature importance tells us:\n",
    "- Which spectral bands contribute most to classification\n",
    "- Whether derived indices (NDVI, NDWI) are valuable\n",
    "- If certain features are redundant\n",
    "- How to optimize future data collection\n",
    "\n",
    "**How Random Forest Calculates Importance**:\n",
    "- Measures how much each feature decreases impurity (Gini or entropy)\n",
    "- Averaged across all trees in the forest\n",
    "- Higher values = more important for classification\n",
    "\n",
    "**Teaching Note**: Emphasize that importance ≠ causation, and correlated features share importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset mimicking Sentinel-2 spectral bands\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "# Simulate 1000 pixels with 8 \"spectral bands\"\n",
    "n_samples = 1000\n",
    "n_features = 8\n",
    "\n",
    "# Feature names mimicking Sentinel-2 bands and indices\n",
    "eo_feature_names = [\n",
    "    'Blue (B2)',\n",
    "    'Green (B3)',\n",
    "    'Red (B4)',\n",
    "    'NIR (B8)',\n",
    "    'SWIR1 (B11)',\n",
    "    'SWIR2 (B12)',\n",
    "    'NDVI',\n",
    "    'NDWI'\n",
    "]\n",
    "\n",
    "# Create synthetic data with realistic patterns\n",
    "# Class 0: Water (low NIR, high Blue, high NDWI)\n",
    "# Class 1: Vegetation (high NIR, low Red, high NDVI)\n",
    "# Class 2: Urban (moderate all, low NDVI, low NDWI)\n",
    "\n",
    "X_eo = np.random.rand(n_samples, n_features)\n",
    "y_eo = np.random.choice([0, 1, 2], size=n_samples)\n",
    "\n",
    "# Add class-specific patterns\n",
    "for i in range(n_samples):\n",
    "    if y_eo[i] == 0:  # Water\n",
    "        X_eo[i, 0] += 0.3  # Higher Blue\n",
    "        X_eo[i, 3] -= 0.3  # Lower NIR\n",
    "        X_eo[i, 7] += 0.4  # Higher NDWI\n",
    "    elif y_eo[i] == 1:  # Vegetation\n",
    "        X_eo[i, 3] += 0.5  # Higher NIR\n",
    "        X_eo[i, 2] -= 0.2  # Lower Red\n",
    "        X_eo[i, 6] += 0.5  # Higher NDVI\n",
    "    else:  # Urban\n",
    "        X_eo[i, 4] += 0.2  # Higher SWIR1\n",
    "        X_eo[i, 5] += 0.2  # Higher SWIR2\n",
    "\n",
    "# Clip to [0, 1] range\n",
    "X_eo = np.clip(X_eo, 0, 1)\n",
    "\n",
    "print(f\"EO Dataset shape: {X_eo.shape}\")\n",
    "print(f\"Features: {eo_feature_names}\")\n",
    "print(f\"Classes: 0=Water, 1=Vegetation, 2=Urban\")\n",
    "print(f\"Class distribution: {np.bincount(y_eo)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest on EO-like data\n",
    "rf_eo = RandomForestClassifier(n_estimators=100, \n",
    "                              max_depth=10,\n",
    "                              random_state=RANDOM_STATE)\n",
    "rf_eo.fit(X_eo, y_eo)\n",
    "\n",
    "# Extract feature importances\n",
    "importances = rf_eo.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]  # Sort descending\n",
    "\n",
    "print(\"Feature Importance Ranking:\")\n",
    "print(\"━\" * 60)\n",
    "for i, idx in enumerate(indices):\n",
    "    print(f\"{i+1}. {eo_feature_names[idx]:15s}: {importances[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importances\n",
    "plt.figure(figsize=(12, 7))\n",
    "bars = plt.barh(range(len(importances)), importances[indices], align='center')\n",
    "\n",
    "# Color bars by importance\n",
    "colors = plt.cm.viridis(importances[indices] / importances.max())\n",
    "for bar, color in zip(bars, colors):\n",
    "    bar.set_color(color)\n",
    "\n",
    "plt.yticks(range(len(importances)), [eo_feature_names[i] for i in indices])\n",
    "plt.xlabel('Importance (Mean Decrease in Impurity)', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Feature Importance for Land Cover Classification', \n",
    "         fontsize=14, fontweight='bold')\n",
    "plt.grid(True, axis='x', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TIP: High importance doesn't always mean causation!\")\n",
    "print(\"   - NDVI is derived from NIR and Red, so they're correlated\")\n",
    "print(\"   - Consider domain knowledge alongside feature importance\")\n",
    "print(\"   - Importance can be unstable with correlated features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise: Interpret Feature Importance (SOLUTION)\n",
    "\n",
    "**Questions**:\n",
    "1. Which feature is most important? Why might this be?\n",
    "2. Are the derived indices (NDVI, NDWI) more or less important than raw bands?\n",
    "3. Which features could potentially be removed to simplify the model?\n",
    "4. How does this align with your knowledge of land cover spectral signatures?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTIONS**:\n",
    "\n",
    "1. **Most important feature**:\n",
    "   - Typically **NDVI** or **NIR (B8)** will rank highest\n",
    "   - **Why**: Strong discriminator between vegetation and non-vegetation\n",
    "   - Vegetation has very high NIR reflectance vs. water/urban\n",
    "   - NDVI combines NIR and Red, enhancing this contrast\n",
    "\n",
    "2. **Derived indices vs. raw bands**:\n",
    "   - **Often more important** because they:\n",
    "     - Normalize for illumination differences\n",
    "     - Enhance specific spectral features\n",
    "     - Reduce dimensionality while retaining information\n",
    "   - However, raw bands still valuable for capturing additional variation\n",
    "\n",
    "3. **Features that could be removed**:\n",
    "   - Look for features with importance < 0.05\n",
    "   - **Green (B3)** might be less important (redundant with Blue/Red)\n",
    "   - **SWIR2 (B12)** might be redundant with SWIR1\n",
    "   - Consider correlation analysis before removal\n",
    "   - **Caution**: Don't remove without testing impact on validation accuracy\n",
    "\n",
    "4. **Alignment with spectral signatures**:\n",
    "   - **Expected patterns**:\n",
    "     - NIR/NDVI: High importance (vegetation has unique NIR signature)\n",
    "     - NDWI/Blue: Important for water detection\n",
    "     - SWIR: Important for urban/soil/moisture\n",
    "   - **Makes spectral sense**:\n",
    "     - Each feature separates specific class pairs\n",
    "     - Vegetation: High NIR, low Red → high NDVI\n",
    "     - Water: High Blue, low NIR → high NDWI\n",
    "     - Urban: Moderate all bands, high SWIR\n",
    "\n",
    "**Teaching Discussion Points**:\n",
    "- Connect to Sentinel-2 band selection rationale\n",
    "- Discuss trade-offs: accuracy vs. computational cost vs. data volume\n",
    "- Mention permutation importance as alternative (more stable with correlated features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## E. Confusion Matrix Interpretation (15 minutes)\n",
    "\n",
    "### Why Confusion Matrix?\n",
    "\n",
    "Overall accuracy can be misleading! Consider:\n",
    "- Dataset: 95% Forest, 5% Mangrove\n",
    "- Model: Predicts everything as Forest\n",
    "- Accuracy: 95% (sounds great!)\n",
    "- Problem: Completely missed mangroves!\n",
    "\n",
    "**Confusion Matrix** reveals:\n",
    "- Which classes are well-predicted\n",
    "- Which classes are confused with each other\n",
    "- Class-specific performance (precision, recall)\n",
    "\n",
    "### Key Metrics:\n",
    "\n",
    "- **Precision (User's Accuracy)**: Of all pixels predicted as class X, how many are actually class X?\n",
    "  - Formula: TP / (TP + FP)\n",
    "  - Important when false positives are costly\n",
    "\n",
    "- **Recall (Producer's Accuracy)**: Of all actual class X pixels, how many did we correctly identify?\n",
    "  - Formula: TP / (TP + FN)\n",
    "  - Important when false negatives are costly\n",
    "\n",
    "- **F1-Score**: Harmonic mean of precision and recall\n",
    "  - Formula: 2 × (Precision × Recall) / (Precision + Recall)\n",
    "  - Balances both metrics\n",
    "\n",
    "**Teaching Tip**: Use concrete EO examples (e.g., mapping illegal logging, disaster damage) to illustrate when precision vs. recall matters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_eo, y_eo, test_size=0.3, random_state=RANDOM_STATE, stratify=y_eo\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")\n",
    "print(f\"Training class distribution: {np.bincount(y_train)}\")\n",
    "print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "\n",
    "print(\"\\n💡 TIP: We use stratified split to maintain class proportions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest\n",
    "rf_final = RandomForestClassifier(n_estimators=100, \n",
    "                                 max_depth=10,\n",
    "                                 random_state=RANDOM_STATE)\n",
    "rf_final.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = rf_final.predict(X_test)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "overall_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Overall Test Accuracy: {overall_accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "class_labels = ['Water', 'Vegetation', 'Urban']\n",
    "\n",
    "print(\"Confusion Matrix (raw counts):\")\n",
    "print(\"━\" * 60)\n",
    "print(cm)\n",
    "print(\"\\nRows = Actual class, Columns = Predicted class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confusion matrix as heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "           xticklabels=class_labels, \n",
    "           yticklabels=class_labels,\n",
    "           cbar_kws={'label': 'Number of Samples'},\n",
    "           linewidths=1, linecolor='gray')\n",
    "plt.xlabel('Predicted Class', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Actual Class', fontsize=12, fontweight='bold')\n",
    "plt.title('Confusion Matrix: Land Cover Classification', \n",
    "         fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nHow to Read This Matrix:\")\n",
    "print(\"━\" * 60)\n",
    "print(\"• Diagonal (top-left to bottom-right): Correct predictions\")\n",
    "print(\"• Off-diagonal: Confusion between classes\")\n",
    "print(\"• Dark blue cells indicate high counts\")\n",
    "print(\"\\n💡 TIP: Look for patterns in confusion:\")\n",
    "print(\"   - Are certain class pairs often confused?\")\n",
    "print(\"   - Do confusions make spectral sense?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate normalized confusion matrix (percentages)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2%', cmap='RdYlGn', \n",
    "           xticklabels=class_labels, \n",
    "           yticklabels=class_labels,\n",
    "           vmin=0, vmax=1,\n",
    "           cbar_kws={'label': 'Percentage'},\n",
    "           linewidths=1, linecolor='gray')\n",
    "plt.xlabel('Predicted Class', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Actual Class', fontsize=12, fontweight='bold')\n",
    "plt.title('Normalized Confusion Matrix (Row Percentages)', \n",
    "         fontsize=14, fontweight='bold', pad=15)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TIP: Normalized matrix shows recall (producer's accuracy) for each class.\")\n",
    "print(\"   Diagonal values are the percentage correctly classified for each class.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Detailed Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "print(\"Classification Report:\")\n",
    "print(\"━\" * 80)\n",
    "report = classification_report(y_test, y_pred, \n",
    "                              target_names=class_labels,\n",
    "                              digits=3)\n",
    "print(report)\n",
    "\n",
    "print(\"\\nMetric Definitions:\")\n",
    "print(\"━\" * 80)\n",
    "print(\"• Precision (User's Accuracy): TP / (TP + FP)\")\n",
    "print(\"  → Of predictions for this class, how many were correct?\")\n",
    "print(\"  → Important when false alarms are costly\")\n",
    "print(\"\")\n",
    "print(\"• Recall (Producer's Accuracy): TP / (TP + FN)\")\n",
    "print(\"  → Of actual samples of this class, how many were found?\")\n",
    "print(\"  → Important when missing instances is costly\")\n",
    "print(\"\")\n",
    "print(\"• F1-Score: 2 × (Precision × Recall) / (Precision + Recall)\")\n",
    "print(\"  → Harmonic mean balancing precision and recall\")\n",
    "print(\"\")\n",
    "print(\"• Support: Number of actual samples in test set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize per-class metrics\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average=None)\n",
    "recall = recall_score(y_test, y_pred, average=None)\n",
    "f1 = f1_score(y_test, y_pred, average=None)\n",
    "\n",
    "# Create DataFrame for easier plotting\n",
    "metrics_df = pd.DataFrame({\n",
    "    'Precision': precision,\n",
    "    'Recall': recall,\n",
    "    'F1-Score': f1\n",
    "}, index=class_labels)\n",
    "\n",
    "# Plot\n",
    "ax = metrics_df.plot(kind='bar', figsize=(12, 7), width=0.8)\n",
    "plt.xlabel('Land Cover Class', fontsize=12)\n",
    "plt.ylabel('Score', fontsize=12)\n",
    "plt.title('Per-Class Performance Metrics', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=0)\n",
    "plt.ylim([0, 1.05])\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(True, axis='y', alpha=0.3)\n",
    "plt.axhline(y=0.8, color='r', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n💡 TIP: In EO applications, different thresholds matter:\")\n",
    "print(\"   - Disaster mapping: High recall for affected areas (don't miss damage)\")\n",
    "print(\"   - Urban planning: High precision for built-up (avoid false alarms)\")\n",
    "print(\"   - Balanced: Use F1-score for overall assessment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Exercise: Confusion Analysis (SOLUTION)\n",
    "\n",
    "**Task**: Analyze the confusion matrix and answer these questions:\n",
    "\n",
    "1. Which class has the highest recall (producer's accuracy)?\n",
    "2. Which class has the lowest precision (user's accuracy)?\n",
    "3. Which two classes are most often confused with each other?\n",
    "4. Why might this confusion occur from a spectral perspective?\n",
    "5. What could you do to improve classification of the weakest class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SOLUTIONS**:\n",
    "\n",
    "1. **Highest recall class**:\n",
    "   - Typically **Vegetation** (class 1)\n",
    "   - **Why**: Strong, unique spectral signature (high NIR, high NDVI)\n",
    "   - Model rarely misses vegetation pixels\n",
    "   - High NDVI values create clear separation from other classes\n",
    "\n",
    "2. **Lowest precision class**:\n",
    "   - Often **Urban** (class 2)\n",
    "   - **Why**: Heterogeneous class (buildings, roads, bare soil, sparse vegetation)\n",
    "   - Spectral variability within class\n",
    "   - Can overlap spectrally with water (shadows, dark roofs) or bare soil\n",
    "\n",
    "3. **Most confused class pair**:\n",
    "   - Commonly **Urban ↔ Water** or **Urban ↔ Bare Soil** (if present)\n",
    "   - Look at off-diagonal elements in confusion matrix\n",
    "   - Check which non-diagonal cell has highest count\n",
    "   - **Example**: If cm[2,0] and cm[0,2] are high → Urban-Water confusion\n",
    "\n",
    "4. **Spectral reason for confusion**:\n",
    "   - **Urban ↔ Water**:\n",
    "     - Shadows in urban areas (low reflectance, similar to water)\n",
    "     - Dark impervious surfaces (asphalt, roofs)\n",
    "     - Both have low NIR and low NDVI\n",
    "   - **Urban ↔ Bare Soil**:\n",
    "     - Construction sites, unpaved roads\n",
    "     - Similar SWIR response\n",
    "     - Both have moderate reflectance across bands\n",
    "   - **Water ↔ Shadows**:\n",
    "     - Very low reflectance in all bands\n",
    "     - Without topographic correction, shadows misclassified as water\n",
    "\n",
    "5. **Improvement strategies**:\n",
    "   \n",
    "   **Data-Centric Approaches**:\n",
    "   - **More training samples** for confused classes\n",
    "     - Especially at class boundaries\n",
    "     - Ensure diversity (different urban types, water conditions)\n",
    "   - **Better quality samples**\n",
    "     - Remove mislabeled examples\n",
    "     - Use higher resolution imagery for ground truth\n",
    "     - Field validation of uncertain areas\n",
    "   \n",
    "   **Feature Engineering**:\n",
    "   - **Add discriminative features**:\n",
    "     - Texture metrics (urban is heterogeneous, water is smooth)\n",
    "     - Temporal features (NDVI time series separates urban from bare soil)\n",
    "     - Topographic features (slope, aspect to handle shadows)\n",
    "   - **Remove redundant/noisy features**\n",
    "   \n",
    "   **Model-Centric Approaches**:\n",
    "   - **Class balancing**: Adjust class_weight parameter\n",
    "   - **Threshold tuning**: Adjust prediction probabilities for cost-sensitive classes\n",
    "   - **Hyperparameter optimization**: Grid search for max_depth, min_samples_split\n",
    "   - **Ensemble with other algorithms**: Combine RF with SVM or neural network\n",
    "   \n",
    "   **Post-Processing**:\n",
    "   - **Spatial filtering**: Majority filter to remove salt-and-pepper noise\n",
    "   - **Contextual rules**: Water is unlikely at high elevations\n",
    "   - **Object-based approach**: Segment first, then classify\n",
    "\n",
    "**Teaching Discussion**:\n",
    "- Emphasize **data-centric AI**: Often better to improve training data than tweak algorithms\n",
    "- Connect to Philippine context: Confusion between mangrove and terrestrial forest?\n",
    "- Discuss operational constraints: Can you collect more samples? Is real-time processing needed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## F. Concept Check Quiz (10 minutes)\n",
    "\n",
    "Test your understanding of Random Forest concepts!\n",
    "\n",
    "**Teaching Note**: Can be done as:\n",
    "- Individual work with class discussion\n",
    "- Think-pair-share\n",
    "- Kahoot/Mentimeter for interactive polling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Decision Tree Splitting\n",
    "\n",
    "**Q**: How does a decision tree decide where to split at each node?\n",
    "\n",
    "A) Randomly selects a feature and threshold  \n",
    "B) Uses the feature and threshold that maximizes information gain (or minimizes impurity)  \n",
    "C) Always splits at the median value of each feature  \n",
    "D) Splits based on alphabetical order of feature names\n",
    "\n",
    "**✓ ANSWER: B**\n",
    "\n",
    "**Explanation**:\n",
    "Decision trees use a **greedy algorithm** that evaluates all possible splits and chooses the one that best separates classes:\n",
    "\n",
    "- **Classification**: Maximizes information gain or minimizes Gini impurity\n",
    "- **Process**: For each feature, tests multiple threshold values\n",
    "- **Criterion**: Gini impurity = 1 - Σ(p_i²), where p_i is proportion of class i\n",
    "- **Goal**: Make child nodes as \"pure\" (single-class) as possible\n",
    "\n",
    "**Teaching Tip**: Draw a simple 2D scatter plot and show how different split lines result in different purities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Bootstrap Sampling\n",
    "\n",
    "**Q**: In Random Forest, what is bootstrap sampling?\n",
    "\n",
    "A) Sampling pixels only from the edges of images  \n",
    "B) Sampling with replacement to create training subsets for each tree  \n",
    "C) Sampling only the most important features  \n",
    "D) Sampling validation data separately from training data\n",
    "\n",
    "**✓ ANSWER: B**\n",
    "\n",
    "**Explanation**:\n",
    "**Bootstrap sampling** (also called **bagging** - Bootstrap AGGregatING):\n",
    "\n",
    "- Randomly selects samples **with replacement**\n",
    "- Each tree gets ~63.2% unique samples (rest are duplicates)\n",
    "- Remaining ~36.8% are \"out-of-bag\" (OOB) samples (can be used for validation)\n",
    "- Creates training diversity → reduces correlation between trees\n",
    "- Key to ensemble's variance reduction\n",
    "\n",
    "**Example**:\n",
    "```\n",
    "Original dataset: [A, B, C, D, E]\n",
    "Tree 1 bootstrap:  [A, A, C, D, E]  (B not selected)\n",
    "Tree 2 bootstrap:  [A, B, B, C, C]  (D, E not selected)\n",
    "Tree 3 bootstrap:  [B, C, D, D, E]  (A not selected)\n",
    "```\n",
    "\n",
    "Each tree sees slightly different data, learns different patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Random Feature Selection\n",
    "\n",
    "**Q**: At each split in a Random Forest tree, what does \"random feature selection\" mean?\n",
    "\n",
    "A) All features are considered for splitting  \n",
    "B) Features are selected in alphabetical order  \n",
    "C) Only a random subset of features is considered (typically √n or log₂n)  \n",
    "D) The most important feature is always selected\n",
    "\n",
    "**✓ ANSWER: C**\n",
    "\n",
    "**Explanation**:\n",
    "**Random feature selection** (controlled by `max_features` parameter):\n",
    "\n",
    "- At each split, only consider a **random subset** of features\n",
    "- **Default for classification**: √n features (e.g., √8 ≈ 3 features)\n",
    "- **Default for regression**: n/3 features\n",
    "- **Purpose**: Decorrelates trees\n",
    "\n",
    "**Why This Matters**:\n",
    "Without it, if one feature is very strong (e.g., NDVI), ALL trees would use it as the first split → highly correlated trees → ensemble doesn't help much.\n",
    "\n",
    "With it, some trees won't have access to NDVI, so they'll find alternative patterns using other features → diverse trees → better ensemble.\n",
    "\n",
    "**Analogy**: If you ask 100 doctors for a diagnosis but they all read the same textbook page, you get redundant opinions. If each reads a random subset of pages, you get diverse insights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Feature Importance Interpretation\n",
    "\n",
    "**Q**: You're classifying land cover and find that NDVI has the highest feature importance. What should you conclude?\n",
    "\n",
    "A) NDVI is the only feature needed; remove all others  \n",
    "B) NDVI contributes most to reducing impurity, but other features may still be valuable  \n",
    "C) NDVI causes the land cover types (causal relationship)  \n",
    "D) All other features are completely irrelevant\n",
    "\n",
    "**✓ ANSWER: B**\n",
    "\n",
    "**Explanation**:\n",
    "**Feature importance ≠ Complete information**\n",
    "\n",
    "High importance means NDVI is most useful **on average** across all splits, but:\n",
    "\n",
    "1. **Other features capture complementary info**:\n",
    "   - NDVI separates vegetation vs. non-vegetation\n",
    "   - But SWIR might separate urban vs. water\n",
    "   - And NDWI might separate water vs. bare soil\n",
    "\n",
    "2. **Correlated features share importance**:\n",
    "   - NDVI = (NIR - Red) / (NIR + Red)\n",
    "   - NIR and Red importance is \"stolen\" by NDVI\n",
    "   - But NIR/Red might still be needed for edge cases\n",
    "\n",
    "3. **Importance ≠ Causation**:\n",
    "   - NDVI doesn't *cause* land cover\n",
    "   - It's just a good *predictor* (correlation)\n",
    "\n",
    "4. **Context-dependent**:\n",
    "   - In a pure urban study (no vegetation), NDVI would be useless\n",
    "   - Importance reflects your specific dataset\n",
    "\n",
    "**Best Practice**: Use importance for **feature understanding**, not feature elimination. Test impact of removing features on validation set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Confusion Matrix - Precision vs. Recall\n",
    "\n",
    "**Scenario**: You're mapping forest fire damage. The confusion matrix shows:\n",
    "- Actual Burned: 100 pixels\n",
    "- Predicted as Burned: 150 pixels\n",
    "- Correctly identified Burned: 90 pixels\n",
    "\n",
    "**Q**: Calculate precision and recall for the \"Burned\" class. Which is more important for this application?\n",
    "\n",
    "**✓ SOLUTION**:\n",
    "\n",
    "**Calculations**:\n",
    "```\n",
    "True Positives (TP) = 90\n",
    "False Positives (FP) = 150 - 90 = 60\n",
    "False Negatives (FN) = 100 - 90 = 10\n",
    "\n",
    "Precision = TP / (TP + FP) = 90 / 150 = 0.60 (60%)\n",
    "Recall = TP / (TP + FN) = 90 / 100 = 0.90 (90%)\n",
    "```\n",
    "\n",
    "**Interpretation**:\n",
    "- **Precision = 60%**: Of pixels we labeled as burned, 60% actually were (40% false alarms)\n",
    "- **Recall = 90%**: Of actual burned pixels, we found 90% (missed 10%)\n",
    "\n",
    "**Which is More Important? → RECALL**\n",
    "\n",
    "**Why**:\n",
    "- **False Negatives (missing burned areas) are costly**:\n",
    "  - Communities might not receive aid\n",
    "  - Extent of disaster underestimated\n",
    "  - Recovery efforts misdirected\n",
    "\n",
    "- **False Positives (false alarms) are acceptable**:\n",
    "  - Can be verified with field checks\n",
    "  - Better to overestimate for safety\n",
    "  - Not life-threatening if incorrect\n",
    "\n",
    "**Strategy**: Lower classification threshold for \"Burned\" class to increase recall (accept more false positives to catch all true positives).\n",
    "\n",
    "**Contrast with Different Application**:\n",
    "If mapping **urban expansion for taxation**, **precision** is more important:\n",
    "- False positives → incorrectly taxing agricultural land as urban\n",
    "- Legal/financial consequences\n",
    "- Better to be conservative\n",
    "\n",
    "**Teaching Point**: The \"right\" metric depends on **application context and costs**. Always ask: \"What's the cost of false positives vs. false negatives?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6: Overfitting in Random Forest\n",
    "\n",
    "**Q**: Which scenario is MOST likely to cause overfitting in Random Forest?\n",
    "\n",
    "A) Using 100 trees instead of 10  \n",
    "B) Setting max_depth=None (unlimited depth)  \n",
    "C) Using bootstrap sampling  \n",
    "D) Using random feature selection\n",
    "\n",
    "**✓ ANSWER: B**\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "**B) Unlimited depth is the main overfitting risk**:\n",
    "- Trees grow until leaves are pure (or min_samples_leaf is reached)\n",
    "- Creates very deep, complex trees\n",
    "- **Memorizes training data** instead of learning patterns\n",
    "- Signs: Training accuracy ≈ 100%, test accuracy much lower\n",
    "\n",
    "**Why other options DON'T cause overfitting**:\n",
    "\n",
    "**A) More trees (100 vs. 10)**:\n",
    "- **Actually REDUCES overfitting!**\n",
    "- More trees → better averaging → more stable predictions\n",
    "- Random Forest rarely overfits from too many trees\n",
    "- Only downside: computational cost\n",
    "\n",
    "**C) Bootstrap sampling**:\n",
    "- **Reduces overfitting!**\n",
    "- Creates training diversity\n",
    "- Each tree sees different data → less correlation\n",
    "- Part of RF's strength\n",
    "\n",
    "**D) Random feature selection**:\n",
    "- **Reduces overfitting!**\n",
    "- Prevents dominance of single strong feature\n",
    "- Decorrelates trees\n",
    "- Encourages learning diverse patterns\n",
    "\n",
    "**Prevention Strategies**:\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    max_depth=10,          # Limit tree depth\n",
    "    min_samples_split=10,  # Minimum samples to split a node\n",
    "    min_samples_leaf=5,    # Minimum samples in a leaf\n",
    "    max_features='sqrt',   # Random feature selection\n",
    "    n_estimators=100       # Many trees (more = better!)\n",
    ")\n",
    "```\n",
    "\n",
    "**Detection**:\n",
    "- Large gap between training and validation accuracy\n",
    "- Very high training accuracy (>99%)\n",
    "- Poor generalization to new areas\n",
    "- Overly complex decision boundaries\n",
    "\n",
    "**Teaching Analogy**: \n",
    "Unlimited depth is like a student who memorizes every exam question/answer instead of understanding concepts. They ace practice exams but fail on new questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary and Key Takeaways\n",
    "\n",
    "### Decision Trees\n",
    "- Learn hierarchical decision rules through recursive splitting\n",
    "- Create axis-aligned decision boundaries\n",
    "- Prone to overfitting if too deep\n",
    "- Easy to interpret and visualize\n",
    "\n",
    "### Random Forest Ensemble\n",
    "- Combines many trees to reduce variance and improve stability\n",
    "- Uses bootstrap sampling (bagging) for training diversity\n",
    "- Uses random feature selection to decorrelate trees\n",
    "- Final prediction by majority voting (classification) or averaging (regression)\n",
    "- More robust than single trees, less prone to overfitting\n",
    "\n",
    "### Feature Importance\n",
    "- Measures contribution of each feature to reducing impurity\n",
    "- Helps identify most informative spectral bands/indices\n",
    "- Useful for feature selection and model interpretation\n",
    "- Should be interpreted with domain knowledge\n",
    "- Can be unstable with correlated features\n",
    "\n",
    "### Confusion Matrix & Metrics\n",
    "- Overall accuracy can hide class-specific problems\n",
    "- **Precision** (user's accuracy): Reliability of positive predictions\n",
    "- **Recall** (producer's accuracy): Completeness of detection\n",
    "- **F1-score**: Harmonic mean balancing precision and recall\n",
    "- Choice of metric depends on application cost (false positives vs. false negatives)\n",
    "\n",
    "### For Earth Observation\n",
    "- Random Forest works well with multi-spectral data\n",
    "- No feature scaling needed (unlike neural networks)\n",
    "- Feature importance reveals spectral signature insights\n",
    "- Confusion patterns often reflect spectral similarity\n",
    "- Fast training enables rapid iteration\n",
    "\n",
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "In the **Hands-On Session**, you will:\n",
    "1. Load real Sentinel-2 data for Palawan, Philippines\n",
    "2. Extract training samples from land cover polygons\n",
    "3. Train Random Forest for multi-class land cover classification\n",
    "4. Optimize hyperparameters (n_estimators, max_depth, etc.)\n",
    "5. Generate wall-to-wall land cover maps\n",
    "6. Validate results and interpret errors\n",
    "\n",
    "**Prepare by reviewing**:\n",
    "- Sentinel-2 band characteristics (B2, B3, B4, B8, B11, B12)\n",
    "- Philippine land cover types (forest, mangrove, agriculture, urban, water)\n",
    "- Google Earth Engine Python API basics\n",
    "\n",
    "---\n",
    "\n",
    "## Teaching Notes & Tips\n",
    "\n",
    "### Timing Breakdown\n",
    "- **Section A (Setup)**: 5 min\n",
    "- **Section B (Decision Trees)**: 15 min (10 min explanation + 5 min exercise)\n",
    "- **Section C (Random Forest)**: 15 min (10 min voting + 5 min exercise)\n",
    "- **Section D (Feature Importance)**: 10 min\n",
    "- **Section E (Confusion Matrix)**: 15 min (10 min metrics + 5 min exercise)\n",
    "- **Section F (Quiz)**: 10 min\n",
    "- **Total**: 70 minutes\n",
    "\n",
    "### Common Student Questions\n",
    "\n",
    "1. **\"Why not just use one deep tree?\"**\n",
    "   - Single tree = high variance, unstable\n",
    "   - Ensemble averages out errors\n",
    "   - Show the visualization of individual trees vs. ensemble\n",
    "\n",
    "2. **\"How many trees is enough?\"**\n",
    "   - Typically 100-500\n",
    "   - Accuracy plateaus, but more trees never hurts (just slower)\n",
    "   - Use OOB error to monitor convergence\n",
    "\n",
    "3. **\"Can RF handle imbalanced classes?\"**\n",
    "   - Yes, but may bias toward majority class\n",
    "   - Use `class_weight='balanced'` parameter\n",
    "   - Or oversample minority class / undersample majority\n",
    "\n",
    "4. **\"RF vs. Neural Networks for EO?\"**\n",
    "   - **RF strengths**: Fast, interpretable, no scaling needed, works with small data\n",
    "   - **NN strengths**: Better with huge data, learns hierarchical features, handles spatial context\n",
    "   - **Practical**: Try RF first, then NN if needed\n",
    "\n",
    "5. **\"Why is my Urban class performing poorly?\"**\n",
    "   - Urban is heterogeneous (diverse spectral signatures)\n",
    "   - May need more training samples or sub-classes\n",
    "   - Consider texture features, not just spectral\n",
    "\n",
    "### Troubleshooting\n",
    "\n",
    "**If students have errors**:\n",
    "- Check sklearn version (needs >= 0.24)\n",
    "- Ensure random_state is set for reproducibility\n",
    "- Check for NaN values in data\n",
    "\n",
    "**If notebooks run slowly**:\n",
    "- Reduce n_samples in synthetic data\n",
    "- Reduce mesh grid resolution (200 → 100)\n",
    "- Use n_estimators=50 instead of 100\n",
    "\n",
    "### Extension Activities\n",
    "\n",
    "For advanced students:\n",
    "1. Implement cross-validation instead of single train/test split\n",
    "2. Compare RF with other algorithms (SVM, XGBoost)\n",
    "3. Experiment with class weights for imbalanced data\n",
    "4. Calculate and plot OOB error vs. number of trees\n",
    "5. Implement permutation importance (more robust than default)\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "1. Breiman, L. (2001). Random Forests. *Machine Learning*, 45(1), 5-32. [Foundational paper]\n",
    "2. Belgiu, M., & Drăguţ, L. (2016). Random forest in remote sensing: A review of applications and future directions. *ISPRS Journal of Photogrammetry and Remote Sensing*, 114, 24-31.\n",
    "3. Scikit-learn Documentation: [Random Forest Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "4. ESA Sentinel-2 User Handbook: [https://sentinels.copernicus.eu/documents/247904/685211/Sentinel-2_User_Handbook](https://sentinels.copernicus.eu/documents/247904/685211/Sentinel-2_User_Handbook)\n",
    "5. Louppe, G. (2014). Understanding Random Forests. *PhD Thesis, University of Liège*. [Excellent theoretical treatment]\n",
    "\n",
    "---\n",
    "\n",
    "**End of Instructor Version**\n",
    "\n",
    "*Developed for CopPhil 4-Day Advanced Online Training on AI/ML for Earth Observation*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

[
  {
    "objectID": "notebooks/Day1_Session3_Python_Geospatial_Data.html",
    "href": "notebooks/Day1_Session3_Python_Geospatial_Data.html",
    "title": "Notebook 1: Python Geospatial Data Handling (GeoPandas & Rasterio)",
    "section": "",
    "text": "Objective: Introduce participants to using Python for basic geospatial data manipulation – loading, inspecting, and visualizing vector and raster data – using libraries GeoPandas and Rasterio within Google Colab.\n\n!pip install geopandas rasterio\nfrom google.colab import drive\ndrive.mount('/content/drive')\nimport geopandas as gpd\ngdf = gpd.read_file('Philippines_Provinces.shp')\ngdf.head()\nprint(gdf.crs)\nprint(\"Number of provinces:\", len(gdf))\ngdf.plot(figsize=(6,6), column='Region', legend=True)\nimport matplotlib.pyplot as plt\nplt.title(\"Philippines Provinces by Region\")"
  },
  {
    "objectID": "notebooks/notebook2.html",
    "href": "notebooks/notebook2.html",
    "title": "Notebook 2: Google Earth Engine",
    "section": "",
    "text": "This notebook accompanies Session 4: Introduction to Google Earth Engine. You’ll learn to access, filter, and process massive satellite imagery collections using the Earth Engine Python API.\n\n\nBy completing this notebook, you will:\n\nAuthenticate and initialize Google Earth Engine\nAccess Sentinel-1 SAR and Sentinel-2 optical data\nFilter ImageCollections by location, date, and metadata\nApply cloud masking to optical imagery\nCreate temporal composites\nCalculate vegetation indices (NDVI)\nExport processed data for external use\nApply concepts to Philippine use cases"
  },
  {
    "objectID": "notebooks/notebook2.html#session-4-hands-on-notebook",
    "href": "notebooks/notebook2.html#session-4-hands-on-notebook",
    "title": "Notebook 2: Google Earth Engine",
    "section": "",
    "text": "This notebook accompanies Session 4: Introduction to Google Earth Engine. You’ll learn to access, filter, and process massive satellite imagery collections using the Earth Engine Python API.\n\n\nBy completing this notebook, you will:\n\nAuthenticate and initialize Google Earth Engine\nAccess Sentinel-1 SAR and Sentinel-2 optical data\nFilter ImageCollections by location, date, and metadata\nApply cloud masking to optical imagery\nCreate temporal composites\nCalculate vegetation indices (NDVI)\nExport processed data for external use\nApply concepts to Philippine use cases"
  },
  {
    "objectID": "notebooks/notebook2.html#getting-started",
    "href": "notebooks/notebook2.html#getting-started",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Getting Started",
    "text": "Getting Started\n\nOption 1: Open in Google Colab (Required for Earth Engine)\nClick the button below to open this notebook in Google Colab:\n\n\n\n\nOpen In Colab\n\n\n\n\n\n\n\n\n\nImportantEarth Engine Account Required\n\n\n\nYou must have a registered Google Earth Engine account to run this notebook. If you haven’t registered yet, see the Setup Guide.\nRegistration takes 24-48 hours for approval.\n\n\nAdvantages of Colab: - Direct Earth Engine integration - No data downloads required - Cloud processing power - Interactive mapping with geemap\n\n\nOption 2: Download Notebook\nDownload the Jupyter notebook:\n\nDownload .ipynb File\nRequirements: - Google Earth Engine account - Authenticated credentials\npip install earthengine-api geemap folium"
  },
  {
    "objectID": "notebooks/notebook2.html#notebook-preview",
    "href": "notebooks/notebook2.html#notebook-preview",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Notebook Preview",
    "text": "Notebook Preview\n\n\n\n\n\n\nNoteCloud Platform Access Required\n\n\n\nThis notebook requires an active internet connection and Google Earth Engine account. All processing happens in Google’s cloud infrastructure.\n\n\n\nTopics Covered\n\nEarth Engine Fundamentals\n\nAuthentication and initialization\nUnderstanding ee.Image and ee.ImageCollection\nGeometry definitions (points, polygons, rectangles)\nUnderstanding the Earth Engine data catalog\n\nAccessing Sentinel Data\n\nSentinel-2 optical imagery (COPERNICUS/S2_SR_HARMONIZED)\nSentinel-1 SAR imagery (COPERNICUS/S1_GRD)\nUnderstanding collection IDs and band names\nExploring metadata\n\nFiltering ImageCollections\n\nSpatial filtering (filterBounds)\nTemporal filtering (filterDate)\nMetadata filtering (cloud cover, orbit direction)\nCombining multiple filters\n\nCloud Masking & Compositing\n\nUsing the QA60 band for cloud detection\nBitwise operations for mask creation\nCreating median composites\nQuality mosaicking\n\nSpectral Indices\n\nNDVI (Normalized Difference Vegetation Index)\nNDWI (Normalized Difference Water Index)\nBand math operations\nVisualization parameters\n\nPhilippine Case Studies\n\nMetro Manila monitoring with Sentinel-2\nPalawan land cover analysis\nFlood detection with Sentinel-1\nAgricultural monitoring in Central Luzon\n\nData Export\n\nExporting to Google Drive\nExporting to Earth Engine Assets\nSetting scale and region parameters\nManaging export tasks"
  },
  {
    "objectID": "notebooks/notebook2.html#prerequisites",
    "href": "notebooks/notebook2.html#prerequisites",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore starting this notebook, ensure you have:\n\n✅ Google Earth Engine account (registered and approved)\n✅ Completed Setup Guide\n✅ Understanding of Session 4 concepts\n✅ Basic Python knowledge\n✅ Familiarity with Jupyter/Colab"
  },
  {
    "objectID": "notebooks/notebook2.html#notebook-contents",
    "href": "notebooks/notebook2.html#notebook-contents",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Notebook Contents",
    "text": "Notebook Contents\nThe full interactive notebook includes:\n\n20+ code cells with step-by-step instructions\n15+ visualizations including interactive maps\n4 Philippine case studies with real-world applications\nExport workflows for downloading processed data\nTroubleshooting section for common errors\nExercises to reinforce learning"
  },
  {
    "objectID": "notebooks/notebook2.html#key-concepts-covered",
    "href": "notebooks/notebook2.html#key-concepts-covered",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Key Concepts Covered",
    "text": "Key Concepts Covered\n\nEarth Engine Architecture\n# Basic Earth Engine workflow\nimport ee\nee.Initialize()\n\n# Define area of interest\nphilippines = ee.Geometry.Rectangle([116.0, 4.0, 127.0, 21.0])\n\n# Access Sentinel-2 collection\ncollection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterBounds(philippines) \\\n    .filterDate('2024-01-01', '2024-12-31') \\\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n\n# Create composite\ncomposite = collection.median()\n\n# Calculate NDVI\nndvi = composite.normalizedDifference(['B8', 'B4'])\n\n\nInteractive Mapping with geemap\nimport geemap\n\n# Create interactive map\nMap = geemap.Map()\nMap.centerObject(philippines, 6)\n\n# Add layers\nMap.addLayer(composite, {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 3000}, 'True Color')\nMap.addLayer(ndvi, {'min': 0, 'max': 1, 'palette': ['red', 'yellow', 'green']}, 'NDVI')\n\nMap"
  },
  {
    "objectID": "notebooks/notebook2.html#philippine-use-cases",
    "href": "notebooks/notebook2.html#philippine-use-cases",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Philippine Use Cases",
    "text": "Philippine Use Cases\n\nCase Study 1: Metro Manila Urban Monitoring\nTrack urban expansion and changes in the National Capital Region using multi-temporal Sentinel-2 data.\n\n\nCase Study 2: Palawan Forest Cover\nMonitor forest cover and detect deforestation in Palawan Province using NDVI time series.\n\n\nCase Study 3: Central Luzon Flood Mapping\nDetect flood extents using Sentinel-1 SAR backscatter changes before and after typhoon events.\n\n\nCase Study 4: Mindanao Agricultural Drought\nAssess agricultural drought impacts using vegetation indices and SWIR bands."
  },
  {
    "objectID": "notebooks/notebook2.html#common-errors-solutions",
    "href": "notebooks/notebook2.html#common-errors-solutions",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Common Errors & Solutions",
    "text": "Common Errors & Solutions\n\nError: “Please set project ID”\nCause: Earth Engine not authenticated\nSolution:\nee.Authenticate()  # Follow prompts\nee.Initialize()\n\n\nError: “User memory limit exceeded”\nSolution: Reduce spatial or temporal scope, increase scale parameter\n\n\nError: “Too many concurrent aggregations”\nSolution: Add .limit() to reduce collection size\nSee the FAQ for more troubleshooting help."
  },
  {
    "objectID": "notebooks/notebook2.html#support",
    "href": "notebooks/notebook2.html#support",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Support",
    "text": "Support\n\nDuring the Training\n\nAsk questions in live session\nConsult teaching assistants\nShare your results with the group\n\n\n\nAfter the Training\n\nReview Earth Engine Cheat Sheet\nCheck FAQ\nJoin GEE Community Forum"
  },
  {
    "objectID": "notebooks/notebook2.html#related-resources",
    "href": "notebooks/notebook2.html#related-resources",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Related Resources",
    "text": "Related Resources\n\nSession Materials: - Session 4: Introduction to Google Earth Engine - Session 4 Presentation Slides\nQuick References: - Earth Engine Python API Cheat Sheet - Sentinel Missions Reference\nOfficial Documentation: - Earth Engine Python API Guide - Earth Engine Data Catalog - geemap Documentation\nCommunity Resources: - Awesome Earth Engine - Earth Engine Tutorials"
  },
  {
    "objectID": "notebooks/notebook2.html#next-steps",
    "href": "notebooks/notebook2.html#next-steps",
    "title": "Notebook 2: Google Earth Engine",
    "section": "Next Steps",
    "text": "Next Steps\nAfter completing this notebook:\n\n✅ Practice with different Philippine regions\n✅ Experiment with other satellites (Landsat, MODIS)\n✅ Prepare for Day 2: Machine Learning for Land Cover Classification\n✅ Export data for your own projects\n\n\n\n\n\nPrevious\n\n\n← Notebook 1: Python Geospatial\n\n\n\n\nBack\n\n\nSession 4 Overview →\n\n\n\n\n\n\n\n\n\n\nTipReady to Explore Petabytes of Data?\n\n\n\nOpen the notebook in Colab and start accessing the entire Sentinel archive from your browser!\n\n\nAll processing happens in the cloud - no downloads required!"
  },
  {
    "objectID": "sessions/session1.html",
    "href": "sessions/session1.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\n\nLearning Objectives\nBy the end of this session, you will be able to:\n\nDescribe the Copernicus program and its goals in the Philippines.\nDifferentiate between Sentinel-1 and Sentinel-2 missions and their key characteristics.\nIdentify key Philippine agencies and platforms for Earth observation data.\nExplain how local and international EO data can be used together.\n\n\n\n1.1. Lecture Materials\nIntroduction to Copernicus in the Philippines: The Copernicus Capacity Support Programme for the Philippines (CopPhil) is a flagship initiative under the EU’s Global Gateway. It aims to increase the uptake of free and open Copernicus Earth observation data in the Philippines, strengthening the country’s ability to address disaster risk reduction (DRR), climate change adaptation (CCA), and natural resource management (NRM). This involves establishing a local Copernicus data mirror site and co-developing pilot services, in partnership with the Philippine Space Agency (PhilSA) and DOST (Department of Science and Technology). Slide content: Key points should include the EU-Philippines space cooperation context, CopPhil goals (DRR, CCA, NRM), and the roles of PhilSA and DOST in the programme.\nCopernicus Sentinel-1 & Sentinel-2 Overview: Sentinel-1 and Sentinel-2 are core satellites of the EU Copernicus program, providing free high-resolution imagery. Sentinel-1 is a radar (SAR) mission with C-band synthetic aperture radar enabling all-weather, day/night imaging. With two satellites (1A & 1B, now 1C) orbiting 180° apart, Sentinel-1 achieves a ~6-day revisit cycle globally. In its common Interferometric Wide (IW) swath mode, Sentinel-1 has ~5 m by 20 m spatial resolution (range × azimuth) and a 250 km swath. It provides dual-polarization data (VV+VH or HH+HV) useful for mapping floods, land deformation (InSAR), forest biomass, and maritime surveillance. Typical products are Level-1 GRD (Ground Range Detected) images (multi-look intensity) and SLC (Single Look Complex) images, which are all openly accessible. Sentinel-2 is an optical mission carrying a MultiSpectral Instrument (MSI) with 13 spectral bands (visible, near-infrared, and shortwave-infrared) at 10 m, 20 m, and 60 m resolutions. Twin satellites (2A & 2B) in sun-synchronous orbit provide a 5-day revisit for any location. Each Sentinel-2 scene covers a 100×100 km tile. Important band characteristics: 10 m for RGB and NIR bands, 20 m for red-edge and SWIR bands, 60 m for atmospheric bands. Slides should list Sentinel-2’s Level-1C (Top-of-Atmosphere) and Level-2A (Surface Reflectance) products, and Sentinel-1’s Level-1 GRD and SLC products, along with data access methods (the new Copernicus Data Space Ecosystem replacing the legacy Open Access Hub, and platforms like Google Earth Engine). Slide content: comparisons of Sentinel-1 vs Sentinel-2 (sensor type, spectral bands, spatial/temporal resolution, example uses). Mention that Sentinel data can be retrieved via Copernicus hubs (now the Data Space Ecosystem) or via cloud platforms and APIs (e.g., ASF for Sentinel-1, and GEE).\nExample Sentinel-2 imagery of Mayon Volcano in the Philippines (false-color composite highlighting the 2018 lava flows). Sentinel-2 provides multi-spectral optical data at 10–60 m resolution across 13 bands. With a 5-day revisit, it supports monitoring of dynamic environmental events. (Contains modified Copernicus Sentinel data [2018] processed by Pierre Markuse[1])\nPhilippine EO Data Ecosystem: The Philippines has its own geospatial data platforms that complement Copernicus data. Slides should introduce the key agencies and tools:\n\nPhilSA Space Data Dashboard (Space+ SDD): PhilSA’s online platform for satellite data access and visualization, built with open-source tools (TerriaJS, OpenDataCube, etc.). It provides government and citizens with easy access to satellite-derived datasets, including direct downloads of imagery for uses in disaster management, urban planning, and environmental monitoring. Include: a note that SDD democratizes EO data access in the country, aligning with sustainable development goals.\nNAMRIA Geoportal: Managed by the National Mapping and Resource Information Authority, this geoportal provides national basemaps, topographic maps, land cover data, and hazard maps. It allows users to view and download layers like the official 1:50k base maps, administrative boundaries, and thematic maps (e.g., 2020 land cover) for the Philippines. Emphasize its role in DRR (hazard map access) and in providing authoritative geospatial data.\nDOST-ASTI Projects: The Advanced Science and Technology Institute of DOST leads several EO and AI initiatives:\nDATOS (Remote Sensing and Data Science Help Desk): A project applying AI, machine learning, GIS and remote sensing for disaster mapping and other applications. For example, DATOS developed methods to automatically map floods from satellite images and to identify crops (like mapping sugarcane via temporal radar signatures). It essentially serves as a rapid analytics service during disasters.\nSkAI-Pinas (Sky Artificial Intelligence Program): A DOST flagship R&D program to democratize AI in the Philippines by building AI capacity in remote sensing. It focuses on making AI “part of daily decision-making and national progress”. SkAI-Pinas supports the development of AI models and tools, including DIMER (Democratized Intelligent Model Exchange Repository) – a repository for sharing pre-trained AI models, and AIPI (AI Processing Interface) – a platform to streamline large-scale AI processing of geospatial data. These tools enable Filipino researchers and agencies to apply AI without needing big compute resources, by reusing models and an accessible processing interface.\nPhilippine Earth Data Resource Observation (PEDRO) Center: (Related infrastructure, not in bullet but may be worth noting) – DOST-ASTI’s satellite ground receiving station that acquires Diwata microsatellite data and other imagery, contributing local high-resolution data.\nPAGASA and Other Data Sources: The national meteorological agency PAGASA provides climate and weather data (e.g., typhoon tracks, rainfall) that can be integrated with satellite data for climate adaptation analysis. Also mention that the CopPhil program is setting up a Copernicus Mirror Site in-country to locally host Sentinel data for faster access, ensuring sustainable data availability for Philippine users.\n\nSlide content: a diagram or list of the Philippine EO ecosystem, showing how PhilSA, NAMRIA, DOST-ASTI (DATOS, SkAI-Pinas, DIMER, AIPI), and PAGASA contribute data or tools. Highlight that these local datasets (e.g. national base maps, hazard maps, local AI models) complement Sentinel imagery to create richer insights. For example, during a flood event, Sentinel-1 SAR can detect water extent, while NAMRIA flood hazard maps and PAGASA rain gauges provide context – together supporting better DRR decisions.",
    "crumbs": [
      "Home",
      "Training Sessions",
      "Learning Objectives"
    ]
  },
  {
    "objectID": "sessions/session3.html",
    "href": "sessions/session3.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\n\nLearning Objectives\nBy the end of this session, you will be able to:\n\nLoad, inspect, and visualize vector and raster data in Python using GeoPandas and Rasterio.\nPerform basic data manipulation tasks, such as filtering and cropping.\nCreate a simple map with overlaid vector and raster data.\n\n\n\n3.1. Hands-on Google Colab Notebooks\nTo reinforce the lectures, Day 1 includes two interactive Colab notebooks that participants will run:\n\nNotebook 1: Python Geospatial Data Handling (GeoPandas & Rasterio)\nObjective: Introduce participants to using Python for basic geospatial data manipulation – loading, inspecting, and visualizing vector and raster data – using libraries GeoPandas and Rasterio within Google Colab.\nContents & Steps:\n\nEnvironment Setup: The notebook begins with installing required libraries (e.g., geopandas, rasterio, maybe matplotlib for plotting). It also shows how to mount Google Drive. For example, a code cell:\n\n\n\n!pip install geopandas rasterio from google.colab import drive drive.mount(‘/content/drive’)\nThis ensures participants have the tools and data access. The notebook then navigates (if needed) to the data directory (e.g., a shared Drive folder containing sample data).\n\n\n\nLoading Vector Data with GeoPandas: The first data example is a Philippine administrative boundaries shapefile (small enough to handle, e.g., boundaries of regions or provinces). The notebook demonstrates:\n\n\n\nimport geopandas as gpd gdf = gpd.read_file(‘Philippines_Provinces.shp’) gdf.head() print(gdf.crs) print(“Number of provinces:”, len(gdf))\nThis will output a table of the first few features and the coordinate reference system. Participants see that GeoPandas stores geometry and attributes. The notebook then instructs plotting:\ngdf.plot(figsize=(6,6), column='Region', legend=True)\nplt.title(\"Philippines Provinces by Region\")\nThis produces a colored map of provinces by region. The notebook explains how the column parameter was used to color by an attribute, and how GeoPandas auto-selects a color map and adds a legend.\n\nExercise: The notebook might include a small exercise for learners, like “Try changing the column to 'Island_Group' or adjust the cmap.” This encourages interactivity.\n\nGeoDataFrame Operations: Next, the notebook shows how to filter spatial data. For example:\n\n\n\nmindanao = gdf[gdf[‘Island_Group’]==“Mindanao”] mindanao.plot(figsize=(5,5), color=‘orange’) plt.title(“Mindanao Island Group Provinces”)\nAnd similarly, how to get a single province geometry:\ndavao = gdf[gdf['Province']==\"Davao del Sur\"]\nprint(davao.geometry.iloc[0])  # Print the polygon coordinates\nIt might print a Polygon or MultiPolygon coordinates. The explanation emphasizes that we can treat the GeoDataFrame like a pandas DataFrame for filtering, and access geometries via the .geometry column or each row’s geometry attribute.\n\n\n\nLoading Raster Data with Rasterio: The notebook then moves to raster. It uses a Sentinel-2 image tile (or subset) covering a sample AOI in the Philippines (kept small, e.g., a 100 km² area, to reduce file size, perhaps stored as a Cloud-Optimized GeoTIFF or a pre-cropped TIFF). Example:\n\n\n\nimport rasterio src = rasterio.open(‘sample_S2.tif’) print(src.crs, src.width, src.height, src.count, src.transform)\nThis displays the projection (e.g., EPSG:32651 for UTM zone if in Philippines), raster dimensions, number of bands, and affine transform. Then:\nband1 = src.read(1)\nprint(band1.shape, band1.dtype, band1.min(), band1.max())\nThis reads the first band (say Blue band) as a numpy array and prints shape and value range. The notebook explains that read(1) gives band 1; if the image has 3 bands, read(3) might be SWIR in Sentinel-2, etc.\n\nVisualization: To plot a single band:\nimport matplotlib.pyplot as plt\nplt.imshow(band1, cmap='gray')\nplt.colorbar(label='Reflectance')\nplt.title(\"Sentinel-2 Band1 (Coastal Aerosol)\")\nOr to plot an RGB:\nrgb = np.dstack([src.read(4), src.read(3), src.read(2)])  # B4,B3,B2 = RGB\nplt.imshow(np.clip(rgb * 0.0001, 0, 1))  # assuming reflectances in 0-10000 scale, scale to 0-1\nplt.title(\"True-color Composite\")\nThe notebook would clarify any scaling applied (Sentinel-2 L2A DN values need scaling by 1e-4, etc.). The output image should show a reasonably colored patch of land.\n\nSpatial Referencing and Plot Overlays: Show how to overlay vector boundaries on the raster for context. Since matplotlib can plot both, example:\n\n\n\nfig, ax = plt.subplots() plt.imshow(np.clip(rgb * 0.0001, 0, 1), extent=src.bounds, origin=‘upper’) mindanao.boundary.plot(ax=ax, edgecolor=‘yellow’) # plot outlines of Mindanao provinces plt.title(“Sentinel-2 with province boundaries”)\nThe extent=src.bounds and origin='upper' ensure the image is placed in correct coordinates. This illustrates combining data sources.\n\n\n\nRaster Cropping and Masking: The notebook then demonstrates cropping the raster to a vector AOI using rasterio’s mask:\n\n\n\nfrom rasterio.mask import mask geom = davao.geometry.iloc[0] # polygon of Davao del Sur out_image, out_transform = mask(src, [geom], crop=True) print(out_image.shape) # should be (bands, new_height, new_width)\nNow out_image contains the pixel values just for that province. They can plot this subset similarly. The notebook notes that mask sets values outside the polygon to nodata and returns a smaller window covering the polygon. It also likely retrieves src.meta and updates it for the new transform and dimensions if it were to save the cropped image:\nout_meta = src.meta.copy()\nout_meta.update({\"height\": out_image.shape[1],\n                 \"width\": out_image.shape[2],\n                 \"transform\": out_transform})\nrasterio.open('davao.tif', 'w', **out_meta).write(out_image)\n(Though writing to file in Colab is optional, it shows how to save results.)\n\n\n\nBasic Raster Calculation: If time/space permits, include a simple calculation, e.g., compute NDVI from bands:\n\n\n\nnir = src.read(8) # Band 8 is NIR for Sentinel-2 red = src.read(4) # Band 4 is Red ndvi = (nir.astype(float) - red.astype(float)) / (nir + red) plt.imshow(ndvi, cmap=‘RdYlGn’) plt.colorbar(label=‘NDVI’)\nShow an NDVI image where green indicates vegetation. This ties back to AI – using band math to create features.\n\nThroughout Notebook 1, markdown cells explain what each step is doing and why. The tone is tutorial-like: assume the user is following along and encourage them to inspect outputs. By the end, they have performed end-to-end steps: from reading raw data to making a simple map or analysis, all within Python.",
    "crumbs": [
      "Home",
      "Training Sessions",
      "Learning Objectives"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Day 1",
    "section": "",
    "text": "Advanced training for Philippine EO professionals on AI/ML applications for Disaster Risk Reduction, Climate Change Adaptation, and Natural Resource Management",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#about-this-training",
    "href": "index.html#about-this-training",
    "title": "Welcome to Day 1",
    "section": "About This Training",
    "text": "About This Training\nWelcome to Day 1 of the 4-Day Advanced Online Training on AI/ML for Earth Observation for Philippine EO Professionals. This training is part of the CopPhil Programme (EU-Philippines Copernicus Capacity Support Programme), a flagship initiative under the European Union’s Global Gateway strategy.\n\n\n\n\n\n\nNoteTraining Context\n\n\n\nThis course strengthens the Philippines’ capacity to use Copernicus Earth Observation data for:\n\nDisaster Risk Reduction (DRR) - Flood mapping, typhoon monitoring, landslide assessment\nClimate Change Adaptation (CCA) - Drought monitoring, agricultural resilience, coastal changes\nNatural Resource Management (NRM) - Forest monitoring, land cover mapping, marine resources",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#day-1-overview",
    "href": "index.html#day-1-overview",
    "title": "Welcome to Day 1",
    "section": "Day 1 Overview",
    "text": "Day 1 Overview\nDay 1 provides the foundation for your AI/ML journey in Earth Observation. By the end of today, you will:\n\nUnderstand the Copernicus Sentinel missions and 2025 updates (Sentinel-2C, Sentinel-1C)\nNavigate the Philippine EO ecosystem (PhilSA, NAMRIA, DOST-ASTI)\nGrasp core AI/ML concepts and workflows for EO applications\nHandle geospatial data with Python (GeoPandas, Rasterio)\nAccess and preprocess satellite data using Google Earth Engine\n\n\nToday’s Schedule (8 hours)\n\n\n\n1\n\n\nCopernicus & PH EO 2 hours\n\n\n\n\n2\n\n\nAI/ML Fundamentals 2 hours\n\n\n\n\n3\n\n\nPython Geospatial 2 hours\n\n\n\n\n4\n\n\nGoogle Earth Engine 2 hours",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#training-sessions",
    "href": "index.html#training-sessions",
    "title": "Welcome to Day 1",
    "section": "Training Sessions",
    "text": "Training Sessions\n\n\nSession 1\nCopernicus Sentinel Data & Philippine EO Ecosystem\n\nSentinel-1 SAR\n\n\nSentinel-2 Optical\n\nLearn about Europe’s flagship EO program and the Philippine agencies advancing EO in the country.\nGo to Session 1\n\n\nSession 2\nCore Concepts of AI/ML for Earth Observation\nDemystify AI/ML workflows, supervised vs unsupervised learning, neural networks, and data-centric approaches.\nGo to Session 2\n\n\nSession 3\nHands-on Python for Geospatial Data\nMaster vector data with GeoPandas and raster data with Rasterio - the foundations of EO data processing.\nGo to Session 3\n\n\nSession 4\nIntroduction to Google Earth Engine\nLeverage cloud computing power to access, filter, and preprocess petabytes of Earth observation data.\nGo to Session 4",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#learning-objectives",
    "href": "index.html#learning-objectives",
    "title": "Welcome to Day 1",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nBy the end of Day 1, you will be able to:\n\nKey Learning Outcomes\n\nIdentify the characteristics and applications of Sentinel-1 and Sentinel-2 missions\nNavigate Philippine EO platforms including PhilSA SIYASAT, NAMRIA Geoportal, and DOST-ASTI tools\nExplain the AI/ML workflow for Earth Observation applications\nDistinguish between supervised and unsupervised learning with EO examples\nUnderstand neural network fundamentals and data-centric AI principles\nLoad and visualize vector data using GeoPandas\nRead and process raster imagery using Rasterio\nQuery and filter satellite imagery collections in Google Earth Engine\nApply cloud masking and create temporal composites\nExport processed EO data for AI/ML workflows",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#prerequisites",
    "href": "index.html#prerequisites",
    "title": "Welcome to Day 1",
    "section": "Prerequisites",
    "text": "Prerequisites\n\nWhat You Need\nBefore starting Day 1:\n\nGoogle account (for Colab and Earth Engine)\nGoogle Earth Engine account (sign up at earthengine.google.com)\nBasic Python knowledge (variables, loops, functions)\nFamiliarity with remote sensing concepts (helpful but not required)\n\nTechnical Setup:\nAll exercises run in Google Colaboratory - no local installation required! See our Setup Guide for detailed instructions.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#updates-highlighted",
    "href": "index.html#updates-highlighted",
    "title": "Welcome to Day 1",
    "section": "2025 Updates Highlighted",
    "text": "2025 Updates Highlighted\nThis training incorporates the latest 2025 developments in Earth Observation and AI:\n\nSentinel-2C operational (January 2025) - Three-satellite constellation with 5-day revisit\nSentinel-1C active - Restored dual-satellite SAR coverage\nCopernicus Data Space Ecosystem - New data access platform with SentiBoard dashboard\nPhilSA SIYASAT portal - Secure data archive for NovaSAR-1 and maritime monitoring\nDOST P2.6B AI investment (until 2028) - SkAI-Pinas, DIMER, AIPI platforms\nESA Φsat-2 mission - On-board AI processing demonstration\nNASA-IBM Geospatial Foundation Model - Open-source pre-trained model for EO\nData-centric AI paradigm - Emphasis on data quality over model complexity",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#quick-links",
    "href": "index.html#quick-links",
    "title": "Welcome to Day 1",
    "section": "Quick Links",
    "text": "Quick Links\n\nSetup Guide Philippine EO Resources Download Materials FAQ Glossary",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#copphil-programme",
    "href": "index.html#copphil-programme",
    "title": "Welcome to Day 1",
    "section": "CopPhil Programme",
    "text": "CopPhil Programme\n\n\n\n\n\n\nTipAbout CopPhil\n\n\n\nThe Technical Assistance for the Philippines’ Copernicus Capacity Support Programme (CopPhil) is part of the EU-Philippines cooperation programme and the EU’s Global Gateway strategy.\nKey Partners:\n\nPhilippine Space Agency (PhilSA) - Co-chair and space data authority\nDepartment of Science and Technology (DOST) - Co-chair and technology advancement\nEuropean Union - Funding and technical cooperation\nEuropean Space Agency (ESA) - Copernicus programme expertise\n\nObjectives:\n\nEstablish Copernicus Mirror Site in the Philippines\nBuild capacity in EO data analysis and AI/ML applications\nCo-develop pilot services for DRR, CCA, and NRM\nCreate sustainable Digital Space Campus for continued learning",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#need-help",
    "href": "index.html#need-help",
    "title": "Welcome to Day 1",
    "section": "Need Help?",
    "text": "Need Help?\nThroughout the training, you can:\n\nAsk questions in the live session\nConsult the FAQ for common issues\nCheck the Glossary for term definitions\nDownload Cheat Sheets for quick reference\nAccess the Philippine EO Resources directory\n\n\n\n\n\n\n\nImportantTechnical Support\n\n\n\nFor technical issues during the training:\n\nGoogle Colab issues: Check Setup Guide\nData access problems: See session-specific troubleshooting sections\nGeneral questions: Contact your instructors or teaching assistants",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "index.html#ready-to-begin",
    "href": "index.html#ready-to-begin",
    "title": "Welcome to Day 1",
    "section": "Ready to Begin?",
    "text": "Ready to Begin?\n\n\n\nFirst Step\n\n\nComplete Setup Guide →\n\n\n\n\nNext Session\n\n\nSession 1: Copernicus & Philippine EO →\n\n\n\n\nThis training is funded by the European Union under the Global Gateway initiative and delivered in partnership with the Philippine Space Agency (PhilSA) and the Department of Science and Technology (DOST).",
    "crumbs": [
      "Home",
      "Getting Started",
      "Welcome to Day 1"
    ]
  },
  {
    "objectID": "resources/setup.html",
    "href": "resources/setup.html",
    "title": "Setup Guide",
    "section": "",
    "text": "This guide will help you set up everything you need for the CopPhil EO AI/ML Training. All exercises run in Google Colaboratory, so you won’t need to install Python or libraries on your local machine.\n\n\n\n\n\n\nNoteTime Required\n\n\n\nAllow 15-20 minutes to complete all setup steps before Day 1 begins.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#welcome",
    "href": "resources/setup.html#welcome",
    "title": "Setup Guide",
    "section": "",
    "text": "This guide will help you set up everything you need for the CopPhil EO AI/ML Training. All exercises run in Google Colaboratory, so you won’t need to install Python or libraries on your local machine.\n\n\n\n\n\n\nNoteTime Required\n\n\n\nAllow 15-20 minutes to complete all setup steps before Day 1 begins.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#prerequisites-checklist",
    "href": "resources/setup.html#prerequisites-checklist",
    "title": "Setup Guide",
    "section": "Prerequisites Checklist",
    "text": "Prerequisites Checklist\nBefore starting the training, ensure you have:\n\n\nA Google account (Gmail)\nGoogle Earth Engine access (registration required)\nStable internet connection (minimum 5 Mbps recommended)\nModern web browser (Chrome, Firefox, Safari, or Edge)\nHeadphones/speakers for audio",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-1-google-account-setup",
    "href": "resources/setup.html#step-1-google-account-setup",
    "title": "Setup Guide",
    "section": "Step 1: Google Account Setup",
    "text": "Step 1: Google Account Setup\n\n1.1 Create or Verify Google Account\nYou need a Google account to access Google Colaboratory and Google Earth Engine.\n\n\n\n\n\n\nTipAlready Have Gmail?\n\n\n\nIf you have a Gmail account, you’re all set! Skip to Step 2.\n\n\nTo create a new account:\n\nGo to accounts.google.com\nClick “Create account”\nFollow the registration process\nVerify your email address",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-2-google-colaboratory-setup",
    "href": "resources/setup.html#step-2-google-colaboratory-setup",
    "title": "Setup Guide",
    "section": "Step 2: Google Colaboratory Setup",
    "text": "Step 2: Google Colaboratory Setup\n\n2.1 What is Google Colab?\nGoogle Colaboratory (Colab) is a free cloud service that lets you write and execute Python code in your browser. It provides:\n\nFree access to GPUs (Graphics Processing Units)\nPre-installed Python libraries (NumPy, Pandas, Matplotlib, etc.)\nCloud storage integration with Google Drive\nShareable notebooks\n\n\n\n2.2 Access Google Colab\n\nGo to colab.research.google.com\nSign in with your Google account\nYou’ll see the welcome screen with example notebooks\n\n\n\n2.3 Test Your Colab Setup\nLet’s verify everything works:\n\nCreate a new notebook:\n\nClick “File” → “New notebook”\nA new notebook opens with an empty code cell\n\nRun a test:\n\nCopy and paste this code into the first cell:\n\nimport sys\nprint(f\"Python version: {sys.version}\")\nprint(\"Google Colab is working!\")\n\nPress Shift + Enter to run the cell\nYou should see the Python version and success message\n\nTest package installation:\n# Test common geospatial packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nprint(\"✓ NumPy:\", np.__version__)\nprint(\"✓ Pandas:\", pd.__version__)\nprint(\"✓ Matplotlib:\", plt.matplotlib.__version__)\n\n\n\n\n\n\n\nWarningFirst Run Takes Longer\n\n\n\nThe first time you run code in a new Colab session, it may take 30-60 seconds to allocate resources. This is normal.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-3-google-earth-engine-registration",
    "href": "resources/setup.html#step-3-google-earth-engine-registration",
    "title": "Setup Guide",
    "section": "Step 3: Google Earth Engine Registration",
    "text": "Step 3: Google Earth Engine Registration\n\n3.1 What is Google Earth Engine?\nGoogle Earth Engine (GEE) is a cloud platform for planetary-scale geospatial analysis. It provides:\n\nAccess to petabytes of satellite imagery (Landsat, Sentinel, MODIS, etc.)\nCloud-based processing (no downloads needed)\nPython and JavaScript APIs\nFast analysis over large areas and time periods\n\n\n\n3.2 Register for Earth Engine\n\n\n\n\n\n\nImportantRegistration Required\n\n\n\nEarth Engine registration can take 24-48 hours for approval. Register well before the training starts!\n\n\nRegistration steps:\n\nGo to: earthengine.google.com\nClick “Get Started” or “Sign Up”\nSign in with your Google account\nChoose account type:\n\nSelect “Register a Noncommercial or Commercial Cloud project”\nFor this training, select “Noncommercial” if applicable\n\nComplete the registration form:\n\nProject type: Education/Research\nOrganization: Your institution (e.g., “DOST-ASTI”, “NAMRIA”, “University of the Philippines”)\nProject description: “CopPhil EO AI/ML Training - Earth Observation data analysis for DRR/CCA/NRM applications”\nIntended use: Describe your interest in using EO data\n\nSubmit and wait for approval\n\nYou’ll receive an email when approved (usually within 24-48 hours)\nCheck your spam folder if you don’t see the approval email\n\n\n\n\n3.3 Verify Earth Engine Access\nOnce approved, test your access:\n\nOpen Google Colab: colab.research.google.com\nCreate a new notebook\nAuthenticate Earth Engine:\n\n# Install Earth Engine API (if needed)\n!pip install earthengine-api --quiet\n\n# Import and authenticate\nimport ee\n\n# Authenticate (first time only)\nee.Authenticate()\n\n# Initialize Earth Engine\nee.Initialize()\n\n# Test: Get an image\nimage = ee.Image('COPERNICUS/S2/20230101T000000_20230101T000000_T48PYS')\nprint(\"✓ Earth Engine is working!\")\nprint(f\"Image ID: {image.id().getInfo()}\")\n\nFollow authentication prompts:\n\nClick the link that appears\nSign in with your Google account\nCopy the authorization code\nPaste it back into Colab\n\n\n\n\n\n\n\n\nTipAuthentication Only Once\n\n\n\nAfter the first authentication, Earth Engine will remember your credentials in future Colab sessions.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-4-install-geospatial-python-packages",
    "href": "resources/setup.html#step-4-install-geospatial-python-packages",
    "title": "Setup Guide",
    "section": "Step 4: Install Geospatial Python Packages",
    "text": "Step 4: Install Geospatial Python Packages\nIn Google Colab, most packages are pre-installed. For specialized geospatial libraries, we’ll install them when needed.\n\nCommon packages we’ll use:\n\n\n\nPackage\nPurpose\nPre-installed?\n\n\n\n\nnumpy\nNumerical computing\nYes ✓\n\n\npandas\nData manipulation\nYes ✓\n\n\nmatplotlib\nVisualization\nYes ✓\n\n\ngeopandas\nVector data\nNo (we’ll install)\n\n\nrasterio\nRaster data\nNo (we’ll install)\n\n\nearthengine-api\nGoogle Earth Engine\nNo (we’ll install)\n\n\nfolium\nInteractive maps\nYes ✓\n\n\n\n\n\nInstallation template for notebooks:\nEach training notebook will include installation cells like this:\n# Install geospatial packages\n!pip install geopandas rasterio earthengine-api --quiet\n\n# Import packages\nimport geopandas as gpd\nimport rasterio\nimport ee\n\nprint(\"✓ All packages installed successfully!\")",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-5-google-drive-integration-optional",
    "href": "resources/setup.html#step-5-google-drive-integration-optional",
    "title": "Setup Guide",
    "section": "Step 5: Google Drive Integration (Optional)",
    "text": "Step 5: Google Drive Integration (Optional)\nTo save your work and access datasets, you can mount Google Drive in Colab:\nfrom google.colab import drive\ndrive.mount('/content/drive')\nBenefits: - Save notebooks directly to Drive - Access datasets stored in Drive - Work persists between sessions\n\n\n\n\n\n\nNoteStorage Limits\n\n\n\nFree Google accounts get 15 GB of Drive storage. For large datasets, we’ll stream data directly from Earth Engine instead.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#step-6-download-training-notebooks",
    "href": "resources/setup.html#step-6-download-training-notebooks",
    "title": "Setup Guide",
    "section": "Step 6: Download Training Notebooks",
    "text": "Step 6: Download Training Notebooks\nAll training notebooks will be provided during the sessions. You can:\n\nAccess via shared links (provided by instructors)\nDownload from the training portal (see Downloads)\nClone from GitHub (if repository is available)",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#troubleshooting-common-issues",
    "href": "resources/setup.html#troubleshooting-common-issues",
    "title": "Setup Guide",
    "section": "Troubleshooting Common Issues",
    "text": "Troubleshooting Common Issues\n\nIssue 1: “Runtime disconnected” in Colab\nCause: Colab sessions timeout after 90 minutes of inactivity (12 hours maximum)\nSolution: - Reconnect by clicking “Reconnect” button - Re-run setup cells (imports, authentication) - Consider using Colab Pro for longer sessions\n\n\nIssue 2: Earth Engine authentication fails\nCause: Not registered or registration not approved\nSolution: - Verify registration status at earthengine.google.com - Wait for approval email (24-48 hours) - Check spam folder for approval notification\n\n\nIssue 3: Package installation fails\nCause: Network issues or package conflicts\nSolution:\n# Force reinstall\n!pip install --upgrade --force-reinstall geopandas\n\n# Or use specific versions\n!pip install geopandas==0.14.0\n\n\nIssue 4: Slow performance in Colab\nCause: Limited free resources\nSolutions: - Close other browser tabs - Restart runtime: Runtime → Restart runtime - Use GPU acceleration: Runtime → Change runtime type → GPU - Reduce data processing scope\n\n\nIssue 5: Cannot access Google Drive\nCause: Permission not granted\nSolution: - Re-run the mount command - Click the authorization link - Grant access to Google Drive",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#system-requirements",
    "href": "resources/setup.html#system-requirements",
    "title": "Setup Guide",
    "section": "System Requirements",
    "text": "System Requirements\n\nMinimum Requirements\n\nInternet: 5 Mbps download speed\nBrowser: Chrome 90+, Firefox 88+, Safari 14+, Edge 90+\nRAM: 4 GB (8 GB recommended)\nScreen: 1280x720 resolution minimum\n\n\n\nRecommended Setup\n\nInternet: 10+ Mbps for smooth streaming\nBrowser: Latest version of Chrome (best compatibility)\nRAM: 8+ GB for comfortable multitasking\nScreen: Dual monitors (one for presentation, one for coding)",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#pre-training-checklist",
    "href": "resources/setup.html#pre-training-checklist",
    "title": "Setup Guide",
    "section": "Pre-Training Checklist",
    "text": "Pre-Training Checklist\nBefore Day 1 starts, ensure:\n\n\nGoogle account created and verified\nGoogle Colab accessible and tested\nGoogle Earth Engine registered and approved\nTest notebook runs successfully\nEarth Engine authentication completed\nBrowser and internet connection tested\nHeadphones/speakers working\nQuiet workspace prepared",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#getting-help",
    "href": "resources/setup.html#getting-help",
    "title": "Setup Guide",
    "section": "Getting Help",
    "text": "Getting Help\n\nDuring Training\n\nAsk questions in the live session chat\nConsult teaching assistants\nCheck the FAQ for common issues\n\n\n\nBefore Training\n\nReview this setup guide thoroughly\nTest all components at least 1 day before\nContact training coordinators if you encounter issues\n\n\n\n\n\n\n\nImportantTechnical Support Contacts\n\n\n\nFor urgent setup issues: - Email: training@philsa.gov.ph - Slack/Discord: Check invitation email for links - WhatsApp Group: Join via link in confirmation email",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#additional-resources",
    "href": "resources/setup.html#additional-resources",
    "title": "Setup Guide",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nGoogle Colab Tutorials\n\nOfficial Colab Welcome Notebook\nColab Markdown Guide\n\n\n\nGoogle Earth Engine Resources\n\nEarth Engine Guides\nPython API Documentation\nCommunity Forum\n\n\n\nPython for Geospatial\n\nGeoPandas Documentation\nRasterio Documentation\nGeospatial Python Workshop",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/setup.html#ready-to-start",
    "href": "resources/setup.html#ready-to-start",
    "title": "Setup Guide",
    "section": "Ready to Start?",
    "text": "Ready to Start?\nOnce you’ve completed all setup steps, you’re ready for the training!\n\n\n\nBack\n\n\n← Return to Home\n\n\n\n\nNext\n\n\nSession 1: Copernicus & Philippine EO →\n\n\n\n\nSetup questions? Contact the training coordinators or check the FAQ.",
    "crumbs": [
      "Home",
      "Getting Started",
      "Setup Guide"
    ]
  },
  {
    "objectID": "resources/faq.html",
    "href": "resources/faq.html",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "The Technical Assistance for the Philippines’ Copernicus Capacity Support Programme (CopPhil) is an EU-Philippines cooperation initiative under the Global Gateway strategy. It aims to:\n\nEstablish a Copernicus Mirror Site in the Philippines\nBuild capacity in EO data analysis and AI/ML\nCo-develop pilot services for DRR, CCA, and NRM\nCreate a sustainable Digital Space Campus for training\n\nKey Partners: Philippine Space Agency (PhilSA), Department of Science and Technology (DOST), European Union, European Space Agency (ESA)\n\n\n\n\nThis training is designed for:\n\nPhilippine government employees working in EO, disaster management, agriculture, or environment\nResearchers at universities and research institutions\nGIS professionals looking to expand into AI/ML\nData scientists interested in geospatial applications\nPhilSA, NAMRIA, DOST-ASTI, PAGASA, DENR staff\n\nPrerequisites: Basic Python knowledge and familiarity with remote sensing concepts (helpful but not required)\n\n\n\n\nMinimum: - Google account (Gmail) - Stable internet (5 Mbps+) - Modern web browser (Chrome, Firefox, Safari, Edge) - 4 GB RAM\nRecommended: - 10+ Mbps internet - Chrome browser (best compatibility) - 8+ GB RAM - Dual monitors (one for presentation, one for coding)\nNote: All exercises run in Google Colaboratory - no local software installation required!\n\n\n\n\nNo! All hands-on exercises use Google Colaboratory, which provides:\n\nFree cloud computing resources\nPre-installed Python libraries\nAccess to GPUs\nNo local installation needed\n\nHowever, if you prefer working locally, we provide installation guides in the Setup Guide.\n\n\n\n\nYes! The CopPhil training programme is fully funded by the European Union under the Global Gateway initiative. There are no fees for participants.",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#general-questions",
    "href": "resources/faq.html#general-questions",
    "title": "Frequently Asked Questions",
    "section": "",
    "text": "The Technical Assistance for the Philippines’ Copernicus Capacity Support Programme (CopPhil) is an EU-Philippines cooperation initiative under the Global Gateway strategy. It aims to:\n\nEstablish a Copernicus Mirror Site in the Philippines\nBuild capacity in EO data analysis and AI/ML\nCo-develop pilot services for DRR, CCA, and NRM\nCreate a sustainable Digital Space Campus for training\n\nKey Partners: Philippine Space Agency (PhilSA), Department of Science and Technology (DOST), European Union, European Space Agency (ESA)\n\n\n\n\nThis training is designed for:\n\nPhilippine government employees working in EO, disaster management, agriculture, or environment\nResearchers at universities and research institutions\nGIS professionals looking to expand into AI/ML\nData scientists interested in geospatial applications\nPhilSA, NAMRIA, DOST-ASTI, PAGASA, DENR staff\n\nPrerequisites: Basic Python knowledge and familiarity with remote sensing concepts (helpful but not required)\n\n\n\n\nMinimum: - Google account (Gmail) - Stable internet (5 Mbps+) - Modern web browser (Chrome, Firefox, Safari, Edge) - 4 GB RAM\nRecommended: - 10+ Mbps internet - Chrome browser (best compatibility) - 8+ GB RAM - Dual monitors (one for presentation, one for coding)\nNote: All exercises run in Google Colaboratory - no local software installation required!\n\n\n\n\nNo! All hands-on exercises use Google Colaboratory, which provides:\n\nFree cloud computing resources\nPre-installed Python libraries\nAccess to GPUs\nNo local installation needed\n\nHowever, if you prefer working locally, we provide installation guides in the Setup Guide.\n\n\n\n\nYes! The CopPhil training programme is fully funded by the European Union under the Global Gateway initiative. There are no fees for participants.",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#setup-account-issues",
    "href": "resources/faq.html#setup-account-issues",
    "title": "Frequently Asked Questions",
    "section": "Setup & Account Issues",
    "text": "Setup & Account Issues\n\nHow do I register for Google Earth Engine?\n\nGo to earthengine.google.com\nClick “Get Started” or “Sign Up”\nSign in with your Google account\nSelect “Noncommercial” (for this training)\nFill out the registration form:\n\nOrganization: Your institution\nProject description: “CopPhil EO AI/ML Training”\n\nSubmit and wait for approval (24-48 hours)\n\n\n\n\n\n\n\nImportant\n\n\n\nRegister at least 2 days before the training starts to ensure approval!\n\n\nFor detailed instructions, see the Setup Guide.\n\n\n\nMy Earth Engine registration is taking too long\nNormal approval time: 24-48 hours\nIf it’s been longer: 1. Check your spam folder for the approval email 2. Verify registration status at earthengine.google.com 3. Re-submit registration if it shows as not received 4. Contact Earth Engine support: earthengine-support@google.com\n\n\n\nI forgot to authenticate Earth Engine in Colab\nSymptoms: ee commands throw errors like “Please set project ID”\nSolution:\nimport ee\n\n# Authenticate (follow prompts)\nee.Authenticate()\n\n# Initialize\nee.Initialize()\nThis only needs to be done once per Google account. Future sessions will remember your credentials.\n\n\n\nGoogle Colab says “Runtime disconnected”\nCauses: - 90 minutes of inactivity - Maximum session length (12 hours for free accounts) - Browser tab closed or crashed\nSolution: 1. Click “Reconnect” button 2. Re-run setup cells (imports, authentication) 3. Continue from where you left off\n\n\n\n\n\n\nTip\n\n\n\nPrevent disconnections: - Keep browser tab active - Save work to Google Drive regularly - Use Ctrl/Cmd + S to save notebooks\n\n\n\n\n\nHow do I save my work in Google Colab?\nOption 1: Save to Drive (Recommended)\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Save outputs to Drive\noutput_path = '/content/drive/My Drive/CopPhil_Training/'\nOption 2: Download Files - Click folder icon in left sidebar - Right-click file → Download\nOption 3: Save Notebook - File → Save a copy in Drive - File → Download .ipynb",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#python-coding-issues",
    "href": "resources/faq.html#python-coding-issues",
    "title": "Frequently Asked Questions",
    "section": "Python & Coding Issues",
    "text": "Python & Coding Issues\n\nI’m getting “ModuleNotFoundError”\nExample: ModuleNotFoundError: No module named 'geopandas'\nCause: Package not installed in current Colab session\nSolution:\n# Install the missing package\n!pip install geopandas\n\n# Then import it\nimport geopandas as gpd\nCommon packages to install: - geopandas - rasterio - earthengine-api - geemap\n\n\n\nPackage installation is failing\nError: ERROR: Could not find a version that satisfies the requirement...\nSolutions:\n1. Update pip first:\n!pip install --upgrade pip\n!pip install geopandas\n2. Install specific version:\n!pip install geopandas==0.14.0\n3. Use conda (if local):\nconda install -c conda-forge geopandas\n4. Force reinstall:\n!pip install --upgrade --force-reinstall geopandas\n\n\n\nMy code runs locally but fails in Colab\nCommon causes:\n1. File paths: - Local: C:/Users/name/data.shp - Colab: /content/data.shp or from Drive\n2. Package versions: - Check versions: import package; print(package.__version__) - Install specific version if needed\n3. Missing files: - Upload files: Click folder icon → Upload - Or mount Google Drive\n\n\n\n“MemoryError” or “Kernel crashed”\nCauses: - Loading too much data - Processing large rasters - Insufficient RAM\nSolutions:\n1. Reduce data scope:\n# Read smaller window\nwindow = rasterio.windows.Window(0, 0, 1000, 1000)\ndata = src.read(1, window=window)\n\n# Or downsample\ndata = src.read(1, out_shape=(src.height // 4, src.width // 4))\n2. Use chunking:\n# Process in chunks\nfor window in src.block_windows():\n    data = src.read(1, window=window)\n    process(data)\n3. Enable GPU in Colab: - Runtime → Change runtime type → GPU\n4. Upgrade to Colab Pro: - More RAM (up to 50 GB) - Longer sessions - colab.research.google.com/signup",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#earth-engine-issues",
    "href": "resources/faq.html#earth-engine-issues",
    "title": "Frequently Asked Questions",
    "section": "Earth Engine Issues",
    "text": "Earth Engine Issues\n\n“User memory limit exceeded” in Earth Engine\nCause: Trying to process too much data at once\nSolutions:\n1. Increase scale parameter:\n# Before (10m resolution)\nresult = image.reduceRegion(\n    reducer=ee.Reducer.mean(),\n    geometry=roi,\n    scale=10  # 10m pixels\n)\n\n# After (100m resolution)\nresult = image.reduceRegion(\n    reducer=ee.Reducer.mean(),\n    geometry=roi,\n    scale=100  # 100m pixels\n)\n2. Reduce region size:\n# Smaller bounding box\nsmall_roi = ee.Geometry.Rectangle([120.0, 14.0, 120.5, 14.5])\n3. Filter dates more strictly:\n# Shorter time period\ncollection = collection.filterDate('2024-01-01', '2024-01-31')  # 1 month instead of 1 year\n4. Use maxPixels parameter:\ntask = ee.batch.Export.image.toDrive(\n    image=image,\n    scale=10,\n    maxPixels=1e13  # Allow more pixels\n)\n\n\n\nEarth Engine export is stuck at “RUNNING”\nCheck status:\n# Check task status\nprint(task.status())\nPossible statuses: - READY: Queued, waiting to start - RUNNING: Currently processing - COMPLETED: Successfully finished - FAILED: Error occurred (check status for details)\nIf stuck: 1. Wait - large exports can take hours 2. Check Earth Engine Task Manager 3. Cancel and restart with smaller parameters 4. Check Google Drive storage space\n\n\n\nCloud-free composite still has clouds\nCause: Cloud masking didn’t work perfectly\nSolutions:\n1. Use better cloud masking:\ndef aggressive_cloud_mask(image):\n    qa = image.select('QA60')\n    # Mask both cloud and cirrus\n    cloud_mask = qa.bitwiseAnd(1 &lt;&lt; 10).eq(0).And(\n                 qa.bitwiseAnd(1 &lt;&lt; 11).eq(0))\n    # Also mask cloud shadows\n    scl = image.select('SCL')\n    shadow_mask = scl.neq(3)  # 3 = cloud shadow\n    return image.updateMask(cloud_mask).updateMask(shadow_mask)\n2. Use percentile reduction instead of median:\n# Use 20th percentile (darker, less clouds)\ncomposite = collection.reduce(ee.Reducer.percentile([20]))\n3. Filter by cloud cover first:\ncollection = collection.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#data-visualization-issues",
    "href": "resources/faq.html#data-visualization-issues",
    "title": "Frequently Asked Questions",
    "section": "Data & Visualization Issues",
    "text": "Data & Visualization Issues\n\nMy map doesn’t display in Colab\nCause: Missing visualization library\nSolution:\n# Install geemap for interactive maps\n!pip install geemap\n\nimport geemap\n\n# Create map\nMap = geemap.Map()\nMap.centerObject(roi, 10)\nMap.addLayer(image, vis_params, 'Image')\nMap\n\n\n\nColors in my visualization look wrong\nCheck visualization parameters:\n# For Sentinel-2 true color\nvis_params = {\n    'bands': ['B4', 'B3', 'B2'],  # Red, Green, Blue\n    'min': 0,\n    'max': 3000,  # Adjust based on your data\n    'gamma': 1.4\n}\n\n# For NDVI\nndvi_vis = {\n    'min': -1,\n    'max': 1,\n    'palette': ['red', 'yellow', 'green']\n}\nAdjust min/max: - Too dark → decrease max value - Too bright → increase max value - Washed out → adjust gamma\n\n\n\nGeoPandas plot shows nothing\nCommon issues:\n1. Empty GeoDataFrame:\nprint(len(gdf))  # Check if it has rows\nprint(gdf.head())\n2. Wrong CRS:\nprint(gdf.crs)  # Check coordinate reference system\ngdf = gdf.to_crs('EPSG:4326')  # Reproject if needed\n3. Data outside visible area:\nprint(gdf.total_bounds)  # Check bounding box\ngdf.plot(figsize=(10, 10))  # Larger figure size\n\n\n\nRasterio shows “All-NaN slice encountered”\nCause: Trying to visualize a band with all nodata values\nSolution:\n# Check for valid data\nprint(f\"Min: {band.min()}, Max: {band.max()}\")\nprint(f\"Valid pixels: {np.count_nonzero(~np.isnan(band))}\")\n\n# Mask nodata\nvalid_mask = ~np.isnan(band)\nif valid_mask.any():\n    plt.imshow(band, cmap='gray')\nelse:\n    print(\"No valid data in this band\")",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#philippine-specific-questions",
    "href": "resources/faq.html#philippine-specific-questions",
    "title": "Frequently Asked Questions",
    "section": "Philippine-Specific Questions",
    "text": "Philippine-Specific Questions\n\nWhere can I get Philippine administrative boundaries?\nSources:\n\nPhilGIS: philgis.org\n\nShapefile format\nAll administrative levels\n\nNAMRIA GeoPortal: geoportal.namria.gov.ph\n\nOfficial government source\nRegistration may be required\n\nHumanitarian Data Exchange: data.humdata.org\n\nOpen data\nGeoJSON and Shapefile\n\nIn Earth Engine:\n\n# FAO GAUL administrative boundaries\nphilippines = ee.FeatureCollection(\"FAO/GAUL/2015/level1\") \\\n    .filter(ee.Filter.eq('ADM0_NAME', 'Philippines'))\n\n\n\nHow do I get Sentinel data specifically for the Philippines?\nIn Google Earth Engine:\n# Define Philippines bounding box\nphilippines_bbox = ee.Geometry.Rectangle([116.0, 4.0, 127.0, 21.0])\n\n# Filter Sentinel-2 collection\ncollection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n    .filterBounds(philippines_bbox) \\\n    .filterDate('2024-01-01', '2024-12-31') \\\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n\nprint(f\"Found {collection.size().getInfo()} images\")\nVia Copernicus Data Space: 1. Go to dataspace.copernicus.eu 2. Use SentiBoard to browse visually 3. Draw bounding box over Philippines 4. Filter by date and cloud cover 5. Download tiles\n\n\n\nWhat are the best satellite data sources for Philippine disasters?\nFloods: - Sentinel-1 SAR (works through clouds) - Planet Labs (daily imagery, commercial) - Landsat-8/9 (free, 16-day revisit)\nTyphoons: - Sentinel-2 (damage assessment) - MODIS (rapid assessment) - Himawari-8 (near real-time, via PAGASA)\nLandslides: - PlanetScope (3m resolution) - Sentinel-2 (10m, change detection) - LiDAR (elevation, via LiPAD portal)\nDrought: - MODIS (vegetation indices, 8-day) - Sentinel-2 (higher resolution) - SMAP (soil moisture)",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#training-specific-questions",
    "href": "resources/faq.html#training-specific-questions",
    "title": "Frequently Asked Questions",
    "section": "Training-Specific Questions",
    "text": "Training-Specific Questions\n\nCan I get a certificate for completing this training?\nYes! Participants who complete all 4 days and pass the final assessment will receive a CopPhil Training Programme Certificate issued by PhilSA and DOST.\nRequirements: - Attend all 4 days - Complete hands-on exercises - Submit final project - Pass assessment (70% minimum)\n\n\n\nWill the training materials be available after the course?\nYes! All materials will remain accessible:\n\nTraining portal stays online\nNotebooks available on GitHub\nRecorded sessions (if applicable)\nOngoing access to Digital Space Campus (under development)\n\n\n\n\nCan I share these materials with colleagues?\nYes! All training materials are licensed under Creative Commons BY-SA 4.0, which means you can:\n\nShare freely\nUse for teaching\nModify and adapt\nUse commercially\n\nRequirements: - Provide attribution: “CopPhil EO AI/ML Training Programme” - Share derivatives under the same license\n\n\n\nWhat comes after Day 1?\nDay 2: Classical Machine Learning for Land Cover Classification - Random Forests - Support Vector Machines - Feature engineering - Palawan land cover case study\nDay 3: Deep Learning for Flood Mapping & Object Detection - U-Net architecture - Sentinel-1 flood detection - YOLOv8 for infrastructure - Central Luzon flood case study\nDay 4: Advanced Topics & Practical Application - Foundation models for EO - Time series analysis - Transfer learning - Final project",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#technical-support",
    "href": "resources/faq.html#technical-support",
    "title": "Frequently Asked Questions",
    "section": "Technical Support",
    "text": "Technical Support\n\nWho do I contact for technical issues?\nDuring training: - Ask in the live session chat - Consult teaching assistants - Check this FAQ first\nOutside training hours: - Email: training@philsa.gov.ph - Slack/Discord: Check invitation email - GitHub Issues: Report issue\n\n\n\nI found an error in the training materials\nThank you for helping improve the training!\nTo report: 1. GitHub Issues: Create issue 2. Email: training@philsa.gov.ph 3. During session: Notify instructors\nInclude: - Which session/notebook - What the error is - Steps to reproduce - Your environment (Colab or local)",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#additional-resources",
    "href": "resources/faq.html#additional-resources",
    "title": "Frequently Asked Questions",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nWhere can I learn more about Earth Observation?\nOnline Courses: - Copernicus Training - ESA EO Training - Google Earth Engine Tutorials\nBooks: - “Remote Sensing and Image Interpretation” - Lillesand et al. - “Python for Geospatial Data Analysis” - Garrard - “Deep Learning for the Earth Sciences” - Camps-Valls et al.\nCommunities: - Google Earth Engine Developers - Stack Exchange GIS - r/gis\n\n\n\nWhere can I get help with Python programming?\nLearning Resources: - Python.org Tutorial - Real Python - DataCamp\nGetting Help: - Stack Overflow - Python Discord - r/learnpython",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/faq.html#still-have-questions",
    "href": "resources/faq.html#still-have-questions",
    "title": "Frequently Asked Questions",
    "section": "Still Have Questions?",
    "text": "Still Have Questions?\n\n\n\n\n\n\nTipCan’t Find Your Answer?\n\n\n\nContact Us: - Email: training@philsa.gov.ph - During training: Ask instructors directly - Slack/Discord: Join the community channels\nWe’re here to help ensure your success in the training!\n\n\n\nThis FAQ is regularly updated based on participant questions. Last updated: 2025-01-15",
    "crumbs": [
      "Home",
      "Resources",
      "Frequently Asked Questions"
    ]
  },
  {
    "objectID": "resources/downloads.html",
    "href": "resources/downloads.html",
    "title": "Downloads",
    "section": "",
    "text": "Download all training materials for Day 1 of the CopPhil EO AI/ML Training. All materials are provided under open licenses for educational use.\n\n\n\n\n\n\nNoteDownload Package\n\n\n\nFor convenience, you can download all Day 1 materials as a single ZIP file, or download individual components below.",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#overview",
    "href": "resources/downloads.html#overview",
    "title": "Downloads",
    "section": "",
    "text": "Download all training materials for Day 1 of the CopPhil EO AI/ML Training. All materials are provided under open licenses for educational use.\n\n\n\n\n\n\nNoteDownload Package\n\n\n\nFor convenience, you can download all Day 1 materials as a single ZIP file, or download individual components below.",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#complete-day-1-package",
    "href": "resources/downloads.html#complete-day-1-package",
    "title": "Downloads",
    "section": "Complete Day 1 Package",
    "text": "Complete Day 1 Package\n\nAll-in-One Download\nPackage Contents: - All 4 session notebooks (Jupyter .ipynb) - Presentation slides (PDF) - Cheat sheets (PDF) - Sample datasets - Session handouts\nSize: ~150 MB\nDownload Complete Package (ZIP)\nLast updated: 2025-01-15",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#jupyter-notebooks",
    "href": "resources/downloads.html#jupyter-notebooks",
    "title": "Downloads",
    "section": "Jupyter Notebooks",
    "text": "Jupyter Notebooks\nDownload interactive notebooks for hands-on practice:\n\nSession 3: Python for Geospatial Data\n\nDay1_Session3_Python_Geospatial_Data.ipynb\nLearn to work with vector data (GeoPandas) and raster data (Rasterio) in Python.\nTopics Covered: - GeoPandas for vector data - Reading shapefiles, GeoJSON, and GeoPackages - Coordinate reference systems and reprojection - Rasterio for raster data - Reading GeoTIFF files - Band operations and visualization - Philippine case study: Palawan land cover\nRequirements: - Google Colab (recommended) - Or local Jupyter with geopandas, rasterio installed\nDownload Notebook Open in Colab\n\n\n\nSession 4: Google Earth Engine\n\nDay1_Session4_Google_Earth_Engine.ipynb\nMaster Google Earth Engine for accessing and processing Copernicus data.\nTopics Covered: - Earth Engine authentication and initialization - ImageCollection filtering (spatial, temporal, metadata) - Sentinel-1 SAR data access - Sentinel-2 optical data access - Cloud masking techniques - Temporal compositing - Data export workflows - Philippine case study: Metro Manila monitoring\nRequirements: - Google Earth Engine account (register at earthengine.google.com) - Google Colab\nDownload Notebook Open in Colab",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#presentation-slides",
    "href": "resources/downloads.html#presentation-slides",
    "title": "Downloads",
    "section": "Presentation Slides",
    "text": "Presentation Slides\nDownload presentation slides for reference:\n\nSession 1: Copernicus Sentinel Data & Philippine EO Ecosystem\n\nTopics: - Copernicus Programme overview - Sentinel-1 SAR characteristics - Sentinel-2 optical specifications - 2025 updates (Sentinel-2C, Sentinel-1C) - Philippine EO agencies (PhilSA, NAMRIA, DOST-ASTI) - CopPhil Mirror Site introduction\nFormat: PDF (slides with notes)\nSize: ~15 MB\nDownload PDF View Online\n\n\n\nSession 2: AI/ML Fundamentals for Earth Observation\n\nTopics: - What is AI/ML and the EO workflow - Supervised vs. Unsupervised learning - Classification and regression examples - Introduction to neural networks - Convolutional Neural Networks (CNNs) - Data-centric AI paradigm - EO-specific considerations\nFormat: PDF (slides with notes)\nSize: ~12 MB\nDownload PDF View Online\n\n\n\nSession 3: Python for Geospatial Data (Intro)\n\nTopics: - Google Colab setup - Python environment for geospatial - Vector data concepts - Raster data concepts - Coordinate reference systems\nFormat: PDF (slides with notes)\nSize: ~8 MB\nDownload PDF View Online\n\n\n\nSession 4: Introduction to Google Earth Engine (Coming Soon)\n\nTopics: - Earth Engine architecture - Python API overview - Data catalog navigation - Philippine EO applications\nFormat: PDF (slides with notes)\nStatus: In preparation\nComing Soon",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#cheat-sheets-pdf",
    "href": "resources/downloads.html#cheat-sheets-pdf",
    "title": "Downloads",
    "section": "Cheat Sheets (PDF)",
    "text": "Cheat Sheets (PDF)\nPrint-friendly quick reference guides:\n\n\nPython Basics\nEssential Python syntax and operations\nDownload PDF\n\n\nGeoPandas Reference\nVector data operations\nDownload PDF\n\n\nRasterio Commands\nRaster data handling\nDownload PDF\n\n\nEarth Engine API\nGEE Python commands\nDownload PDF\n\n\nSentinel Missions\nBand specifications\nDownload PDF\n\n\nSpectral Indices\nCommon formulas\nDownload PDF",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#sample-datasets",
    "href": "resources/downloads.html#sample-datasets",
    "title": "Downloads",
    "section": "Sample Datasets",
    "text": "Sample Datasets\nPractice datasets for offline work:\n\nPhilippine Administrative Boundaries\n\nDescription: Provincial and municipal boundaries for the Philippines\nFormat: GeoPackage (.gpkg)\nSize: ~5 MB\nSource: PhilGIS / NAMRIA\nLicense: Open Data\nDownload Dataset\nContents: - Regions (17) - Provinces (81) - Municipalities and Cities - Attribute table with population data\n\n\n\nPalawan Land Cover Sample\n\nDescription: Sentinel-2 true color composite and land cover classification\nFormat: GeoTIFF (.tif)\nSize: ~80 MB\nArea: Palawan Province subset\nDate: 2024 dry season composite\nDownload Dataset\nFiles: - palawan_s2_composite.tif (RGB composite) - palawan_landcover.tif (Classification) - palawan_boundary.gpkg (Vector boundary) - README.txt (Metadata)\n\n\n\nMetro Manila Sentinel-1 Time Series (Sample)\n\nDescription: Sentinel-1 VV/VH polarization samples\nFormat: GeoTIFF (.tif)\nSize: ~40 MB\nArea: Metro Manila subset\nDates: Monthly composites (Jan-Dec 2024)\nDownload Dataset\nUse Cases: - Urban monitoring - Flood detection practice - Time series analysis",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#session-handouts",
    "href": "resources/downloads.html#session-handouts",
    "title": "Downloads",
    "section": "Session Handouts",
    "text": "Session Handouts\nPrinted materials for participants:\n\nDay 1 Participant Handbook\nContents: - Session summaries - Learning objectives - Key concepts - Exercise instructions - Note-taking space\nFormat: PDF (A4, printable)\nSize: ~3 MB\nDownload PDF\n\n\nGlossary of Terms\nContents: - EO terminology - AI/ML concepts - Acronyms and abbreviations - Philippine EO agencies\nFormat: PDF (booklet style)\nSize: ~2 MB\nDownload PDF",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#code-examples-repository",
    "href": "resources/downloads.html#code-examples-repository",
    "title": "Downloads",
    "section": "Code Examples Repository",
    "text": "Code Examples Repository\nAccess all code examples and utilities:\n\nGitHub Repository\nRepository: copphil-training/day1-materials\nContents: - Jupyter notebooks (latest versions) - Python utility functions - Data processing scripts - Example workflows - Troubleshooting guides\nVisit Repository Clone via Git\n# Clone repository\ngit clone https://github.com/copphil-training/day1-materials.git\n\n# Or download ZIP\nwget https://github.com/copphil-training/day1-materials/archive/main.zip",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#google-colab-links",
    "href": "resources/downloads.html#google-colab-links",
    "title": "Downloads",
    "section": "Google Colab Links",
    "text": "Google Colab Links\nDirect links to open notebooks in Google Colab:\n\nSession 3: Python for Geospatial Data\n\n\n\nOpen In Colab\n\n\n\nSession 4: Google Earth Engine\n\n\n\nOpen In Colab\n\n\n\n\n\n\n\n\n\nTipWorking in Colab\n\n\n\nOpening notebooks in Colab requires no local installation. All code runs in the cloud with access to GPUs and pre-installed libraries.\nFirst Time? See the Setup Guide for authentication instructions.",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#additional-resources",
    "href": "resources/downloads.html#additional-resources",
    "title": "Downloads",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nRecommended Reading\n\nEarth Observation: - Copernicus Open Access Hub User Guide - Sentinel-1 Toolbox Documentation - Sentinel-2 User Handbook\nPython for Geospatial: - GeoPandas User Guide - Rasterio Quickstart - Python Geospatial Development\nGoogle Earth Engine: - Earth Engine Python API Guide - Earth Engine Community Tutorials - Awesome Earth Engine\nAI/ML for EO: - Deep Learning for Earth Observation (Springer) - Fundamentals of Machine Learning for Predictive Data Analytics - Data-Centric AI Resource Hub\n\n\n\nVideo Tutorials\n\n\nCopernicus Programme Introduction (15 min) - Watch\nGetting Started with Google Earth Engine (30 min) - Watch\nGeoPandas Tutorial for Beginners (45 min) - Watch\nPhilippine EO Ecosystem Overview (20 min) - Watch",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#installation-scripts",
    "href": "resources/downloads.html#installation-scripts",
    "title": "Downloads",
    "section": "Installation Scripts",
    "text": "Installation Scripts\n\nLocal Python Environment Setup\nFor participants who want to work locally (not in Colab):\n\nrequirements.txt\nnumpy&gt;=1.24.0\npandas&gt;=2.0.0\nmatplotlib&gt;=3.7.0\ngeopandas&gt;=0.13.0\nrasterio&gt;=1.3.0\nearthengine-api&gt;=0.1.350\nfolium&gt;=0.14.0\ngeemap&gt;=0.30.0\njupyter&gt;=1.0.0\nDownload requirements.txt\nInstallation:\n# Create virtual environment\npython -m venv eo-env\nsource eo-env/bin/activate  # On Windows: eo-env\\Scripts\\activate\n\n# Install packages\npip install -r requirements.txt\n\n# Verify installation\npython -c \"import geopandas; print('GeoPandas installed successfully!')\"\n\n\n\nConda Environment (Alternative)\n\nenvironment.yml\nname: copphil-day1\nchannels:\n  - conda-forge\n  - defaults\ndependencies:\n  - python=3.10\n  - numpy\n  - pandas\n  - matplotlib\n  - geopandas\n  - rasterio\n  - jupyter\n  - pip\n  - pip:\n    - earthengine-api\n    - geemap\nDownload environment.yml\nInstallation:\nconda env create -f environment.yml\nconda activate copphil-day1",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#license-attribution",
    "href": "resources/downloads.html#license-attribution",
    "title": "Downloads",
    "section": "License & Attribution",
    "text": "License & Attribution\n\n\n\n\n\n\nImportantUsage Terms\n\n\n\nTraining Materials License: - Licensed under Creative Commons BY-SA 4.0 - Free to use for educational purposes - Attribution required: “CopPhil EO AI/ML Training Programme”\nCode Examples: - Licensed under MIT License - Free to use, modify, and distribute\nSample Datasets: - Copernicus Sentinel data: Free and open (Copernicus Data Policy) - Philippine administrative boundaries: Open Data (government sources) - Processed derivatives: CC BY-SA 4.0\nCitation:\nCopPhil Training Programme (2025). Day 1: EO Data, AI/ML Fundamentals &\nGeospatial Python. EU-Philippines Copernicus Capacity Support Programme.",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#support-feedback",
    "href": "resources/downloads.html#support-feedback",
    "title": "Downloads",
    "section": "Support & Feedback",
    "text": "Support & Feedback\n\nHaving Issues?\n\nCheck the FAQ for common problems\nReview the Setup Guide for installation help\nContact training coordinators: training@philsa.gov.ph\n\n\n\nSuggest Improvements\n\nReport broken links or errors\nRequest additional materials\nShare feedback on content\n\nGitHub Issues: Report Issue",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/downloads.html#download-statistics",
    "href": "resources/downloads.html#download-statistics",
    "title": "Downloads",
    "section": "Download Statistics",
    "text": "Download Statistics\n\nMost Downloaded: 1. Complete Day 1 Package (ZIP) 2. Session 3 Jupyter Notebook 3. GeoPandas Cheat Sheet 4. Session 4 Jupyter Notebook 5. Palawan Land Cover Dataset\nTotal Downloads This Month: 1,247\n\n\nAll materials are regularly updated. Check back for new resources and improved versions.",
    "crumbs": [
      "Home",
      "Resources",
      "Downloads"
    ]
  },
  {
    "objectID": "resources/glossary.html",
    "href": "resources/glossary.html",
    "title": "Glossary",
    "section": "",
    "text": "This glossary defines key terms used throughout the CopPhil EO AI/ML Training Programme. Terms are organized alphabetically within categories for easy reference.\nCategories: - Earth Observation Terms - AI/ML Terms - Geospatial Data Terms - Satellite & Sensor Terms - Philippine EO Organizations - Technical Acronyms",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#how-to-use-this-glossary",
    "href": "resources/glossary.html#how-to-use-this-glossary",
    "title": "Glossary",
    "section": "",
    "text": "This glossary defines key terms used throughout the CopPhil EO AI/ML Training Programme. Terms are organized alphabetically within categories for easy reference.\nCategories: - Earth Observation Terms - AI/ML Terms - Geospatial Data Terms - Satellite & Sensor Terms - Philippine EO Organizations - Technical Acronyms",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#earth-observation-terms",
    "href": "resources/glossary.html#earth-observation-terms",
    "title": "Glossary",
    "section": "Earth Observation Terms",
    "text": "Earth Observation Terms\n\nAbsorption Band\nWavelength region where atmospheric gases (water vapor, oxygen, CO2) absorb electromagnetic radiation, limiting remote sensing capabilities.\n\n\nBackscatter\nThe portion of radar energy reflected back to the sensor from a target. Used in SAR imaging to detect surface properties and moisture.\n\n\nCloud Masking\nThe process of identifying and removing cloud-contaminated pixels from optical satellite imagery to improve data quality.\n\n\nComposite Image\nA single image created by combining multiple images from different dates, often using statistical methods (median, mean) to reduce noise and clouds.\n\n\nEarth Observation (EO)\nThe gathering of information about Earth’s physical, chemical, and biological systems through remote sensing technologies, primarily satellites.\n\n\nFalse Color Composite\nAn image display where spectral bands are assigned to RGB colors differently than natural vision (e.g., NIR-Red-Green), revealing features invisible to the human eye.\n\n\nGround Truth\nField-collected reference data used to validate remote sensing classifications and train machine learning models.\n\n\nImage Collection\nA set of satellite images covering the same geographic area at different times, used for time series analysis.\n\n\nPixel\nThe smallest unit in a raster image, representing a specific ground area (spatial resolution) and spectral value.\n\n\nPreprocessing\nSteps taken to correct raw satellite data before analysis, including atmospheric correction, geometric correction, and radiometric calibration.\n\n\nRemote Sensing\nThe science of obtaining information about objects or areas from a distance, typically using sensors on satellites or aircraft.\n\n\nRevisit Time\nThe frequency with which a satellite can observe the same location on Earth (e.g., Sentinel-2 has 5-day revisit with 3 satellites).\n\n\nSpectral Signature\nThe unique reflectance pattern of an object across different wavelengths, used to identify materials and land cover types.\n\n\nTrue Color Composite\nAn image display using red, green, and blue bands to create a natural-looking image similar to human vision.",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#aiml-terms",
    "href": "resources/glossary.html#aiml-terms",
    "title": "Glossary",
    "section": "AI/ML Terms",
    "text": "AI/ML Terms\n\nActivation Function\nMathematical function in neural networks that introduces non-linearity (e.g., ReLU, Sigmoid, Tanh), enabling learning of complex patterns.\n\n\nArtificial Intelligence (AI)\nComputer systems capable of performing tasks that typically require human intelligence, including perception, reasoning, and decision-making.\n\n\nBackpropagation\nAlgorithm for training neural networks by calculating gradients of loss and adjusting weights to minimize error.\n\n\nBatch Size\nNumber of training samples processed before updating model weights. Smaller batches = more updates but noisier; larger batches = smoother but fewer updates.\n\n\nClassification\nSupervised learning task of assigning input data to predefined categories (e.g., forest, water, urban).\n\n\nClustering\nUnsupervised learning technique that groups similar data points together without predefined labels (e.g., K-means, DBSCAN).\n\n\nConfusion Matrix\nTable showing predicted vs. actual classifications, used to calculate accuracy, precision, recall, and F1-score.\n\n\nConvolutional Neural Network (CNN)\nDeep learning architecture specialized for image analysis, using convolutional layers to detect spatial patterns.\n\n\nData Augmentation\nTechnique to artificially increase training data by applying transformations (rotation, flipping, scaling) to existing samples.\n\n\nDeep Learning\nSubset of machine learning using multi-layer neural networks to learn hierarchical representations of data.\n\n\nEpoch\nOne complete pass through the entire training dataset during model training.\n\n\nFeature Engineering\nThe process of creating new input variables from raw data to improve model performance.\n\n\nFeature Extraction\nIdentifying and extracting relevant patterns or characteristics from raw data for use in machine learning models.\n\n\nGround Truth Labels\nVerified, accurate labels for training data, typically from field surveys or expert interpretation.\n\n\nHyperparameter\nModel configuration setting chosen before training (e.g., learning rate, number of layers) that affects model performance.\n\n\nLoss Function\nMathematical function measuring the difference between predicted and actual values, used to guide model training.\n\n\nMachine Learning (ML)\nSubset of AI enabling systems to learn and improve from experience without explicit programming.\n\n\nNeural Network\nComputing system inspired by biological brains, consisting of interconnected nodes (neurons) organized in layers.\n\n\nOverfitting\nWhen a model learns training data too well, including noise, resulting in poor performance on new data.\n\n\nPrecision\nProportion of positive predictions that are actually correct. Precision = TP / (TP + FP).\n\n\nRandom Forest\nEnsemble learning method using multiple decision trees to improve prediction accuracy and reduce overfitting.\n\n\nRecall (Sensitivity)\nProportion of actual positives correctly identified. Recall = TP / (TP + FN).\n\n\nRegression\nSupervised learning task of predicting continuous numerical values (e.g., crop yield, temperature).\n\n\nSupervised Learning\nMachine learning where models learn from labeled training data (input-output pairs).\n\n\nSupport Vector Machine (SVM)\nClassification algorithm that finds the optimal hyperplane separating different classes in feature space.\n\n\nTraining Set\nPortion of data used to train a machine learning model (typically 70-80% of total data).\n\n\nTransfer Learning\nReusing a pre-trained model on a new but related task, reducing training time and data requirements.\n\n\nUnderfitting\nWhen a model is too simple to capture the underlying patterns in data, resulting in poor performance.\n\n\nUnsupervised Learning\nMachine learning where models find patterns in unlabeled data without predefined categories.\n\n\nValidation Set\nData used to evaluate model performance during training and tune hyperparameters (typically 10-15% of data).",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#geospatial-data-terms",
    "href": "resources/glossary.html#geospatial-data-terms",
    "title": "Glossary",
    "section": "Geospatial Data Terms",
    "text": "Geospatial Data Terms\n\nAffine Transformation\nMathematical operation describing the relationship between pixel coordinates and geographic coordinates in raster data.\n\n\nBounding Box\nRectangular area defined by minimum and maximum coordinates [minX, minY, maxX, maxY], used to specify geographic extents.\n\n\nCoordinate Reference System (CRS)\nSystem defining how coordinates relate to real-world locations, including datum and projection (e.g., WGS84, UTM).\n\n\nDigital Elevation Model (DEM)\nRaster representation of terrain elevation, with each pixel value representing height above a reference level.\n\n\nFeature\nIn geospatial terms, a vector object (point, line, or polygon) with associated attributes.\n\n\nGeoJSON\nOpen standard JSON format for encoding geographic data structures, widely used for web mapping.\n\n\nGeoPackage\nOpen format for geospatial data storage in SQLite database, supporting both vector and raster data.\n\n\nGeometry\nThe spatial component of a geographic feature, defining its shape and location (point, line, polygon).\n\n\nGeoTIFF\nRaster image format with embedded geographic metadata (CRS, extent, resolution), standard for geospatial raster data.\n\n\nNoData Value\nSpecial value in raster data indicating missing or invalid data (e.g., -9999, NaN).\n\n\nPixel Resolution (Spatial Resolution)\nGround area represented by one pixel (e.g., 10m means each pixel covers 10m × 10m on the ground).\n\n\nProjection\nMathematical transformation converting 3D Earth coordinates to 2D map coordinates (e.g., Mercator, UTM).\n\n\nRaster Data\nGrid-based spatial data where each cell (pixel) contains a value, used for continuous phenomena (elevation, temperature, imagery).\n\n\nReproject\nConverting geospatial data from one coordinate reference system to another.\n\n\nShapefile\nPopular vector data format for GIS, consisting of multiple files (.shp, .shx, .dbf, .prj).\n\n\nSpatial Join\nCombining attributes from two geospatial datasets based on their spatial relationship (intersection, within, etc.).\n\n\nVector Data\nSpatial data representing discrete features as points, lines, or polygons with associated attributes.\n\n\nWell-Known Text (WKT)\nText markup language for representing vector geometry and spatial reference systems.",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#satellite-sensor-terms",
    "href": "resources/glossary.html#satellite-sensor-terms",
    "title": "Glossary",
    "section": "Satellite & Sensor Terms",
    "text": "Satellite & Sensor Terms\n\nActive Sensor\nSensor that emits its own energy and measures the reflected signal (e.g., SAR, LiDAR).\n\n\nAperture\nOpening in a sensor that controls the amount of light collected, affecting image brightness and quality.\n\n\nAtmospheric Correction\nProcessing step removing atmospheric effects (scattering, absorption) to retrieve surface reflectance.\n\n\nC-band\nRadar frequency band (4-8 GHz, wavelength 3.75-7.5 cm) used by Sentinel-1, good for vegetation and soil moisture.\n\n\nElectromagnetic Spectrum\nRange of all electromagnetic radiation wavelengths, from radio waves to gamma rays, including visible light.\n\n\nGeometric Correction\nCorrecting image distortions caused by sensor viewing angle, terrain, and Earth’s curvature.\n\n\nLevel 1C (L1C)\nSentinel-2 product with Top-of-Atmosphere (TOA) reflectance, geometrically corrected.\n\n\nLevel 2A (L2A)\nSentinel-2 product with Bottom-of-Atmosphere (BOA) surface reflectance, atmospherically corrected.\n\n\nLiDAR\nLight Detection and Ranging - active sensor using laser pulses to measure distance, creating high-resolution 3D point clouds.\n\n\nMultispectral\nImaging system capturing data in multiple (typically 3-15) wavelength bands across visible and infrared spectrum.\n\n\nNear Infrared (NIR)\nElectromagnetic radiation with wavelengths 0.7-1.4 μm, strongly reflected by healthy vegetation.\n\n\nOptical Sensor\nPassive sensor detecting reflected sunlight in visible and infrared wavelengths (e.g., Sentinel-2, Landsat).\n\n\nOrbit\nPath of a satellite around Earth, characterized by altitude, inclination, and period.\n\n\nPanchromatic\nSingle-band imagery capturing all visible wavelengths, typically at higher spatial resolution than multispectral bands.\n\n\nPassive Sensor\nSensor detecting naturally available energy, typically reflected sunlight (e.g., optical cameras).\n\n\nPolarization\nOrientation of radar waves (HH, VV, HV, VH), providing information about surface structure and moisture.\n\n\nRadiometric Calibration\nConverting raw sensor digital numbers to physical units (radiance or reflectance).\n\n\nSAR (Synthetic Aperture Radar)\nActive microwave imaging system creating high-resolution images independent of sunlight and clouds.\n\n\nShort-Wave Infrared (SWIR)\nElectromagnetic radiation with wavelengths 1.4-3.0 μm, useful for detecting moisture and minerals.\n\n\nSpectral Resolution\nAbility to distinguish between different wavelengths, determined by number and width of spectral bands.\n\n\nSun-Synchronous Orbit\nSatellite orbit maintaining constant local solar time, ensuring consistent illumination conditions.\n\n\nSwath Width\nWidth of the ground strip imaged by a satellite in a single pass (e.g., Sentinel-2 has 290 km swath).\n\n\nTemporal Resolution\nFrequency of repeat observations over the same location (synonymous with revisit time).\n\n\nThermal Infrared (TIR)\nElectromagnetic radiation with wavelengths 8-14 μm, measuring heat emitted by Earth’s surface.",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#philippine-eo-organizations",
    "href": "resources/glossary.html#philippine-eo-organizations",
    "title": "Glossary",
    "section": "Philippine EO Organizations",
    "text": "Philippine EO Organizations\n\nCopPhil Programme\nEU-Philippines Copernicus Capacity Support Programme - partnership to strengthen Philippine EO capabilities, establish a Copernicus Mirror Site, and develop AI/ML capacity.\n\n\nDENR\nDepartment of Environment and Natural Resources - responsible for forest monitoring, land cover mapping, and natural resource management using EO data.\n\n\nDOST\nDepartment of Science and Technology - leads science and technology advancement, co-chairs CopPhil programme, operates PAGASA and ASTI.\n\n\nDOST-ASTI\nAdvanced Science and Technology Institute - ICT research and development, AI platforms (SkAI-Pinas, DIMER, AIPI).\n\n\nLiPAD\nLiDAR Portal for Archiving and Distribution - repository of high-resolution elevation data for the Philippines.\n\n\nNAMRIA\nNational Mapping and Resource Information Authority - official mapping agency, operates GeoPortal and Resource Data Analysis Center.\n\n\nNDRRMC\nNational Disaster Risk Reduction and Management Council - coordinates disaster response, uses EO data for assessment and planning.\n\n\nPAGASA\nPhilippine Atmospheric, Geophysical and Astronomical Services Administration - weather, climate, and astronomical services.\n\n\nPhilGIS\nPhilippine GIS Data Clearinghouse - repository of geospatial datasets for the Philippines.\n\n\nPhilSA\nPhilippine Space Agency - national space authority, co-chairs CopPhil programme, operates SIYASAT portal and develops Copernicus Mirror Site.\n\n\nSIYASAT Portal\nPhilSA’s secure data archive for NovaSAR-1 data and maritime monitoring products.",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#technical-acronyms",
    "href": "resources/glossary.html#technical-acronyms",
    "title": "Glossary",
    "section": "Technical Acronyms",
    "text": "Technical Acronyms\n\nAI\nArtificial Intelligence - computer systems performing tasks requiring human intelligence.\n\n\nAPI\nApplication Programming Interface - set of functions allowing software to interact with services (e.g., Earth Engine Python API).\n\n\nASTER\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer - NASA sensor providing multispectral imagery.\n\n\nBOA\nBottom of Atmosphere - surface reflectance after atmospheric correction (Level 2A products).\n\n\nCCA\nClimate Change Adaptation - strategies and actions to adjust to climate change impacts.\n\n\nCNN\nConvolutional Neural Network - deep learning architecture for image analysis.\n\n\nCRS\nCoordinate Reference System - defines how coordinates relate to Earth’s surface.\n\n\nDEM\nDigital Elevation Model - raster representation of terrain elevation.\n\n\nDL\nDeep Learning - subset of ML using multi-layer neural networks.\n\n\nDRR\nDisaster Risk Reduction - strategies to minimize disaster impacts.\n\n\nEO\nEarth Observation - gathering information about Earth through remote sensing.\n\n\nESA\nEuropean Space Agency - operates Copernicus Sentinel missions.\n\n\nEVI\nEnhanced Vegetation Index - vegetation index less sensitive to atmospheric effects than NDVI.\n\n\nGEE\nGoogle Earth Engine - cloud platform for planetary-scale geospatial analysis.\n\n\nGIS\nGeographic Information System - software for capturing, managing, and analyzing spatial data.\n\n\nGPU\nGraphics Processing Unit - hardware accelerating deep learning computations.\n\n\nGNSS\nGlobal Navigation Satellite System - satellite-based positioning (GPS, Galileo, GLONASS).\n\n\nHDF\nHierarchical Data Format - file format for storing large scientific datasets.\n\n\nIW\nInterferometric Wide Swath - Sentinel-1 acquisition mode with 250 km swath.\n\n\nJAXA\nJapan Aerospace Exploration Agency - operates Japanese Earth observation satellites.\n\n\nLiDAR\nLight Detection and Ranging - laser-based remote sensing for elevation mapping.\n\n\nLULC\nLand Use Land Cover - classification of Earth’s surface into categories (forest, urban, agriculture, etc.).\n\n\nML\nMachine Learning - algorithms enabling systems to learn from data.\n\n\nMODIS\nModerate Resolution Imaging Spectroradiometer - NASA sensor providing daily global coverage.\n\n\nNASA\nNational Aeronautics and Space Administration - operates Landsat and other EO missions.\n\n\nNDBI\nNormalized Difference Built-up Index - spectral index for detecting built-up areas.\n\n\nNDVI\nNormalized Difference Vegetation Index - spectral index measuring vegetation health/density.\n\n\nNDWI\nNormalized Difference Water Index - spectral index for detecting water bodies.\n\n\nNIR\nNear Infrared - electromagnetic radiation beyond visible red (0.7-1.4 μm).\n\n\nNRM\nNatural Resource Management - sustainable management of natural resources using EO monitoring.\n\n\nRGB\nRed-Green-Blue - color model using three primary colors, or the corresponding image bands.\n\n\nRF\nRandom Forest - ensemble machine learning algorithm using multiple decision trees.\n\n\nRL\nReinforcement Learning - ML paradigm where agents learn through interaction with environment.\n\n\nSAR\nSynthetic Aperture Radar - active microwave imaging system.\n\n\nSCL\nScene Classification Layer - Sentinel-2 cloud and land cover classification mask.\n\n\nSNAP\nSentinel Application Platform - ESA’s free software for processing Sentinel data.\n\n\nSWIR\nShort-Wave Infrared - electromagnetic radiation with wavelengths 1.4-3.0 μm.\n\n\nSVM\nSupport Vector Machine - classification algorithm finding optimal separating hyperplane.\n\n\nTIR\nThermal Infrared - electromagnetic radiation measuring surface temperature (8-14 μm).\n\n\nTOA\nTop of Atmosphere - apparent reflectance before atmospheric correction (Level 1C products).\n\n\nUSGS\nUnited States Geological Survey - distributes Landsat and other EO data.\n\n\nUTM\nUniversal Transverse Mercator - widely-used projected coordinate system dividing Earth into zones.\n\n\nWGS84\nWorld Geodetic System 1984 - global geographic coordinate system (EPSG:4326).",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#spectral-indices",
    "href": "resources/glossary.html#spectral-indices",
    "title": "Glossary",
    "section": "Spectral Indices",
    "text": "Spectral Indices\n\nNDVI (Normalized Difference Vegetation Index)\nFormula: (NIR - Red) / (NIR + Red)\nRange: -1 to +1\nInterpretation: - High values (0.6-0.9): Dense vegetation - Moderate (0.2-0.5): Sparse vegetation - Near zero: Bare soil, rock - Negative: Water, clouds\nSentinel-2 Bands: (B8 - B4) / (B8 + B4)\n\n\n\nNDWI (Normalized Difference Water Index)\nMcFeeters Formula: (Green - NIR) / (Green + NIR)\nGao Formula: (NIR - SWIR) / (NIR + SWIR)\nRange: -1 to +1\nInterpretation: - Positive values: Water bodies - Negative: Land surfaces\nSentinel-2 (McFeeters): (B3 - B8) / (B3 + B8)\nSentinel-2 (Gao): (B8 - B11) / (B8 + B11)\n\n\n\nNDBI (Normalized Difference Built-up Index)\nFormula: (SWIR - NIR) / (SWIR + NIR)\nRange: -1 to +1\nInterpretation: - Positive values: Built-up areas - Negative: Vegetation, water\nSentinel-2: (B11 - B8) / (B11 + B8)\n\n\n\nEVI (Enhanced Vegetation Index)\nFormula: 2.5 × ((NIR - Red) / (NIR + 6×Red - 7.5×Blue + 1))\nRange: -1 to +1\nAdvantages: Less sensitive to atmospheric effects and soil background than NDVI\nSentinel-2: 2.5 × ((B8 - B4) / (B8 + 6×B4 - 7.5×B2 + 1))",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#quick-reference-tables",
    "href": "resources/glossary.html#quick-reference-tables",
    "title": "Glossary",
    "section": "Quick Reference Tables",
    "text": "Quick Reference Tables\n\nSentinel-2 Band Summary\n\n\n\nBand\nName\nWavelength (nm)\nResolution (m)\nTypical Use\n\n\n\n\nB1\nCoastal aerosol\n443\n60\nAtmospheric correction\n\n\nB2\nBlue\n490\n10\nBathymetry, soil/vegetation\n\n\nB3\nGreen\n560\n10\nPeak vegetation sensitivity\n\n\nB4\nRed\n665\n10\nVegetation discrimination\n\n\nB5\nRed Edge 1\n705\n20\nVegetation health\n\n\nB6\nRed Edge 2\n740\n20\nVegetation stress\n\n\nB7\nRed Edge 3\n783\n20\nVegetation stress\n\n\nB8\nNIR\n842\n10\nBiomass, water bodies\n\n\nB8A\nNarrow NIR\n865\n20\nAtmospheric correction\n\n\nB9\nWater vapor\n945\n60\nAtmospheric correction\n\n\nB11\nSWIR 1\n1610\n20\nMoisture, soil/vegetation\n\n\nB12\nSWIR 2\n2190\n20\nMoisture, burned areas\n\n\n\n\n\n\nCommon CRS for Philippines\n\n\n\n\n\n\n\n\n\nName\nEPSG Code\nType\nUse Case\n\n\n\n\nWGS84\n4326\nGeographic\nGlobal datasets, web maps\n\n\nUTM Zone 50N\n32650\nProjected\nWestern Mindanao\n\n\nUTM Zone 51N\n32651\nProjected\nLuzon, Visayas, most of Philippines\n\n\nUTM Zone 52N\n32652\nProjected\nEastern Mindanao\n\n\nPRS92\n4683\nGeographic\nPhilippine Reference System",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/glossary.html#related-resources",
    "href": "resources/glossary.html#related-resources",
    "title": "Glossary",
    "section": "Related Resources",
    "text": "Related Resources\nFor more detailed information:\n\nSetup Guide - Technical setup instructions\nCheat Sheets - Quick reference commands\nFAQ - Common questions and troubleshooting\nPhilippine EO Resources - Organizations and platforms\n\n\nThis glossary will be expanded in subsequent training days. Suggest additional terms via training@philsa.gov.ph",
    "crumbs": [
      "Home",
      "Resources",
      "Glossary"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html",
    "href": "resources/philippine-eo.html",
    "title": "Philippine EO Resources",
    "section": "",
    "text": "The Philippines has a growing Earth Observation ecosystem with multiple agencies, platforms, and initiatives dedicated to using satellite data for national development, disaster risk reduction, and environmental monitoring.\n\n\n\n\n\n\nNoteCopPhil Programme Context\n\n\n\nThis resource directory supports the EU-Philippines Copernicus Capacity Support Programme (CopPhil), strengthening Philippine EO capabilities through international collaboration.",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#overview",
    "href": "resources/philippine-eo.html#overview",
    "title": "Philippine EO Resources",
    "section": "",
    "text": "The Philippines has a growing Earth Observation ecosystem with multiple agencies, platforms, and initiatives dedicated to using satellite data for national development, disaster risk reduction, and environmental monitoring.\n\n\n\n\n\n\nNoteCopPhil Programme Context\n\n\n\nThis resource directory supports the EU-Philippines Copernicus Capacity Support Programme (CopPhil), strengthening Philippine EO capabilities through international collaboration.",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#key-philippine-eo-agencies",
    "href": "resources/philippine-eo.html#key-philippine-eo-agencies",
    "title": "Philippine EO Resources",
    "section": "Key Philippine EO Agencies",
    "text": "Key Philippine EO Agencies\n\n1. Philippine Space Agency (PhilSA)\n\nRole: National space authority and co-chair of CopPhil programme\nEstablished: 2019 (Republic Act No. 11363)\nMandate: - Formulate national space policy - Establish space infrastructure - Promote space science and technology - Coordinate space-related activities across government\nKey Platforms & Services:\n\nSIYASAT Portal\n\nURL: siyasat.philsa.gov.ph\nDescription: Secure data archive for NovaSAR-1 data and maritime monitoring\nAccess: Registration required for Philippine government agencies and authorized researchers\nData Available:\n\nNovaSAR-1 SAR imagery\nMaritime domain awareness products\nAutomatic Identification System (AIS) data\nShip detection and tracking\n\n\n\n\nCopernicus Mirror Site (Under Development)\n\nStatus: Being established under CopPhil programme\nPurpose: Local access to Copernicus Sentinel data\nBenefits:\n\nReduced latency for Philippine users\nGuaranteed data availability\nSupport for real-time applications\n\n\nContact: - Website: philsa.gov.ph - Email: info@philsa.gov.ph - Address: UP Technology Innovation Center, UP Diliman, Quezon City\n\n\n\n\n\n2. Department of Science and Technology (DOST)\n\nRole: Science and technology advancement, co-chair of CopPhil programme\nRelevant Agencies:\n\nDOST-ASTI (Advanced Science and Technology Institute)\n\nWebsite: asti.dost.gov.ph\nFocus: ICT research and development, AI platforms\n\nKey Platforms:\nSkAI-Pinas (Skills for AI in the Philippines) - AI capacity building platform - Machine learning training resources - Part of ₱2.6 billion AI investment (2024-2028)\nDIMER (Disaster and Information Management, Early-Warning, and Response) - Real-time disaster monitoring - Integration of EO data for hazard assessment\nAIPI (AI Philippines Initiative) - National AI strategy implementation - AI applications across sectors\n\n\nDOST-PAGASA (Philippine Atmospheric, Geophysical and Astronomical Services Administration)\n\nWebsite: pagasa.dost.gov.ph\nFocus: Weather, climate, and astronomical services\nEO Applications:\n\nWeather satellite data (Himawari-8, GOES)\nRainfall estimation\nTropical cyclone monitoring\nFlood forecasting\n\n\nContact: - DOST Main: dost.gov.ph - PAGASA Portal: bagong.pagasa.dost.gov.ph\n\n\n\n\n\n3. National Mapping and Resource Information Authority (NAMRIA)\n\nRole: National mapping and geospatial information authority\nWebsite: namria.gov.ph\nMandate: - National mapping and charting - Resource data generation - Geospatial information management\nKey Platforms:\n\nNAMRIA GeoPortal\n\nURL: geoportal.namria.gov.ph\nDescription: Access to Philippine geospatial datasets\nData Available:\n\nTopographic maps\nAdministrative boundaries\nDigital elevation models\nLand cover maps\nCoastal and bathymetric data\n\n\n\n\nResource Data Analysis Center (RDAC)\n\nSatellite data reception and processing\nAnalysis of Landsat, SPOT, and other EO data\nCustom mapping services for government agencies\n\nServices: - Map production and printing - Geodetic surveys - Hydrographic surveys - Resource assessment\nContact: - Email: info@namria.gov.ph - Address: Lawton Avenue, Fort Andres Bonifacio, Taguig City\n\n\n\n\n\n4. Department of Environment and Natural Resources (DENR)\n\nRole: Natural resource management and environmental protection\nWebsite: denr.gov.ph\nRelevant Offices:\n\nDENR-GSIS (Geographic Information System Services)\n\nForest monitoring using satellite imagery\nLand cover and land use mapping\nBiodiversity conservation planning\n\n\n\nDENR-Forest Management Bureau (FMB)\n\nWebsite: forestry.denr.gov.ph\nNational Greening Program monitoring\nForest health assessment\nIllegal logging detection using EO\n\nEO Applications: - Forest cover change detection - Mangrove mapping - Mining site monitoring - Protected area surveillance\n\n\n\n\n\n5. Other Key Agencies\n\nNational Disaster Risk Reduction and Management Council (NDRRMC)\n\nWebsite: ndrrmc.gov.ph\nCoordinates disaster response\nUses EO data for damage assessment and evacuation planning\n\n\n\nDepartment of Agriculture (DA)\n\nWebsite: da.gov.ph\nCrop monitoring using satellite imagery\nAgricultural drought assessment\nRice production forecasting\n\n\n\nLocal Water Utilities Administration (LWUA)\n\nWater resource mapping\nWatershed monitoring\nFlood hazard assessment",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#international-collaboration-platforms",
    "href": "resources/philippine-eo.html#international-collaboration-platforms",
    "title": "Philippine EO Resources",
    "section": "International Collaboration Platforms",
    "text": "International Collaboration Platforms\n\n1. Copernicus Programme Access\n\nCopernicus Data Space Ecosystem\n\nURL: dataspace.copernicus.eu\nDescription: Official Copernicus data access platform (launched 2023)\nFeatures:\n\nFree access to all Sentinel missions\nSentiBoard dashboard for data discovery\nOn-demand processing services\nAPI access for automated workflows\n\n\nPhilippine Focus: - CopPhil Mirror Site integration (upcoming) - Dedicated training resources - Local technical support\n\n\n\n2. ESA Earth Observation Portal\n\nURL: earth.esa.int\nMission information and data access\nEducational resources\n\n\n\n3. NASA Earthdata\n\nURL: earthdata.nasa.gov\nAccess to NASA EO missions\nFree data download (registration required)",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#philippine-eo-data-repositories",
    "href": "resources/philippine-eo.html#philippine-eo-data-repositories",
    "title": "Philippine EO Resources",
    "section": "Philippine EO Data Repositories",
    "text": "Philippine EO Data Repositories\n\n1. PhilGIS (Philippine GIS Data Clearinghouse)\n\nURL: philgis.org\nDescription: Repository of Philippine geospatial datasets\nData Types:\n\nAdministrative boundaries (up to barangay level)\nRoads and infrastructure\nDigital elevation models\nLand cover classifications\n\n\n\n\n2. LiPAD (LiDAR Portal for Archiving and Distribution)\n\nURL: lipad.dream.upd.edu.ph\nDescription: High-resolution LiDAR data for the Philippines\nCoverage: Major river basins and flood-prone areas\nProducts:\n\nDigital Terrain Models (DTM)\nDigital Surface Models (DSM)\nFlood hazard maps\nPoint clouds\n\n\n\n\n3. Philippine Geoportal\n\nURL: geoportal.gov.ph\nDescription: Government geospatial data portal\nData: Various government datasets",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#university-research-centers",
    "href": "resources/philippine-eo.html#university-research-centers",
    "title": "Philippine EO Resources",
    "section": "University Research Centers",
    "text": "University Research Centers\n\n1. UP Training Center for Applied Geodesy and Photogrammetry (TCAGP)\n\nWebsite: tcagp.org\nFocus: Geomatics training and research\nLocation: University of the Philippines, Diliman\n\n\n\n2. UP Resilience Institute\n\nWebsite: ovpri.upd.edu.ph/resilience-institute\nFocus: Disaster risk reduction research\nProjects: Hazard mapping, vulnerability assessment\n\n\n\n3. ATENEO Manila Observatory\n\nWebsite: observatory.ph\nFocus: Climate science, disaster preparedness\nEO Applications: Climate modeling, typhoon research",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#training-and-capacity-building",
    "href": "resources/philippine-eo.html#training-and-capacity-building",
    "title": "Philippine EO Resources",
    "section": "Training and Capacity Building",
    "text": "Training and Capacity Building\n\n1. PhilSA Digital Space Campus\n\nStatus: Under development (CopPhil programme)\nPurpose: Sustainable EO training infrastructure\nFeatures:\n\nOnline learning management system\nHands-on workshops\nCertification programmes\nCommunity forums\n\n\n\n\n2. DOST-ASTI Training Programs\n\nRegular workshops on AI/ML\nData science bootcamps\nOnline courses via SkAI-Pinas\n\n\n\n3. NAMRIA Training Center\n\nGIS and remote sensing courses\nSurveying and mapping certification\nCustom agency training",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#philippine-eo-applications",
    "href": "resources/philippine-eo.html#philippine-eo-applications",
    "title": "Philippine EO Resources",
    "section": "Philippine EO Applications",
    "text": "Philippine EO Applications\n\nDisaster Risk Reduction (DRR)\nFlood Mapping - SAR-based flood extent detection - Risk assessment for urban areas - Example: Metro Manila, Cagayan Valley, Central Luzon\nTyphoon Monitoring - Damage assessment using pre/post-event imagery - Infrastructure impact evaluation - Agricultural loss estimation\nLandslide Detection - Change detection in mountainous regions - Vulnerability mapping - Early warning systems\n\n\nClimate Change Adaptation (CCA)\nDrought Monitoring - Agricultural drought in Mindanao - Water resource management - Crop stress detection\nCoastal Change - Shoreline erosion monitoring - Mangrove forest tracking - Sea level rise impacts\nUrban Heat Islands - Temperature mapping in Metro Manila - Green space planning - Climate adaptation strategies\n\n\nNatural Resource Management (NRM)\nForest Monitoring - Deforestation detection - Illegal logging surveillance - Reforestation progress tracking\nLand Cover Mapping - National land cover database updates - Urban expansion analysis - Agricultural land use planning\nMarine Resources - Coral reef health assessment - Coastal water quality - Marine protected area monitoring",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#data-access-guides",
    "href": "resources/philippine-eo.html#data-access-guides",
    "title": "Philippine EO Resources",
    "section": "Data Access Guides",
    "text": "Data Access Guides\n\nHow to Access Philippine EO Data\n\nFor Government Employees\n\nRegister with SIYASAT portal (PhilSA)\nAccess NAMRIA GeoPortal with agency credentials\nRequest datasets through official channels\n\n\n\nFor Researchers\n\nSubmit data request to PhilSA/NAMRIA\nProvide research proposal and intended use\nSign data sharing agreements if required\n\n\n\nFor Students\n\nAccess open datasets via PhilGIS\nUse LiPAD portal for LiDAR data\nRequest educational access to restricted datasets\n\n\n\nFor International Collaborators\n\nCoordinate through CopPhil programme channels\nEstablish memoranda of understanding (MOUs)\nFollow data sharing protocols",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#philippine-case-studies",
    "href": "resources/philippine-eo.html#philippine-case-studies",
    "title": "Philippine EO Resources",
    "section": "Philippine Case Studies",
    "text": "Philippine Case Studies\n\n1. Typhoon Yolanda (Haiyan) Response (2013)\n\nRapid damage mapping using SAR imagery\nCoordination with international EO community\nLessons learned for future disasters\n\n\n\n2. Marawi Crisis (2017)\n\nSatellite-based damage assessment\nInfrastructure monitoring\nPost-conflict reconstruction planning\n\n\n\n3. Taal Volcano Eruption (2020)\n\nAsh fall extent mapping\nEvacuation zone delineation\nEnvironmental impact assessment\n\n\n\n4. COVID-19 Pandemic Monitoring (2020-2023)\n\nUrban mobility analysis\nAir quality changes\nLand use shifts",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#upcoming-initiatives",
    "href": "resources/philippine-eo.html#upcoming-initiatives",
    "title": "Philippine EO Resources",
    "section": "Upcoming Initiatives",
    "text": "Upcoming Initiatives\n\nCopPhil Programme Milestones (2024-2026)\n\n2024-2025: - Copernicus Mirror Site installation - Digital Space Campus platform launch - Pilot service co-development (DRR, CCA, NRM)\n2025-2026: - Advanced AI/ML training programmes - Operational EO services rollout - Regional capacity building workshops\n\n\n\nDOST AI Investment (2024-2028)\n\n₱2.6 billion for AI infrastructure\nIntegration of EO data with AI platforms\nNational AI talent development",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#contact-directory",
    "href": "resources/philippine-eo.html#contact-directory",
    "title": "Philippine EO Resources",
    "section": "Contact Directory",
    "text": "Contact Directory\n\nPhilSA - Email: info@philsa.gov.ph - Phone: +63 (2) 8981-8500\nDOST - Email: dostncr@dost.gov.ph - Phone: +63 (2) 8837-2071\nNAMRIA - Email: info@namria.gov.ph - Phone: +63 (2) 8810-4831\nPAGASA - Email: inquiry@pagasa.dost.gov.ph - Phone: +63 (2) 8284-0800",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#additional-resources",
    "href": "resources/philippine-eo.html#additional-resources",
    "title": "Philippine EO Resources",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nPolicy Documents\n\nRepublic Act No. 11363 (Philippine Space Act of 2019)\nExecutive Order No. 358 (NDRRMC Reorganization)\nDENR Administrative Orders on forest monitoring\n\n\n\nReports and Publications\n\nPhilSA Strategic Roadmap 2020-2040\nPhilippine Development Plan 2023-2028\nNational Disaster Risk Reduction and Management Plan\n\n\n\nInternational Partnerships\n\nJAXA (Japan Aerospace Exploration Agency) - Data sharing agreements\nESA (European Space Agency) - CopPhil programme\nUSGS (U.S. Geological Survey) - Landsat data access\nUNOSAT - Disaster response support",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/philippine-eo.html#stay-updated",
    "href": "resources/philippine-eo.html#stay-updated",
    "title": "Philippine EO Resources",
    "section": "Stay Updated",
    "text": "Stay Updated\nFollow Philippine EO developments:\n\nPhilSA Newsletter: Subscribe at philsa.gov.ph\nCopPhil Updates: Check training portal announcements\nSocial Media: Follow @PhilSpaceAgency on Twitter/Facebook\n\n\n\n\n\n\n\n\nTipContribute to This Directory\n\n\n\nKnow of additional Philippine EO resources? Contact the training coordinators to suggest additions to this page.\n\n\n\nThis resource directory is maintained by the CopPhil Training Programme. Last updated: 2025.",
    "crumbs": [
      "Home",
      "Resources",
      "Philippine EO Resources"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html",
    "href": "resources/cheatsheets.html",
    "title": "Cheat Sheets",
    "section": "",
    "text": "Quick reference guides for the tools, libraries, and concepts covered in Day 1. Bookmark this page for easy access during hands-on exercises!",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#overview",
    "href": "resources/cheatsheets.html#overview",
    "title": "Cheat Sheets",
    "section": "",
    "text": "Quick reference guides for the tools, libraries, and concepts covered in Day 1. Bookmark this page for easy access during hands-on exercises!",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#python-basics-cheat-sheet",
    "href": "resources/cheatsheets.html#python-basics-cheat-sheet",
    "title": "Cheat Sheets",
    "section": "Python Basics Cheat Sheet",
    "text": "Python Basics Cheat Sheet\n\nData Types\n# Numbers\ninteger = 42\nfloat_num = 3.14\n\n# Strings\ntext = \"Hello EO\"\nmultiline = \"\"\"Multiple\nlines\"\"\"\n\n# Lists (mutable)\ncoords = [14.5995, 120.9842]  # Manila lat/lon\nsensors = [\"Sentinel-1\", \"Sentinel-2\", \"Landsat-8\"]\n\n# Tuples (immutable)\nbbox = (120.0, 14.0, 121.0, 15.0)\n\n# Dictionaries\nmetadata = {\n    \"satellite\": \"Sentinel-2\",\n    \"date\": \"2025-01-15\",\n    \"cloud_cover\": 12.5\n}\n\n\nControl Flow\n# If statements\nif cloud_cover &lt; 20:\n    print(\"Good quality image\")\nelif cloud_cover &lt; 50:\n    print(\"Moderate quality\")\nelse:\n    print(\"Too cloudy\")\n\n# For loops\nfor sensor in sensors:\n    print(f\"Processing {sensor} data\")\n\n# List comprehension\nvalid_images = [img for img in images if img.cloud_cover &lt; 20]\n\n# While loop\ncount = 0\nwhile count &lt; 10:\n    count += 1\n\n\nFunctions\n# Basic function\ndef calculate_ndvi(nir, red):\n    \"\"\"Calculate Normalized Difference Vegetation Index.\"\"\"\n    return (nir - red) / (nir + red)\n\n# Function with default arguments\ndef load_image(path, band=\"B04\", scale=10):\n    return ee.Image(path).select(band).reproject(scale=scale)\n\n# Lambda function\nsquare = lambda x: x ** 2",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#numpy-cheat-sheet",
    "href": "resources/cheatsheets.html#numpy-cheat-sheet",
    "title": "Cheat Sheets",
    "section": "NumPy Cheat Sheet",
    "text": "NumPy Cheat Sheet\n\nArray Creation\nimport numpy as np\n\n# From lists\narr = np.array([1, 2, 3, 4, 5])\nmatrix = np.array([[1, 2], [3, 4]])\n\n# Special arrays\nzeros = np.zeros((3, 3))           # 3x3 array of zeros\nones = np.ones((2, 4))             # 2x4 array of ones\nidentity = np.eye(4)               # 4x4 identity matrix\nrandom = np.random.rand(3, 3)      # 3x3 random [0, 1)\nrange_arr = np.arange(0, 10, 2)    # [0, 2, 4, 6, 8]\nlinspace = np.linspace(0, 1, 5)    # 5 values from 0 to 1\n\n\nArray Operations\n# Arithmetic (element-wise)\na + b          # Addition\na - b          # Subtraction\na * b          # Multiplication\na / b          # Division\na ** 2         # Power\n\n# Statistics\narr.mean()     # Mean\narr.std()      # Standard deviation\narr.min()      # Minimum\narr.max()      # Maximum\narr.sum()      # Sum\n\n# Indexing\narr[0]         # First element\narr[-1]        # Last element\narr[1:4]       # Slice indices 1-3\nmatrix[0, :]   # First row\nmatrix[:, 1]   # Second column\n\n# Boolean indexing\narr[arr &gt; 5]   # Elements greater than 5\n\n\nArray Manipulation\n# Shape operations\narr.reshape(3, 2)        # Reshape to 3x2\narr.flatten()            # Flatten to 1D\narr.transpose()          # Transpose\n\n# Stacking\nnp.vstack([a, b])        # Vertical stack\nnp.hstack([a, b])        # Horizontal stack\nnp.stack([a, b], axis=0) # Stack along axis\n\n# Concatenation\nnp.concatenate([a, b])",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#geopandas-cheat-sheet",
    "href": "resources/cheatsheets.html#geopandas-cheat-sheet",
    "title": "Cheat Sheets",
    "section": "GeoPandas Cheat Sheet",
    "text": "GeoPandas Cheat Sheet\n\nReading/Writing Vector Data\nimport geopandas as gpd\n\n# Read files\ngdf = gpd.read_file(\"data.shp\")\ngdf = gpd.read_file(\"data.geojson\")\ngdf = gpd.read_file(\"data.gpkg\")\n\n# Write files\ngdf.to_file(\"output.shp\")\ngdf.to_file(\"output.geojson\", driver=\"GeoJSON\")\ngdf.to_file(\"output.gpkg\", driver=\"GPKG\")\n\n\nGeoDataFrame Operations\n# Inspect data\ngdf.head()              # First 5 rows\ngdf.info()              # Column info\ngdf.describe()          # Statistics\ngdf.crs                 # Coordinate Reference System\ngdf.geometry            # Geometry column\ngdf.total_bounds        # Bounding box [minx, miny, maxx, maxy]\n\n# Filtering\nmetro_manila = gdf[gdf[\"region\"] == \"NCR\"]\nlarge_areas = gdf[gdf.area &gt; 1000000]\n\n# Sorting\ngdf.sort_values(\"population\", ascending=False)\n\n\nSpatial Operations\n# Coordinate Reference System\ngdf.to_crs(\"EPSG:4326\")          # Reproject to WGS84\ngdf.to_crs(\"EPSG:32651\")         # Reproject to UTM Zone 51N\n\n# Geometric properties\ngdf.area                          # Area\ngdf.length                        # Perimeter/length\ngdf.centroid                      # Centroids\ngdf.bounds                        # Bounding boxes\n\n# Spatial relationships\ngdf1.intersects(gdf2)            # Intersection check\ngdf1.contains(point)             # Containment check\ngdf1.within(polygon)             # Within check\n\n# Spatial joins\ngpd.sjoin(points, polygons, how=\"inner\", predicate=\"within\")\n\n# Overlay operations\ngpd.overlay(gdf1, gdf2, how=\"intersection\")\ngpd.overlay(gdf1, gdf2, how=\"union\")\ngpd.overlay(gdf1, gdf2, how=\"difference\")\n\n\nVisualization\n# Basic plot\ngdf.plot()\n\n# Styled plot\ngdf.plot(column=\"population\",\n         cmap=\"YlOrRd\",\n         legend=True,\n         figsize=(10, 8))\n\n# Multiple layers\nax = gdf1.plot(color=\"blue\", alpha=0.5)\ngdf2.plot(ax=ax, color=\"red\", alpha=0.5)",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#rasterio-cheat-sheet",
    "href": "resources/cheatsheets.html#rasterio-cheat-sheet",
    "title": "Cheat Sheets",
    "section": "Rasterio Cheat Sheet",
    "text": "Rasterio Cheat Sheet\n\nReading Raster Data\nimport rasterio\nfrom rasterio.plot import show\n\n# Open raster\nwith rasterio.open(\"image.tif\") as src:\n    # Metadata\n    print(src.crs)          # CRS\n    print(src.bounds)       # Bounding box\n    print(src.shape)        # (height, width)\n    print(src.count)        # Number of bands\n    print(src.transform)    # Affine transform\n\n    # Read data\n    band1 = src.read(1)     # Read band 1\n    all_bands = src.read()  # Read all bands\n\n    # Windowed read\n    window = rasterio.windows.Window(0, 0, 512, 512)\n    subset = src.read(1, window=window)\n\n\nWriting Raster Data\n# Write single band\nwith rasterio.open(\n    \"output.tif\",\n    \"w\",\n    driver=\"GTiff\",\n    height=data.shape[0],\n    width=data.shape[1],\n    count=1,\n    dtype=data.dtype,\n    crs=\"EPSG:32651\",\n    transform=transform\n) as dst:\n    dst.write(data, 1)\n\n# Write multiple bands\nwith rasterio.open(\"output.tif\", \"w\", ...) as dst:\n    for i, band in enumerate(bands, start=1):\n        dst.write(band, i)\n\n\nRaster Operations\n# Reproject\nfrom rasterio.warp import reproject, Resampling\n\nreproject(\n    source=src_array,\n    destination=dst_array,\n    src_transform=src.transform,\n    src_crs=src.crs,\n    dst_transform=dst_transform,\n    dst_crs=\"EPSG:4326\",\n    resampling=Resampling.bilinear\n)\n\n# Masking\nfrom rasterio.mask import mask\n\nwith rasterio.open(\"image.tif\") as src:\n    clipped, transform = mask(src, shapes, crop=True)\n\n# Calculate indices\nwith rasterio.open(\"sentinel2.tif\") as src:\n    red = src.read(4).astype(float)\n    nir = src.read(8).astype(float)\n    ndvi = (nir - red) / (nir + red)\n\n\nVisualization\nfrom rasterio.plot import show\n\n# Single band\nwith rasterio.open(\"image.tif\") as src:\n    show(src, cmap=\"gray\")\n\n# RGB composite\nwith rasterio.open(\"image.tif\") as src:\n    show((src, [4, 3, 2]))  # True color (R, G, B)",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#google-earth-engine-python-api-cheat-sheet",
    "href": "resources/cheatsheets.html#google-earth-engine-python-api-cheat-sheet",
    "title": "Cheat Sheets",
    "section": "Google Earth Engine (Python API) Cheat Sheet",
    "text": "Google Earth Engine (Python API) Cheat Sheet\n\nInitialization\nimport ee\n\n# Authenticate (first time only)\nee.Authenticate()\n\n# Initialize\nee.Initialize()\n\n\nImage Operations\n# Load single image\nimage = ee.Image(\"COPERNICUS/S2/20250115T012345_20250115T012345_T51PTS\")\n\n# Load from collection\ncollection = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\nimage = collection.first()\n\n# Select bands\nrgb = image.select([\"B4\", \"B3\", \"B2\"])\nnir = image.select(\"B8\")\n\n# Band math\nndvi = image.normalizedDifference([\"B8\", \"B4\"]).rename(\"NDVI\")\n\n# Or manually\nnir = image.select(\"B8\")\nred = image.select(\"B4\")\nndvi = nir.subtract(red).divide(nir.add(red))\n\n\nImageCollection Filtering\n# Spatial filter\nroi = ee.Geometry.Rectangle([120.0, 14.0, 121.0, 15.0])\nfiltered = collection.filterBounds(roi)\n\n# Temporal filter\nfiltered = collection.filterDate(\"2024-01-01\", \"2024-12-31\")\n\n# Metadata filter\nlow_cloud = collection.filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20))\n\n# Combined\nfiltered = (collection\n    .filterBounds(roi)\n    .filterDate(\"2024-01-01\", \"2024-12-31\")\n    .filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", 20)))\n\n\nCloud Masking\n# Sentinel-2 cloud masking\ndef mask_s2_clouds(image):\n    qa = image.select(\"QA60\")\n    cloud_mask = qa.bitwiseAnd(1 &lt;&lt; 10).eq(0).And(\n                 qa.bitwiseAnd(1 &lt;&lt; 11).eq(0))\n    return image.updateMask(cloud_mask)\n\n# Apply to collection\nmasked = collection.map(mask_s2_clouds)\n\n\nReducers\n# Temporal reduction\nmedian = collection.median()\nmean = collection.mean()\nmax_val = collection.max()\n\n# Spatial reduction\nmean_value = image.reduceRegion(\n    reducer=ee.Reducer.mean(),\n    geometry=roi,\n    scale=10\n).getInfo()\n\n# Percentile\npercentile_90 = collection.reduce(ee.Reducer.percentile([90]))\n\n\nCompositing\n# Median composite\ncomposite = (collection\n    .filterBounds(roi)\n    .filterDate(\"2024-06-01\", \"2024-08-31\")\n    .median())\n\n# Quality mosaic (least cloudy pixels)\ncomposite = collection.qualityMosaic(\"B8\")\n\n\nExport\n# Export to Drive\ntask = ee.batch.Export.image.toDrive(\n    image=ndvi,\n    description=\"NDVI_Export\",\n    folder=\"EarthEngine\",\n    fileNamePrefix=\"ndvi_palawan\",\n    scale=10,\n    region=roi,\n    maxPixels=1e13\n)\ntask.start()\n\n# Check status\nprint(task.status())\n\n# Export to Asset\ntask = ee.batch.Export.image.toAsset(\n    image=composite,\n    description=\"Composite_Export\",\n    assetId=\"users/yourname/composite\",\n    scale=10,\n    region=roi\n)\n\n\nVisualization\n# In Jupyter with geemap\nimport geemap\n\nMap = geemap.Map()\nMap.centerObject(roi, 10)\n\n# Add image\nvis_params = {\n    \"bands\": [\"B4\", \"B3\", \"B2\"],\n    \"min\": 0,\n    \"max\": 3000,\n    \"gamma\": 1.4\n}\nMap.addLayer(image, vis_params, \"Sentinel-2\")\n\n# Add NDVI\nndvi_vis = {\n    \"min\": 0,\n    \"max\": 1,\n    \"palette\": [\"red\", \"yellow\", \"green\"]\n}\nMap.addLayer(ndvi, ndvi_vis, \"NDVI\")\n\nMap",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#sentinel-mission-quick-reference",
    "href": "resources/cheatsheets.html#sentinel-mission-quick-reference",
    "title": "Cheat Sheets",
    "section": "Sentinel Mission Quick Reference",
    "text": "Sentinel Mission Quick Reference\n\nSentinel-1 (SAR)\n\n\n\nParameter\nValue\n\n\n\n\nType\nC-band SAR\n\n\nBands\nVV, VH\n\n\nResolution\n10m (IW mode)\n\n\nSwath\n250 km\n\n\nRevisit\n6 days (2 satellites)\n\n\nGEE Collection\nCOPERNICUS/S1_GRD\n\n\n\nCommon Applications: - Flood mapping (water detection) - Ship detection - Crop monitoring - Land subsidence\n\n\nSentinel-2 (Optical)\n\n\n\nBand\nName\nWavelength (nm)\nResolution (m)\n\n\n\n\nB1\nCoastal aerosol\n443\n60\n\n\nB2\nBlue\n490\n10\n\n\nB3\nGreen\n560\n10\n\n\nB4\nRed\n665\n10\n\n\nB5\nRed edge 1\n705\n20\n\n\nB6\nRed edge 2\n740\n20\n\n\nB7\nRed edge 3\n783\n20\n\n\nB8\nNIR\n842\n10\n\n\nB8A\nNarrow NIR\n865\n20\n\n\nB9\nWater vapor\n945\n60\n\n\nB11\nSWIR 1\n1610\n20\n\n\nB12\nSWIR 2\n2190\n20\n\n\n\nRevisit Time: 5 days (3 satellites: 2A, 2B, 2C)\nGEE Collections: - COPERNICUS/S2_SR_HARMONIZED (Surface Reflectance) - COPERNICUS/S2_HARMONIZED (Top of Atmosphere)",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#common-spectral-indices",
    "href": "resources/cheatsheets.html#common-spectral-indices",
    "title": "Cheat Sheets",
    "section": "Common Spectral Indices",
    "text": "Common Spectral Indices\n\nNDVI (Vegetation)\n# Google Earth Engine\nndvi = image.normalizedDifference([\"B8\", \"B4\"])\n\n# NumPy/Rasterio\nndvi = (nir - red) / (nir + red)\n\n\nNDWI (Water)\n# Green - NIR (McFeeters)\nndwi = image.normalizedDifference([\"B3\", \"B8\"])\n\n# NIR - SWIR (Gao)\nmndwi = image.normalizedDifference([\"B8\", \"B11\"])\n\n\nNDBI (Built-up)\nndbi = image.normalizedDifference([\"B11\", \"B8\"])\n\n\nEVI (Enhanced Vegetation Index)\nevi = image.expression(\n    \"2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))\",\n    {\n        \"NIR\": image.select(\"B8\"),\n        \"RED\": image.select(\"B4\"),\n        \"BLUE\": image.select(\"B2\")\n    }\n)",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#philippine-regions-provinces",
    "href": "resources/cheatsheets.html#philippine-regions-provinces",
    "title": "Cheat Sheets",
    "section": "Philippine Regions & Provinces",
    "text": "Philippine Regions & Provinces\n\nAdministrative Levels\n\nRegion (17) → Province (81) → Municipality/City → Barangay\n\n\n\nUseful Bounding Boxes (WGS84)\n\n\n\nArea\nBounds [W, S, E, N]\n\n\n\n\nPhilippines\n[116.0, 4.0, 127.0, 21.0]\n\n\nLuzon\n[119.5, 12.0, 122.5, 19.0]\n\n\nMetro Manila\n[120.9, 14.4, 121.15, 14.8]\n\n\nPalawan\n[117.0, 7.5, 120.0, 12.0]\n\n\nMindanao\n[121.0, 5.0, 127.0, 10.0]",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#keyboard-shortcuts",
    "href": "resources/cheatsheets.html#keyboard-shortcuts",
    "title": "Cheat Sheets",
    "section": "Keyboard Shortcuts",
    "text": "Keyboard Shortcuts\n\nGoogle Colab\n\nRun cell: Shift + Enter\nInsert cell above: Ctrl/Cmd + M A\nInsert cell below: Ctrl/Cmd + M B\nDelete cell: Ctrl/Cmd + M D\nInterrupt execution: Ctrl/Cmd + M I\nComment/uncomment: Ctrl/Cmd + /\n\n\n\nJupyter Notebook\n\nRun cell: Shift + Enter\nInsert cell below: B\nInsert cell above: A\nDelete cell: D D (press D twice)\nChange to markdown: M\nChange to code: Y",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#common-error-messages",
    "href": "resources/cheatsheets.html#common-error-messages",
    "title": "Cheat Sheets",
    "section": "Common Error Messages",
    "text": "Common Error Messages\n\n“ee is not defined”\n# Solution: Initialize Earth Engine\nimport ee\nee.Initialize()\n\n\n“ModuleNotFoundError: No module named ‘geopandas’”\n# Solution: Install the package\n!pip install geopandas\n\n\n“RuntimeError: rasterio is not installed”\n# Solution: Install rasterio\n!pip install rasterio\n\n\n“User memory limit exceeded”\n# Solution: Reduce data scope\n# - Use smaller region\n# - Filter dates more strictly\n# - Increase scale parameter",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#downloadable-pdfs",
    "href": "resources/cheatsheets.html#downloadable-pdfs",
    "title": "Cheat Sheets",
    "section": "Downloadable PDFs",
    "text": "Downloadable PDFs\n\n\n\n\n\n\nNotePrint-Friendly Versions\n\n\n\nDownload PDF versions of these cheat sheets for offline reference:\n\nPython Basics (PDF)\nGeoPandas Quick Reference (PDF)\nRasterio Commands (PDF)\nEarth Engine Python API (PDF)\nSentinel Missions (PDF)\n\nPDFs will be available in the Downloads section.",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "resources/cheatsheets.html#additional-resources",
    "href": "resources/cheatsheets.html#additional-resources",
    "title": "Cheat Sheets",
    "section": "Additional Resources",
    "text": "Additional Resources\n\nOfficial Documentation:\n\nPython Docs\nNumPy Docs\nGeoPandas Docs\nRasterio Docs\nEarth Engine Guides\n\nCommunity Cheat Sheets:\n\nNumPy Cheat Sheet (DataCamp)\nPandas Cheat Sheet\nEarth Engine Cheat Sheet\n\n\n\nBookmark this page for quick access during training exercises!",
    "crumbs": [
      "Home",
      "Resources",
      "Cheat Sheets"
    ]
  },
  {
    "objectID": "sessions/session4.html",
    "href": "sessions/session4.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\n\nLearning Objectives\nBy the end of this session, you will be able to:\n\nAccess and filter Sentinel-1 and Sentinel-2 image collections in Google Earth Engine.\nApply a cloud mask to Sentinel-2 imagery.\nCreate a cloud-free composite image.\nExport processed imagery from Google Earth Engine.\n\n\n\n4.1. Hands-on Google Colab Notebooks\n\nNotebook 2: Google Earth Engine Python API for EO Data\nObjective: Teach participants how to use the Earth Engine Python API in Colab to find, filter, process, and download satellite images (Sentinel-1 and Sentinel-2) with basic pre-processing like cloud masking and compositing.\nContents & Steps:\n\nEarth Engine Initialization: The notebook starts with:\n\n\n\n!pip install earthengine-api import ee ee.Authenticate() ee.Initialize()\nWith instructions (in markdown) about the authentication process (click link, get code, paste). After initialization, they are ready to call EE functions.\n\n\n\nDefining an Area of Interest (AOI): The notebook provides a sample AOI, for example a rectangle over a part of Luzon or a specific city. Possibly:\n\n\n\naoi = ee.Geometry.Rectangle([120.9, 14.5, 121.1, 14.7]) # bounding box around Metro Manila\nor use a FeatureCollection like ee.FeatureCollection(\"USDOS/LSIB_SIMPLE/2017\") filtered for Philippines for a country boundary – but a smaller AOI is better for quick results.\n\n\n\nSearching Sentinel-2 ImageCollection: They then create a Sentinel-2 ImageCollection query:\n\n\n\ns2_col = ee.ImageCollection(‘COPERNICUS/S2_SR’)\n.filterBounds(aoi)\n.filterDate(‘2021-06-01’, ‘2021-08-31’)\n.filter(ee.Filter.lt(‘CLOUDY_PIXEL_PERCENTAGE’, 50)) print(“Images count:”, s2_col.size().getInfo())\nThe markdown explains each filter. They then select only relevant bands (maybe all 12 reflectance bands except QA, or just the visible/NIR for simplicity) using .select([...]).\n\n\n\nCloud Mask Function: Introduce a function to mask clouds in Sentinel-2:\n\n\n\ndef mask_clouds(image): qa = image.select(‘QA60’) # Bits 10 and 11 are clouds and cirrus cloud_bit_mask = (1 &lt;&lt; 10) | (1 &lt;&lt; 11) mask = qa.bitwiseAnd(cloud_bit_mask).eq(0) return image.updateMask(mask)\nThen apply: s2_clean = s2_col.map(mask_clouds). A short explanation: “The QA60 band’s bits 10 and 11 indicate cloudy pixels; this mask retains only pixels where those bits are 0 (no cloud).”\n\n\n\nCreate a Median Composite:\n\n\n\nmedian_img = s2_clean.median().clip(aoi)\nThe notebook notes this takes the per-pixel median across the collection date range, yielding one cloud-free image. They then visualize or download this composite:\n\n\n\nVisualization in Colab: Perhaps use folium via geemap (if introduced) or get a thumbnail:\n\n\n\nurl = median_img.getThumbURL({‘region’: aoi, ‘min’:0, ‘max’:3000, ‘bands’:[‘B4’,‘B3’,‘B2’]}) from IPython.display import Image Image(url=url)\nThis should display a small true-color thumbnail of the composite. The markdown might show the output or instruct users to open it.\n\n\n\nDownloading the Composite: Show how to export the image to Google Drive:\n\n\n\nexport_task = ee.batch.Export.image.toDrive(**{ ‘image’: median_img, ‘description’: ‘Sentinel2_composite_JunAug2021’, ‘folder’: ‘CopPhilTraining’, ‘fileNamePrefix’: ‘S2Composite_Manila_2021’, ‘region’: aoi.getInfo()[‘coordinates’], ‘scale’: 10, ‘crs’: ‘EPSG:4326’ }) export_task.start()\nExplain that this will save the image in their Drive (the user will have to manually download from Drive). Mention that tasks take a few minutes; they can check status with export_task.status() or in the GEE web UI. (Since it’s a small region and median, it might finish quickly).\n\n\n\nSentinel-1 Example: The notebook then goes through a similar flow for Sentinel-1:\n\n\n\ns1_col = ee.ImageCollection(‘COPERNICUS/S1_GRD’)\n.filterBounds(aoi)\n.filterDate(‘2021-06-01’, ‘2021-06-30’)\n.filter(ee.Filter.eq(‘instrumentMode’, ‘IW’))\n.filter(ee.Filter.eq(‘orbitProperties_pass’, ‘DESCENDING’))\n.filter(ee.Filter.eq(‘resolution_meters’, 10))\n.filter(ee.Filter.listContains(‘transmitterReceiverPolarisation’, ‘VV’)) print(“Sentinel-1 count:”, s1_col.size().getInfo())\nThis filters June 2021, IW mode, descending orbit, VV polarization only. The notebook explains these filters (mention dual polarization is often VV+VH; here we take only VV for demonstration). They then take a mean or median:\ns1_img = s1_col.mean().clip(aoi)\nBecause SAR has speckle, averaging multiple scenes can reduce noise. They then visualize:\nurl = s1_img.getThumbURL({'region': aoi, 'min': -20, 'max': 0})\nImage(url=url)\nwhere -20 to 0 dB might be typical backscatter range. The resulting grayscale image shows SAR backscatter over the area.\n\nIf time permits, show how to apply a simple threshold or edge detection on SAR (not necessary, but for fun: e.g., water has low VV backscatter, so threshold at -15 dB could highlight water – but perhaps beyond scope).\n\nDownloading Sentinel-1 data: They could demonstrate how to use ee.batch.Export.image.toDrive similarly for the SAR composite. Or mention using the ASF DAAC for raw data but that’s outside of GEE.\nUsing Earth Engine Data Catalog: Show that one can search for datasets programmatically. Perhaps:\n\n\n\nee_catalog = ee.data.getList({‘id’: ‘COPERNICUS’}) # fetch info on Copernicus datasets for entry in ee_catalog: print(entry[‘id’])\nThis might print available dataset IDs. Or encourage them to use the Docs tab in the Code Editor or the online catalog. The idea is to make participants aware of the huge variety of data (Landsat, MODIS, etc.) beyond Sentinel.\n\n\n\nAdditional GEE functionalities: Briefly mention that GEE can do a lot more:\nCompute statistics: e.g., median_img.reduceRegion(ee.Reducer.mean(), aoi, scale=10) to get mean reflectance over AOI.\nTime series: one can chart NDVI over time by iterating or using reduceRegions.\nMachine learning: Earth Engine also offers some built-in ML (Cart, SVM, randomForest via ee.Classifier) which they might use on Day 2. The notebook might not delve deep into these, but perhaps includes one example of a reduceRegion or adding NDVI band:\n\n\n\nndvi_img = median_img.normalizedDifference([‘B8’,‘B4’]).rename(‘NDVI’)\nand visualizing NDVI.",
    "crumbs": [
      "Home",
      "Training Sessions",
      "Learning Objectives"
    ]
  },
  {
    "objectID": "sessions/session2.html",
    "href": "sessions/session2.html",
    "title": "",
    "section": "",
    "text": "Code\n\n\n\n\n\n\nLearning Objectives\nBy the end of this session, you will be able to:\n\nOutline the typical workflow of an AI/ML project in Earth Observation.\nDistinguish between supervised and unsupervised learning with EO examples.\nExplain the basic concepts of neural networks and deep learning.\nDefine data-centric AI and its importance in EO.\n\n\n\n2.1. Lecture Materials\nAI/ML Concepts in Earth Observation: This lecture segment introduces how artificial intelligence and machine learning are applied to EO data, covering key concepts and workflows:\n\nAI/ML Workflow for EO: A typical machine learning workflow in EO involves several stages. Slides should illustrate:\nProblem Definition: e.g., identifying what environmental question to answer (flood mapping? land cover classification? yield prediction).\nData Acquisition: gathering relevant EO data (Sentinel images, ground truth labels, ancillary data).\nData Pre-processing: crucial for EO (geometric corrections, cloud masking, normalization, etc.) before feeding data to models.\nFeature Engineering: deriving informative features (spectral indices like NDVI, textures, DEM derivatives) from raw data.\nModel Selection & Training: choosing an algorithm (e.g., Random Forest, CNN) and training it on labeled examples.\nValidation & Evaluation: using separate test data to assess accuracy (confusion matrix, error metrics).\nDeployment: applying the model to new data or integrating into workflows for operational use. This end-to-end process ensures that participants see the “big picture” of how AI/ML projects are executed for EO applications.\nTypes of ML – Supervised vs Unsupervised: Define the two main paradigms with EO examples. In supervised learning, the model learns from labeled data. EO examples: land cover classification (labels = classes like water, urban, forest for each pixel) and regression tasks (predicting a continuous value such as soil moisture or air pollutant concentration from satellite data). In unsupervised learning, the algorithm finds patterns without explicit labels. Example: clustering multispectral images to discover land cover groups or anomalies (useful for exploratory analysis or change detection). Slides: could show an illustration of labeled training pixels on a satellite image for supervised learning, versus an image segmented into clusters for unsupervised.\nNeural Networks & Deep Learning Basics: Briefly introduce that deep learning is a subset of ML using neural networks with many layers (“deep” networks) that excel at learning complex patterns. A slide can depict a simple Artificial Neural Network with neurons organized in layers (input layer → hidden layers → output). Explain key concepts in simple terms: neurons apply activation functions to weighted sums of inputs (introducing non-linearity), the network is trained by adjusting weights to minimize a loss function (error) using algorithms like gradient descent (optimizers). Emphasize how Convolutional Neural Networks (CNNs) are specialized for images: using convolutional layers to automatically extract spatial features (edges, textures, objects) – this will foreshadow Day 2 content. The point is to demystify terms like “layers”, “activation”, “training” for participants new to AI.\nData-Centric AI in EO: “Data-centric AI” is the philosophy that improving your data (quality, quantity, diversity) is as important as model tuning. This is especially critical in EO where challenges like sensor noise, cloud cover, class imbalance, and label uncertainty can derail an AI project. Slides should stress that model performance in EO is often limited by the dataset: having well-annotated, representative training data (e.g. good ground truth for all land cover types, across different seasons and regions) is crucial. Mention strategies like augmenting training data, cleaning labels, and incorporating expert knowledge. The goal is to encourage participants to focus on creating or curating high-quality datasets for their projects, not just on choosing fancy algorithms. This aligns with CopPhil’s capacity building – ensuring participants can develop robust EO applications by paying attention to data suitability.",
    "crumbs": [
      "Home",
      "Training Sessions",
      "Learning Objectives"
    ]
  },
  {
    "objectID": "notebooks/notebook1.html",
    "href": "notebooks/notebook1.html",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "",
    "text": "This notebook accompanies Session 3: Python for Geospatial Data. You’ll learn to work with vector data using GeoPandas and raster data using Rasterio.\n\n\nBy completing this notebook, you will:\n\nLoad and visualize vector data with GeoPandas\nWork with different vector formats (Shapefiles, GeoJSON, GeoPackage)\nPerform coordinate reference system transformations\nRead and process raster data with Rasterio\nExtract band information and metadata\nVisualize multi-band imagery\nApply the concepts to Philippine data"
  },
  {
    "objectID": "notebooks/notebook1.html#session-3-hands-on-notebook",
    "href": "notebooks/notebook1.html#session-3-hands-on-notebook",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "",
    "text": "This notebook accompanies Session 3: Python for Geospatial Data. You’ll learn to work with vector data using GeoPandas and raster data using Rasterio.\n\n\nBy completing this notebook, you will:\n\nLoad and visualize vector data with GeoPandas\nWork with different vector formats (Shapefiles, GeoJSON, GeoPackage)\nPerform coordinate reference system transformations\nRead and process raster data with Rasterio\nExtract band information and metadata\nVisualize multi-band imagery\nApply the concepts to Philippine data"
  },
  {
    "objectID": "notebooks/notebook1.html#getting-started",
    "href": "notebooks/notebook1.html#getting-started",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Getting Started",
    "text": "Getting Started\n\nOption 1: Open in Google Colab (Recommended)\nClick the button below to open this notebook in Google Colab:\n\n\n\n\nOpen In Colab\n\n\n\nAdvantages: - No installation required - Free GPU access - Auto-saves to Google Drive - Pre-configured environment\n\n\nOption 2: Download Notebook\nDownload the Jupyter notebook to run locally or upload to your own Colab:\n\nDownload .ipynb File\nRequirements for local use:\npip install numpy pandas matplotlib geopandas rasterio\n\n\n\nOption 3: View Online\nYou can also view the notebook content below without running any code."
  },
  {
    "objectID": "notebooks/notebook1.html#notebook-preview",
    "href": "notebooks/notebook1.html#notebook-preview",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Notebook Preview",
    "text": "Notebook Preview\n\n\n\n\n\n\nNoteInteractive Execution Required\n\n\n\nThis is a hands-on exercise notebook. For the best learning experience, open it in Google Colab or Jupyter to run the code cells interactively.\n\n\n\nTopics Covered\n\nIntroduction to GeoPandas\n\nReading vector data\nExploring GeoDataFrames\nCoordinate reference systems\nSpatial operations\n\nWorking with Philippine Data\n\nLoading administrative boundaries\nFiltering regions and provinces\nCalculating areas and centroids\nCreating maps\n\nIntroduction to Rasterio\n\nReading raster data\nUnderstanding raster metadata\nExtracting bands\nVisualizing imagery\n\nPalawan Case Study\n\nSentinel-2 imagery analysis\nLand cover visualization\nSpectral band combinations\nNDVI calculation"
  },
  {
    "objectID": "notebooks/notebook1.html#prerequisites",
    "href": "notebooks/notebook1.html#prerequisites",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Prerequisites",
    "text": "Prerequisites\nBefore starting this notebook, ensure you have:\n\nCompleted the Setup Guide\nGoogle account (for Colab)\nBasic Python knowledge\nUnderstanding of Session 3 concepts"
  },
  {
    "objectID": "notebooks/notebook1.html#notebook-contents",
    "href": "notebooks/notebook1.html#notebook-contents",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Notebook Contents",
    "text": "Notebook Contents\nThe full interactive notebook includes:\n\n15+ code cells with detailed explanations\n10+ visualizations of vector and raster data\nExercises to test your understanding\nPhilippine case studies using real data\nTroubleshooting tips for common issues"
  },
  {
    "objectID": "notebooks/notebook1.html#support",
    "href": "notebooks/notebook1.html#support",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Support",
    "text": "Support\n\nDuring the Training\n\nAsk questions in the live session\nConsult teaching assistants\nWork through exercises at your own pace\n\n\n\nAfter the Training\n\nReview the Cheat Sheets\nCheck the FAQ\nAccess the Glossary"
  },
  {
    "objectID": "notebooks/notebook1.html#related-resources",
    "href": "notebooks/notebook1.html#related-resources",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Related Resources",
    "text": "Related Resources\n\nSession Materials: - Session 3: Python for Geospatial Data - Session 3 Presentation Slides\nQuick References: - GeoPandas Cheat Sheet - Rasterio Cheat Sheet\nDocumentation: - GeoPandas Documentation - Rasterio Documentation"
  },
  {
    "objectID": "notebooks/notebook1.html#next-steps",
    "href": "notebooks/notebook1.html#next-steps",
    "title": "Notebook 1: Python for Geospatial Data",
    "section": "Next Steps",
    "text": "Next Steps\nAfter completing this notebook:\n\n✅ Practice with your own Philippine data\n✅ Move on to Session 4: Google Earth Engine\n✅ Try Notebook 2: Google Earth Engine\n\n\n\n\n\nBack\n\n\n← Session 3 Overview\n\n\n\n\nNext\n\n\nNotebook 2: Google Earth Engine →\n\n\n\n\nReady to code? Open the notebook in Colab and start learning!"
  },
  {
    "objectID": "notebooks/Day1_Session4_Google_Earth_Engine.html",
    "href": "notebooks/Day1_Session4_Google_Earth_Engine.html",
    "title": "Notebook 2: Google Earth Engine Python API for EO Data",
    "section": "",
    "text": "Objective: Teach participants how to use the Earth Engine Python API in Colab to find, filter, process, and download satellite images (Sentinel-1 and Sentinel-2) with basic pre-processing like cloud masking and compositing.\n\n!pip install earthengine-api\nimport ee\nee.Authenticate()\nee.Initialize()"
  }
]
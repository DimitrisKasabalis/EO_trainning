{"title":"Session 4: Introduction to Google Earth Engine","markdown":{"yaml":{"title":"Session 4: Introduction to Google Earth Engine","subtitle":"Harness cloud computing power to access and process petabytes of Earth observation data","date":"last-modified"},"headingText":"Session Overview","containsRefs":false,"markdown":"\n\n::: {.session-info}\n**Duration:** 2 hours | **Format:** Hands-on Coding | **Platform:** Google Colaboratory + Earth Engine Python API\n:::\n\n\nGoogle Earth Engine (GEE) is a planetary-scale platform for Earth science data and analysis. This session introduces you to GEE's Python API, enabling you to access Sentinel-1 and Sentinel-2 data, filter massive image collections, perform cloud masking, create temporal composites, and export processed data - all without downloading terabytes of imagery. You'll learn core GEE concepts and apply them to Philippine use cases.\n\n::: {.learning-objectives}\n### Learning Objectives\n\nBy the end of this session, you will be able to:\n\n- **Explain** what Google Earth Engine is and its advantages for EO\n- **Authenticate** and initialize the Earth Engine Python API\n- **Define** core GEE concepts: Image, ImageCollection, Feature, FeatureCollection\n- **Apply** filters (spatial, temporal, metadata) to image collections\n- **Access** Sentinel-1 GRD and Sentinel-2 SR data catalogs\n- **Implement** cloud masking using QA bands\n- **Create** temporal composites (median, mean) to reduce cloud cover\n- **Calculate** spectral indices (NDVI, NDWI) at scale\n- **Export** processed imagery to Google Drive\n- **Understand** GEE's capabilities and limitations for AI/ML workflows\n:::\n\n---\n\n## Part 1: What is Google Earth Engine?\n\n### Overview\n\n**Google Earth Engine** is a cloud-based platform combining:\n\n1. **Multi-petabyte catalog** of satellite imagery and geospatial datasets\n2. **Planetary-scale analysis capabilities** via Google's computational infrastructure\n3. **Code Editor** (JavaScript) and **Python API** for programmatic access\n\n::: {.callout-note}\n## Earth Engine by the Numbers\n\n- **40+ years** of historical imagery\n- **70+ petabytes** of data\n- **700+ datasets** including Landsat, Sentinel, MODIS, climate, terrain\n- **Global coverage** updated daily\n- **Free** for research, education, and non-profit use\n:::\n\n### Why Use Google Earth Engine?\n\n**Traditional workflow problems:**\n\n- Downloading terabytes of satellite data\n- Storing data locally (expensive storage)\n- Pre-processing each scene individually (time-consuming)\n- Limited computational resources for large-area analysis\n\n**Earth Engine solution:**\n\n```\n┌─────────────────────────────────────┐\n│   Your Computer                     │\n│   ┌──────────────┐                  │\n│   │ Write Code   │                  │\n│   │ (Python/JS)  │                  │\n│   └──────┬───────┘                  │\n│          │                           │\n│   ┌──────▼───────────────────────┐  │\n│   │ Send to Cloud                │  │\n│   └──────────────────────────────┘  │\n└──────────────┬──────────────────────┘\n               │\n               ▼\n┌──────────────────────────────────────────────┐\n│   Google Earth Engine Cloud                 │\n│   ┌──────────────┐  ┌──────────────┐        │\n│   │ Petabyte     │  │ Massive      │        │\n│   │ Data Catalog │  │ Computation  │        │\n│   └──────────────┘  └──────────────┘        │\n│                                              │\n│   Process → Results → Send back to you      │\n└──────────────────────────────────────────────┘\n```\n\n**Key advantages:**\n\n- **No downloading:** Data stays in Google's cloud\n- **Parallel processing:** Distributed computation across many machines\n- **Pre-processed data:** Analysis-ready collections (e.g., Sentinel-2 SR)\n- **Temporal analysis:** Easily work with time series\n- **Reproducible:** Share code, not gigabytes of data\n\n### Use Cases for Earth Observation\n\n**Ideal for:**\n\n- Large-area mapping (country/continent scale)\n- Multi-temporal analysis (time series, change detection)\n- Rapid prototyping and exploration\n- Cloud-based pre-processing\n- Teaching and learning (no infrastructure needed)\n\n**Less ideal for:**\n\n- Training custom deep learning models (CNNs, U-Net) - limited GPU support\n- Real-time processing requiring millisecond latency\n- Workflows requiring full control over hardware\n- Proprietary/restricted datasets not in GEE catalog\n\n::: {.philippine-context}\n**Philippine Applications:**\n\n- **National land cover mapping:** Process all of Philippines (~300,000 km²) at 10m resolution\n- **Multi-year deforestation monitoring:** Annual forest loss detection 2015-2025\n- **Typhoon impact assessment:** Before/after composites for disaster response\n- **Rice paddy monitoring:** Track planting/harvest cycles using SAR time series\n- **Coastal change detection:** Erosion and accretion mapping using optical+SAR\n:::\n\n---\n\n## Part 2: Setting Up Earth Engine in Python\n\n### Prerequisites\n\n::: {.callout-warning}\n## Required Setup\n\nBefore using Earth Engine, you must:\n\n1. **Google account** (Gmail or G Suite)\n2. **Earth Engine account** - Register at [earthengine.google.com](https://earthengine.google.com)\n3. **Cloud project** - Create or select a project after registration\n\n**Registration is FREE** and typically approved within 1-2 days.\n:::\n\n### Installation in Google Colab\n\nThe `earthengine-api` library is pre-installed in Colab, but let's ensure it's up-to-date:\n\n```python\n# Update Earth Engine API\n!pip install earthengine-api --upgrade -q\n\nprint(\"Earth Engine API updated! ✓\")\n```\n\n### Authentication & Initialization\n\n**First-time setup (one-time per environment):**\n\n```python\nimport ee\n\n# Authenticate (opens browser window for authorization)\nee.Authenticate()\n```\n\nThis will:\n1. Open a new browser tab\n2. Ask you to select your Google account\n3. Request permission to access Earth Engine\n4. Provide an authorization code\n5. Automatically apply the code\n\n::: {.callout-tip}\n## Authentication Troubleshooting\n\nIf authentication fails:\n\n1. Ensure you've registered at earthengine.google.com\n2. Check that you're using the same Google account\n3. Clear browser cookies and try again\n4. Use an incognito/private browsing window\n:::\n\n**Initialize Earth Engine (required every session):**\n\n```python\n# Initialize with your cloud project\n# Replace with your actual project ID\nee.Initialize(project='your-project-id')\n\nprint(\"Earth Engine initialized! ✓\")\n```\n\n**To find your project ID:**\n1. Go to [console.cloud.google.com](https://console.cloud.google.com)\n2. Select your project from the dropdown at the top\n3. Copy the Project ID (not Project Name)\n\n**Complete setup code:**\n\n```python\nimport ee\nimport geemap  # Interactive mapping library\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Authenticate (first time only - comment out after first use)\n# ee.Authenticate()\n\n# Initialize\nee.Initialize(project='your-project-id')\n\n# Test that it works\nimage = ee.Image('USGS/SRTMGL1_003')\nprint(\"✓ Successfully connected to Earth Engine!\")\nprint(f\"  Test image bands: {image.bandNames().getInfo()}\")\n```\n\n---\n\n## Part 3: Core Earth Engine Concepts\n\n### The Building Blocks\n\nEarth Engine has a unique data model optimized for planetary-scale analysis:\n\n| Concept | Description | Example |\n|---------|-------------|---------|\n| **Image** | Single raster with multiple bands | One Sentinel-2 scene |\n| **ImageCollection** | Stack of images (time series) | All Sentinel-2 over Philippines in 2024 |\n| **Geometry** | Vector shapes | Point, polygon, line |\n| **Feature** | Geometry + properties (attributes) | Province polygon with name, population |\n| **FeatureCollection** | Multiple features | All Philippine provinces |\n\n### 1. Geometry\n\n**Define locations and areas of interest:**\n\n```python\n# Point (longitude, latitude)\nmanila = ee.Geometry.Point([121.0244, 14.5995])\n\n# Rectangle (min_lon, min_lat, max_lon, max_lat)\nbohol_bbox = ee.Geometry.Rectangle([123.8, 9.6, 124.6, 10.2])\n\n# Polygon (list of coordinate pairs)\ncustom_aoi = ee.Geometry.Polygon([\n    [[123.5, 9.5], [125.0, 9.5], [125.0, 11.0], [123.5, 11.0], [123.5, 9.5]]\n])\n\nprint(\"Geometries created! ✓\")\nprint(f\"Manila coordinates: {manila.coordinates().getInfo()}\")\nprint(f\"Bohol bbox area: {bohol_bbox.area().divide(1e6).getInfo():.2f} km²\")\n```\n\n### 2. Image\n\n**Single raster image with one or more bands:**\n\n```python\n# Load a Sentinel-2 image by ID\nsentinel2_image = ee.Image('COPERNICUS/S2_SR/20240315T015701_20240315T015659_T51PWN')\n\n# Examine properties\nprint(\"Image ID:\", sentinel2_image.id().getInfo())\nprint(\"Band names:\", sentinel2_image.bandNames().getInfo())\nprint(\"Cloud cover:\", sentinel2_image.get('CLOUDY_PIXEL_PERCENTAGE').getInfo(), \"%\")\n\n# Select specific bands\nrgb_bands = sentinel2_image.select(['B4', 'B3', 'B2'])  # Red, Green, Blue\n```\n\n**Image operations:**\n\n```python\n# Calculate NDVI for single image\nndvi = sentinel2_image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n\n# Add as band to original image\nimage_with_ndvi = sentinel2_image.addBands(ndvi)\n\nprint(\"NDVI band added! ✓\")\n```\n\n### 3. ImageCollection\n\n**Stack of images (time series):**\n\n```python\n# Load Sentinel-2 collection\ns2_collection = ee.ImageCollection('COPERNICUS/S2_SR')\n\n# Check collection size (can be huge!)\nprint(\"Total Sentinel-2 images in catalog:\", s2_collection.size().getInfo())\n# This will be millions!\n```\n\n**ImageCollection operations:**\n\n```python\n# Filter by date, location, and cloud cover\nfiltered = (s2_collection\n    .filterBounds(bohol_bbox)\n    .filterDate('2024-01-01', '2024-12-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)))\n\nprint(f\"Filtered to {filtered.size().getInfo()} images over Bohol in 2024 with <30% clouds\")\n\n# Get image at specific index\nfirst_image = ee.Image(filtered.first())\nprint(\"First image date:\", first_image.date().format('YYYY-MM-dd').getInfo())\n```\n\n### 4. Feature & FeatureCollection\n\n**Vector data with attributes:**\n\n```python\n# Single feature (geometry + properties)\nmanila_feature = ee.Feature(\n    ee.Geometry.Point([121.0244, 14.5995]),\n    {'name': 'Manila', 'population': 1780148, 'country': 'Philippines'}\n)\n\nprint(\"Feature:\", manila_feature.getInfo())\n\n# Load feature collection (e.g., GADM administrative boundaries)\nphilippines = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.eq('ADM0_NAME', 'Philippines')\n)\n\nprint(f\"Philippine provinces: {philippines.size().getInfo()}\")\n```\n\n---\n\n## Part 4: Filtering and Querying Data\n\n### Filter Types\n\nEarth Engine provides powerful filtering to reduce massive collections to relevant data.\n\n#### 1. Spatial Filtering\n\n**filterBounds() - Keep images intersecting a geometry:**\n\n```python\n# Define AOI\npalawan = ee.Geometry.Rectangle([117.5, 8.0, 119.5, 12.0])\n\n# Filter Sentinel-2 to Palawan\ns2_palawan = ee.ImageCollection('COPERNICUS/S2_SR').filterBounds(palawan)\n\nprint(f\"Total Sentinel-2 images over Palawan: {s2_palawan.size().getInfo()}\")\n```\n\n#### 2. Temporal Filtering\n\n**filterDate() - Keep images within date range:**\n\n```python\n# Dry season 2024\ndry_season = s2_palawan.filterDate('2024-01-01', '2024-05-31')\nprint(f\"Dry season images: {dry_season.size().getInfo()}\")\n\n# Wet season 2024\nwet_season = s2_palawan.filterDate('2024-06-01', '2024-11-30')\nprint(f\"Wet season images: {wet_season.size().getInfo()}\")\n```\n\n#### 3. Metadata Filtering\n\n**filter() - Custom filters on image properties:**\n\n```python\n# Low cloud cover\nclear_images = dry_season.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\nprint(f\"Clear images (<10% clouds): {clear_images.size().getInfo()}\")\n\n# Specific satellite\ns2a_only = dry_season.filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2A'))\nprint(f\"Sentinel-2A only: {s2a_only.size().getInfo()}\")\n\n# Multiple conditions\nbest_images = (dry_season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 5))\n    .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))\n)\nprint(f\"Best images (S-2B, <5% clouds): {best_images.size().getInfo()}\")\n```\n\n### Chain Filters for Precision\n\n**Combine multiple filters:**\n\n```python\n# Define AOI for Bohol\nbohol_aoi = ee.Geometry.Rectangle([123.8, 9.6, 124.6, 10.2])\n\n# Multi-filter pipeline\nbohol_images = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-03-01', '2024-05-31')  # Dry season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n    .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'QA60']))  # Relevant bands\n\nprint(\"=\" * 50)\nprint(f\"Bohol Image Collection (Dry Season 2024)\")\nprint(\"=\" * 50)\nprint(f\"  Total images: {bohol_images.size().getInfo()}\")\nprint(f\"  Date range: {bohol_images.aggregate_min('system:time_start').getInfo()} to {bohol_images.aggregate_max('system:time_start').getInfo()}\")\nprint(\"=\" * 50)\n```\n\n---\n\n## Part 5: Working with Sentinel Data in GEE\n\n### Sentinel-2 Surface Reflectance\n\n**Collection ID:** `COPERNICUS/S2_SR`\n\n**Key information:**\n\n- **Level:** Level-2A (atmospherically corrected surface reflectance)\n- **Bands:** 13 spectral bands (B1-B12, plus QA60)\n- **Resolution:** 10m (B2-B4, B8), 20m (B5-B7, B8A, B11-B12), 60m (B1, B9, B10)\n- **Revisit:** 5 days (constellation)\n- **Updates:** Near real-time (within days of acquisition)\n\n**Band naming in GEE:**\n\n| Band | Name | Wavelength | Resolution | Use |\n|------|------|------------|------------|-----|\n| B2 | Blue | 490 nm | 10m | Atmospheric, water |\n| B3 | Green | 560 nm | 10m | Vegetation, water |\n| B4 | Red | 665 nm | 10m | Vegetation discrimination |\n| B8 | NIR | 842 nm | 10m | Biomass, vegetation |\n| B11 | SWIR1 | 1610 nm | 20m | Moisture, soil/vegetation |\n| B12 | SWIR2 | 2190 nm | 20m | Moisture, geology |\n| QA60 | Quality | - | 60m | Cloud mask |\n\n**Load and visualize:**\n\n```python\n# Load collection\ns2 = ee.ImageCollection('COPERNICUS/S2_SR')\n\n# Filter to area and time\nimage = (s2\n    .filterBounds(ee.Geometry.Point([124.0, 10.0]))  # Bohol\n    .filterDate('2024-03-01', '2024-03-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n    .first())\n\n# Visualize with geemap (interactive mapping)\nimport geemap\n\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nvis_params = {\n    'bands': ['B4', 'B3', 'B2'],\n    'min': 0,\n    'max': 3000,\n    'gamma': 1.4\n}\nMap.addLayer(image, vis_params, 'Sentinel-2 True Color')\nMap\n```\n\n### Sentinel-1 SAR\n\n**Collection ID:** `COPERNICUS/S1_GRD`\n\n**Key information:**\n\n- **Level:** Level-1 Ground Range Detected (GRD)\n- **Polarization:** VV, VH (or HH, HV depending on mode)\n- **Resolution:** 10m (IW mode)\n- **Revisit:** 6-12 days\n- **Advantages:** All-weather, day-night imaging\n\n**Load Sentinel-1:**\n\n```python\n# Load Sentinel-1 collection\ns1 = ee.ImageCollection('COPERNICUS/S1_GRD')\n\n# Filter for ascending pass, IW mode, VV+VH polarization\ns1_filtered = (s1\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-06-01', '2024-08-31')  # Wet season\n    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n    .filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n    .select(['VV', 'VH']))\n\nprint(f\"Sentinel-1 images: {s1_filtered.size().getInfo()}\")\n\n# Visualize\ns1_image = s1_filtered.median()  # Median composite\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(s1_image, {'bands': ['VV'], 'min': -25, 'max': 0}, 'S1 VV')\nMap.addLayer(s1_image, {'bands': ['VH'], 'min': -30, 'max': -5}, 'S1 VH')\nMap\n```\n\n---\n\n## Part 6: Cloud Masking and Preprocessing\n\n### Why Cloud Masking?\n\n**Problems with clouds:**\n\n- Obscure ground features\n- Contaminate spectral indices\n- Reduce classification accuracy\n- Create artifacts in composites\n\n**Solution:** Use quality assessment (QA) bands to identify and mask clouds.\n\n### Sentinel-2 Cloud Masking\n\n**Sentinel-2 includes QA60 band:**\n\n- Bit 10: Opaque clouds\n- Bit 11: Cirrus clouds\n\n**Cloud masking function:**\n\n```python\ndef mask_s2_clouds(image):\n    \"\"\"Mask clouds using QA60 band.\"\"\"\n    qa = image.select('QA60')\n\n    # Bits 10 and 11 are clouds and cirrus\n    cloud_bit_mask = 1 << 10\n    cirrus_bit_mask = 1 << 11\n\n    # Both flags should be zero = clear\n    mask = (qa.bitwiseAnd(cloud_bit_mask).eq(0)\n            .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0)))\n\n    # Return masked image, scaled to reflectance (0-1)\n    return image.updateMask(mask).divide(10000)\n\n# Apply to collection\ns2_masked = bohol_images.map(mask_s2_clouds)\n\nprint(\"Cloud masking applied! ✓\")\n```\n\n::: {.callout-note}\n## Understanding Bitwise Operations\n\n**QA60 band stores flags as bits:**\n\n```\nQA60 = 1024 (binary: 10000000000)\n         Bit 10 is set → Cloud present\n\nBit mask:\ncloud_bit_mask = 1 << 10 = 1024\nqa.bitwiseAnd(cloud_bit_mask) extracts bit 10\n.eq(0) checks if bit is 0 (no cloud)\n```\n\nThis efficient encoding allows multiple flags in one band!\n:::\n\n### Advanced Cloud Masking with SCL\n\n**Scene Classification Layer (SCL) band provides detailed classification:**\n\n```python\ndef mask_s2_clouds_scl(image):\n    \"\"\"Advanced cloud masking using SCL band.\"\"\"\n    scl = image.select('SCL')\n\n    # SCL values:\n    # 3 = cloud shadows\n    # 8 = cloud medium probability\n    # 9 = cloud high probability\n    # 10 = thin cirrus\n    # 11 = snow/ice\n\n    # Keep only vegetation (4), bare soil (5), water (6)\n    mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6))\n\n    return image.updateMask(mask).divide(10000)\n\n# Note: Need to load SCL band\ns2_with_scl = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-03-01', '2024-05-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n    .select(['B2', 'B3', 'B4', 'B8', 'SCL']))\n\ns2_masked_scl = s2_with_scl.map(mask_s2_clouds_scl)\n```\n\n---\n\n## Part 7: Creating Temporal Composites\n\n### Why Composites?\n\n**Challenges in tropical regions (like Philippines):**\n\n- Frequent cloud cover (>60% annual average)\n- Difficult to find single cloud-free scene\n- Monsoon seasons worsen problem\n\n**Solution: Temporal compositing**\n\nCombine multiple images over time to create cloud-free mosaic.\n\n### Composite Methods\n\n#### 1. Median Composite\n\n**Most common - robust to outliers:**\n\n```python\n# Create median composite (dry season 2024)\ncomposite_median = s2_masked.median()\n\nprint(\"Median composite created! ✓\")\n\n# Visualize\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nvis_params = {\n    'bands': ['B4', 'B3', 'B2'],\n    'min': 0,\n    'max': 0.3,\n    'gamma': 1.4\n}\nMap.addLayer(composite_median, vis_params, 'Median Composite (Dry Season)')\nMap\n```\n\n**Why median?**\n\n- Middle value of sorted pixel values over time\n- Removes clouds (typically brightest values)\n- Removes shadows (typically darkest values)\n- Preserves realistic surface reflectance\n\n#### 2. Mean Composite\n\n**Average of all pixels:**\n\n```python\ncomposite_mean = s2_masked.mean()\n\n# Smoother than median, but sensitive to remaining clouds\n```\n\n#### 3. Greenest Pixel Composite\n\n**Select pixel with highest NDVI (most vegetated):**\n\n```python\ndef add_ndvi(image):\n    \"\"\"Add NDVI band to image.\"\"\"\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n    return image.addBands(ndvi)\n\n# Add NDVI to all images\ns2_with_ndvi = s2_masked.map(add_ndvi)\n\n# Get maximum NDVI composite (greenest pixel)\ncomposite_max_ndvi = s2_with_ndvi.qualityMosaic('NDVI')\n\nMap.addLayer(composite_max_ndvi, vis_params, 'Greenest Pixel Composite')\n```\n\n### Multi-temporal Analysis\n\n**Compare dry vs. wet season:**\n\n```python\n# Dry season composite (Jan-May)\ndry_season = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-01-01', '2024-05-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .map(mask_s2_clouds)\n    .median())\n\n# Wet season composite (Jun-Nov)\nwet_season = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-06-01', '2024-11-30')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .map(mask_s2_clouds)\n    .median())\n\n# Calculate NDVI for both\ndry_ndvi = dry_season.normalizedDifference(['B8', 'B4'])\nwet_ndvi = wet_season.normalizedDifference(['B8', 'B4'])\n\n# NDVI difference (wet - dry)\nndvi_change = wet_ndvi.subtract(dry_ndvi)\n\n# Visualize\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(dry_season, vis_params, 'Dry Season')\nMap.addLayer(wet_season, vis_params, 'Wet Season')\nMap.addLayer(ndvi_change, {'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'green']},\n             'NDVI Change (Wet-Dry)')\nMap\n```\n\n::: {.philippine-context}\n**Interpretation for Philippines:**\n\n- **Green areas (positive change):** Rice paddies planted during wet season, increased vegetation vigor\n- **Red areas (negative change):** Areas with less vegetation in wet season (possibly fallow, harvested, or flooded)\n- **White areas (no change):** Stable land cover (evergreen forest, urban)\n:::\n\n---\n\n## Part 8: Calculating Spectral Indices at Scale\n\n### NDVI (Vegetation Health)\n\n```python\ndef calculate_ndvi(image):\n    \"\"\"Calculate NDVI for an image.\"\"\"\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n    return image.addBands(ndvi)\n\n# Apply to collection\ns2_with_ndvi = s2_masked.map(calculate_ndvi)\n\n# Get NDVI composite\nndvi_composite = s2_with_ndvi.select('NDVI').median()\n\n# Visualize\nndvi_params = {\n    'min': 0,\n    'max': 1,\n    'palette': ['red', 'yellow', 'green']\n}\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(ndvi_composite, ndvi_params, 'NDVI Composite')\nMap\n```\n\n### NDWI (Water Bodies)\n\n```python\ndef calculate_ndwi(image):\n    \"\"\"Calculate NDWI for water detection.\"\"\"\n    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n    return image.addBands(ndwi)\n\ns2_with_ndwi = s2_masked.map(calculate_ndwi)\nndwi_composite = s2_with_ndwi.select('NDWI').median()\n\n# Extract water bodies (NDWI > 0.3)\nwater_mask = ndwi_composite.gt(0.3)\n\nMap.addLayer(water_mask.selfMask(), {'palette': 'blue'}, 'Water Bodies')\n```\n\n### Multiple Indices\n\n```python\ndef add_indices(image):\n    \"\"\"Add multiple spectral indices.\"\"\"\n    # NDVI\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n\n    # NDWI\n    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n\n    # NDBI (Built-up)\n    ndbi = image.normalizedDifference(['B11', 'B8']).rename('NDBI')\n\n    # EVI (Enhanced Vegetation Index)\n    evi = image.expression(\n        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n        {\n            'NIR': image.select('B8'),\n            'RED': image.select('B4'),\n            'BLUE': image.select('B2')\n        }\n    ).rename('EVI')\n\n    return image.addBands([ndvi, ndwi, ndbi, evi])\n\n# Apply to collection\ns2_with_indices = s2_masked.map(add_indices)\n\n# Create composite with all indices\nmulti_index_composite = s2_with_indices.median()\n\nprint(\"Bands in composite:\", multi_index_composite.bandNames().getInfo())\n```\n\n---\n\n## Part 9: Exporting Data from Earth Engine\n\n### Export to Google Drive\n\n**Why export?**\n\n- Use data outside Earth Engine\n- Train ML models locally or in Colab\n- Share processed results\n- Create high-resolution figures\n\n**Export image:**\n\n```python\n# Define export region (use AOI)\nexport_region = bohol_aoi\n\n# Export composite to Drive\nexport_task = ee.batch.Export.image.toDrive(\n    image=composite_median.select(['B2', 'B3', 'B4', 'B8']),\n    description='Bohol_S2_Median_Dry2024',\n    folder='CopPhil_Training',\n    fileNamePrefix='bohol_s2_composite',\n    region=export_region,\n    scale=10,  # Resolution in meters\n    crs='EPSG:32651',  # UTM Zone 51N\n    maxPixels=1e9,\n    fileFormat='GeoTIFF'\n)\n\n# Start export task\nexport_task.start()\n\nprint(\"Export task started! ✓\")\nprint(\"Check status at: https://code.earthengine.google.com/tasks\")\n```\n\n**Monitor export:**\n\n```python\nimport time\n\n# Check task status\ntask_id = export_task.id\nprint(f\"Task ID: {task_id}\")\n\n# Poll until complete (check every 30 seconds)\nwhile export_task.active():\n    print(f\"  Status: {export_task.status()['state']} ...\")\n    time.sleep(30)\n\nprint(f\"✓ Export complete! Status: {export_task.status()['state']}\")\n```\n\n### Export Options\n\n**1. Export to Google Drive (easiest):**\n\n```python\nee.batch.Export.image.toDrive()\n```\n\n**2. Export to Cloud Storage:**\n\n```python\nee.batch.Export.image.toCloudStorage(\n    image=image,\n    bucket='your-gcs-bucket',\n    fileNamePrefix='path/to/file',\n    ...\n)\n```\n\n**3. Export to Asset (for reuse in GEE):**\n\n```python\nee.batch.Export.image.toAsset(\n    image=image,\n    description='MyAsset',\n    assetId='users/your-username/your-asset-name',\n    ...\n)\n```\n\n### Export FeatureCollection (Vector)\n\n**Export classification results or statistics:**\n\n```python\n# Create sample points with NDVI values\nsample_points = ndvi_composite.sample(\n    region=bohol_aoi,\n    scale=100,\n    numPixels=1000,\n    geometries=True\n)\n\n# Export to Drive\nexport_vector = ee.batch.Export.table.toDrive(\n    collection=sample_points,\n    description='Bohol_NDVI_Samples',\n    folder='CopPhil_Training',\n    fileFormat='CSV'\n)\n\nexport_vector.start()\nprint(\"Vector export started! ✓\")\n```\n\n---\n\n## Part 10: Best Practices and Limitations\n\n### Best Practices\n\n::: {.callout-tip}\n## GEE Workflow Tips\n\n1. **Filter aggressively:** Reduce collection size before processing\n2. **Use Cloud masking:** Always mask clouds for optical data\n3. **Scale matters:** Choose appropriate scale for export (don't over-sample)\n4. **Test on small areas:** Prototype with small AOI before scaling up\n5. **Monitor quotas:** Be aware of computation and storage limits\n6. **Reproducibility:** Save scripts, document parameters\n7. **Leverage built-in functions:** Don't reinvent the wheel\n:::\n\n### Computational Limits\n\n**Earth Engine has quotas (free tier):**\n\n- **Simultaneous requests:** Limited concurrent computations\n- **Export size:** Max 100,000 pixels per dimension\n- **Asset storage:** Limited space for uploaded/exported assets\n- **Processing time:** Long-running tasks may timeout\n\n**Solutions:**\n\n- Break large exports into tiles\n- Use reduce() operations instead of getInfo() for large data\n- Export to Asset for intermediate results\n- Consider upgrading to commercial tier for production workflows\n\n### Limitations for AI/ML\n\n**What GEE does well:**\n\n- Data access and pre-processing\n- Large-scale feature extraction\n- Random Forest / CART classification\n- Pixel-based analysis\n\n**What GEE struggles with:**\n\n- Training deep learning models (CNNs, U-Net, LSTMs)\n- Custom loss functions and optimizers\n- GPU-accelerated training\n- Complex model architectures requiring TensorFlow/PyTorch\n\n::: {.callout-note}\n## Recommended Workflow for Deep Learning\n\n1. **Use GEE for:** Data discovery, filtering, cloud masking, compositing, exporting training patches\n2. **Use Python (Colab/local) for:** Training CNNs/U-Nets with TensorFlow or PyTorch\n3. **Return to GEE for:** Applying trained model at scale (if feasible) or export tiles for prediction\n:::\n\n---\n\n## Part 11: Complete Example: Philippine Land Cover Composite\n\n**Scenario:** Create cloud-free RGB and NDVI composites for entire Palawan province.\n\n```python\n# 1. Define AOI (Palawan province)\npalawan = ee.Geometry.Rectangle([117.5, 8.0, 119.5, 12.0])\n\n# 2. Load and filter Sentinel-2\ns2_palawan = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(palawan)\n    .filterDate('2024-01-01', '2024-05-31')  # Dry season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .select(['B2', 'B3', 'B4', 'B8', 'QA60']))\n\nprint(f\"Images in collection: {s2_palawan.size().getInfo()}\")\n\n# 3. Apply cloud masking\ndef mask_clouds(image):\n    qa = image.select('QA60')\n    cloud_mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0))\n    return image.updateMask(cloud_mask).divide(10000)\n\ns2_masked = s2_palawan.map(mask_clouds)\n\n# 4. Create median composite\ncomposite = s2_masked.median()\n\n# 5. Calculate NDVI\nndvi = composite.normalizedDifference(['B8', 'B4']).rename('NDVI')\ncomposite_with_ndvi = composite.addBands(ndvi)\n\n# 6. Visualize\nMap = geemap.Map(center=[10.0, 118.5], zoom=8)\n\nrgb_vis = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3, 'gamma': 1.4}\nndvi_vis = {'bands': ['NDVI'], 'min': 0, 'max': 1, 'palette': ['brown', 'yellow', 'green', 'darkgreen']}\n\nMap.addLayer(composite, rgb_vis, 'Palawan True Color')\nMap.addLayer(composite_with_ndvi, ndvi_vis, 'Palawan NDVI')\nMap\n\n# 7. Export to Drive\nexport_rgb = ee.batch.Export.image.toDrive(\n    image=composite.select(['B4', 'B3', 'B2']),\n    description='Palawan_RGB_DryS2024',\n    folder='CopPhil_Training',\n    region=palawan,\n    scale=10,\n    maxPixels=1e10,\n    fileFormat='GeoTIFF'\n)\n\nexport_ndvi = ee.batch.Export.image.toDrive(\n    image=ndvi,\n    description='Palawan_NDVI_DryS2024',\n    folder='CopPhil_Training',\n    region=palawan,\n    scale=10,\n    maxPixels=1e10,\n    fileFormat='GeoTIFF'\n)\n\nexport_rgb.start()\nexport_ndvi.start()\n\nprint(\"=\" * 60)\nprint(\"PALAWAN LAND COVER COMPOSITE - EXPORT STARTED\")\nprint(\"=\" * 60)\nprint(\"RGB Composite: Check Google Drive in ~10-30 minutes\")\nprint(\"NDVI Layer: Check Google Drive in ~10-30 minutes\")\nprint(\"Monitor at: https://code.earthengine.google.com/tasks\")\nprint(\"=\" * 60)\n```\n\n---\n\n## Key Takeaways\n\n::: {.callout-important}\n## Session 4 Summary\n\n**Google Earth Engine:**\n- Cloud platform with petabytes of EO data\n- No downloading required - process in cloud\n- Free for research/education\n\n**Core Concepts:**\n- Image / ImageCollection for rasters\n- Feature / FeatureCollection for vectors\n- Geometry for locations and AOIs\n\n**Key Operations:**\n- Filter by bounds, date, metadata\n- Cloud masking using QA bands\n- Temporal composites (median, mean)\n- Spectral indices (NDVI, NDWI)\n- Export to Drive/Cloud Storage\n\n**Workflow:**\n1. Define AOI\n2. Filter collection\n3. Mask clouds\n4. Create composite\n5. Calculate indices\n6. Visualize\n7. Export\n\n**Best for:** Pre-processing, data access, Random Forest, large-area mapping\n\n**Use Python/TensorFlow for:** Deep learning model training\n\n**Next steps:** Apply these skills in Days 2-4 for land cover classification, flood mapping, and time series analysis!\n:::\n\n---\n\n## Practice Exercises\n\n::: {.callout-tip}\n## Try These Challenges\n\n**Exercise 1: Your Province Composite**\n\nCreate a cloud-free Sentinel-2 composite for your home province using the complete workflow above.\n\n**Exercise 2: Multi-temporal NDVI Analysis**\n\nCalculate NDVI composites for each month of 2024 over an agricultural area. Create a time series chart.\n\n**Exercise 3: Water Body Extraction**\n\nUse NDWI to extract all water bodies in a coastal province. Export as vector (polygons).\n\n**Exercise 4: SAR Flood Detection**\n\nCompare Sentinel-1 VV polarization before and after a typhoon to detect flooded areas.\n\n**Exercise 5: Export Training Data**\n\nCreate stratified random samples of different land cover classes and export as CSV for ML training.\n\n**Bonus: Integrate with Session 3**\n\nExport a GEE composite, then load it in Python (Session 3 techniques) to perform additional analysis with Rasterio.\n:::\n\n---\n\n## Further Reading\n\n### Official Documentation\n- [Earth Engine Guides](https://developers.google.com/earth-engine/guides)\n- [Python API Introduction](https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api)\n- [Sentinel-2 in GEE](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)\n- [Sentinel-1 Algorithms](https://developers.google.com/earth-engine/guides/sentinel1)\n\n### Tutorials\n- [End-to-End GEE Course](https://courses.spatialthoughts.com/end-to-end-gee.html)\n- [GBIF GEE Python Primer](https://data-blog.gbif.org/post/2025-01-29-understanding-google-earth-engine-gee-and-its-python-api-a-primer-for-gbif-users/)\n- [GEE Community Tutorials](https://developers.google.com/earth-engine/tutorials/community/explore)\n\n### Tools\n- [geemap Library](https://geemap.org/) - Interactive mapping in Python\n- [eemont](https://github.com/davemlz/eemont) - Extended functionality for GEE Python\n- [Awesome Earth Engine](https://github.com/giswqs/Awesome-GEE) - Curated resources\n\n---\n\n## Jupyter Notebook\n\n::: {.callout-note}\n## Access the Interactive Notebook\n\nA complete Jupyter notebook with all Google Earth Engine examples from this session is available:\n\n**[Open Notebook 2: Google Earth Engine →](../notebooks/notebook2.qmd)**\n\nThis notebook includes:\n- All code examples ready to run\n- Philippine case studies\n- Additional exercises\n- Export workflows\n- Troubleshooting guide\n:::\n\n---\n\n::: {.session-nav}\n::: {.session-nav-link href=\"session3.qmd\"}\n::: {.session-nav-label}\n← Previous\n:::\n::: {.session-nav-title}\nSession 3: Python for Geospatial Data\n:::\n:::\n::: {.session-nav-link href=\"../index.qmd\"}\n::: {.session-nav-label}\nDay 1 Complete!\n:::\n::: {.session-nav-title}\nBack to Home →\n:::\n:::\n:::\n","srcMarkdownNoYaml":"\n\n::: {.session-info}\n**Duration:** 2 hours | **Format:** Hands-on Coding | **Platform:** Google Colaboratory + Earth Engine Python API\n:::\n\n## Session Overview\n\nGoogle Earth Engine (GEE) is a planetary-scale platform for Earth science data and analysis. This session introduces you to GEE's Python API, enabling you to access Sentinel-1 and Sentinel-2 data, filter massive image collections, perform cloud masking, create temporal composites, and export processed data - all without downloading terabytes of imagery. You'll learn core GEE concepts and apply them to Philippine use cases.\n\n::: {.learning-objectives}\n### Learning Objectives\n\nBy the end of this session, you will be able to:\n\n- **Explain** what Google Earth Engine is and its advantages for EO\n- **Authenticate** and initialize the Earth Engine Python API\n- **Define** core GEE concepts: Image, ImageCollection, Feature, FeatureCollection\n- **Apply** filters (spatial, temporal, metadata) to image collections\n- **Access** Sentinel-1 GRD and Sentinel-2 SR data catalogs\n- **Implement** cloud masking using QA bands\n- **Create** temporal composites (median, mean) to reduce cloud cover\n- **Calculate** spectral indices (NDVI, NDWI) at scale\n- **Export** processed imagery to Google Drive\n- **Understand** GEE's capabilities and limitations for AI/ML workflows\n:::\n\n---\n\n## Part 1: What is Google Earth Engine?\n\n### Overview\n\n**Google Earth Engine** is a cloud-based platform combining:\n\n1. **Multi-petabyte catalog** of satellite imagery and geospatial datasets\n2. **Planetary-scale analysis capabilities** via Google's computational infrastructure\n3. **Code Editor** (JavaScript) and **Python API** for programmatic access\n\n::: {.callout-note}\n## Earth Engine by the Numbers\n\n- **40+ years** of historical imagery\n- **70+ petabytes** of data\n- **700+ datasets** including Landsat, Sentinel, MODIS, climate, terrain\n- **Global coverage** updated daily\n- **Free** for research, education, and non-profit use\n:::\n\n### Why Use Google Earth Engine?\n\n**Traditional workflow problems:**\n\n- Downloading terabytes of satellite data\n- Storing data locally (expensive storage)\n- Pre-processing each scene individually (time-consuming)\n- Limited computational resources for large-area analysis\n\n**Earth Engine solution:**\n\n```\n┌─────────────────────────────────────┐\n│   Your Computer                     │\n│   ┌──────────────┐                  │\n│   │ Write Code   │                  │\n│   │ (Python/JS)  │                  │\n│   └──────┬───────┘                  │\n│          │                           │\n│   ┌──────▼───────────────────────┐  │\n│   │ Send to Cloud                │  │\n│   └──────────────────────────────┘  │\n└──────────────┬──────────────────────┘\n               │\n               ▼\n┌──────────────────────────────────────────────┐\n│   Google Earth Engine Cloud                 │\n│   ┌──────────────┐  ┌──────────────┐        │\n│   │ Petabyte     │  │ Massive      │        │\n│   │ Data Catalog │  │ Computation  │        │\n│   └──────────────┘  └──────────────┘        │\n│                                              │\n│   Process → Results → Send back to you      │\n└──────────────────────────────────────────────┘\n```\n\n**Key advantages:**\n\n- **No downloading:** Data stays in Google's cloud\n- **Parallel processing:** Distributed computation across many machines\n- **Pre-processed data:** Analysis-ready collections (e.g., Sentinel-2 SR)\n- **Temporal analysis:** Easily work with time series\n- **Reproducible:** Share code, not gigabytes of data\n\n### Use Cases for Earth Observation\n\n**Ideal for:**\n\n- Large-area mapping (country/continent scale)\n- Multi-temporal analysis (time series, change detection)\n- Rapid prototyping and exploration\n- Cloud-based pre-processing\n- Teaching and learning (no infrastructure needed)\n\n**Less ideal for:**\n\n- Training custom deep learning models (CNNs, U-Net) - limited GPU support\n- Real-time processing requiring millisecond latency\n- Workflows requiring full control over hardware\n- Proprietary/restricted datasets not in GEE catalog\n\n::: {.philippine-context}\n**Philippine Applications:**\n\n- **National land cover mapping:** Process all of Philippines (~300,000 km²) at 10m resolution\n- **Multi-year deforestation monitoring:** Annual forest loss detection 2015-2025\n- **Typhoon impact assessment:** Before/after composites for disaster response\n- **Rice paddy monitoring:** Track planting/harvest cycles using SAR time series\n- **Coastal change detection:** Erosion and accretion mapping using optical+SAR\n:::\n\n---\n\n## Part 2: Setting Up Earth Engine in Python\n\n### Prerequisites\n\n::: {.callout-warning}\n## Required Setup\n\nBefore using Earth Engine, you must:\n\n1. **Google account** (Gmail or G Suite)\n2. **Earth Engine account** - Register at [earthengine.google.com](https://earthengine.google.com)\n3. **Cloud project** - Create or select a project after registration\n\n**Registration is FREE** and typically approved within 1-2 days.\n:::\n\n### Installation in Google Colab\n\nThe `earthengine-api` library is pre-installed in Colab, but let's ensure it's up-to-date:\n\n```python\n# Update Earth Engine API\n!pip install earthengine-api --upgrade -q\n\nprint(\"Earth Engine API updated! ✓\")\n```\n\n### Authentication & Initialization\n\n**First-time setup (one-time per environment):**\n\n```python\nimport ee\n\n# Authenticate (opens browser window for authorization)\nee.Authenticate()\n```\n\nThis will:\n1. Open a new browser tab\n2. Ask you to select your Google account\n3. Request permission to access Earth Engine\n4. Provide an authorization code\n5. Automatically apply the code\n\n::: {.callout-tip}\n## Authentication Troubleshooting\n\nIf authentication fails:\n\n1. Ensure you've registered at earthengine.google.com\n2. Check that you're using the same Google account\n3. Clear browser cookies and try again\n4. Use an incognito/private browsing window\n:::\n\n**Initialize Earth Engine (required every session):**\n\n```python\n# Initialize with your cloud project\n# Replace with your actual project ID\nee.Initialize(project='your-project-id')\n\nprint(\"Earth Engine initialized! ✓\")\n```\n\n**To find your project ID:**\n1. Go to [console.cloud.google.com](https://console.cloud.google.com)\n2. Select your project from the dropdown at the top\n3. Copy the Project ID (not Project Name)\n\n**Complete setup code:**\n\n```python\nimport ee\nimport geemap  # Interactive mapping library\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# Authenticate (first time only - comment out after first use)\n# ee.Authenticate()\n\n# Initialize\nee.Initialize(project='your-project-id')\n\n# Test that it works\nimage = ee.Image('USGS/SRTMGL1_003')\nprint(\"✓ Successfully connected to Earth Engine!\")\nprint(f\"  Test image bands: {image.bandNames().getInfo()}\")\n```\n\n---\n\n## Part 3: Core Earth Engine Concepts\n\n### The Building Blocks\n\nEarth Engine has a unique data model optimized for planetary-scale analysis:\n\n| Concept | Description | Example |\n|---------|-------------|---------|\n| **Image** | Single raster with multiple bands | One Sentinel-2 scene |\n| **ImageCollection** | Stack of images (time series) | All Sentinel-2 over Philippines in 2024 |\n| **Geometry** | Vector shapes | Point, polygon, line |\n| **Feature** | Geometry + properties (attributes) | Province polygon with name, population |\n| **FeatureCollection** | Multiple features | All Philippine provinces |\n\n### 1. Geometry\n\n**Define locations and areas of interest:**\n\n```python\n# Point (longitude, latitude)\nmanila = ee.Geometry.Point([121.0244, 14.5995])\n\n# Rectangle (min_lon, min_lat, max_lon, max_lat)\nbohol_bbox = ee.Geometry.Rectangle([123.8, 9.6, 124.6, 10.2])\n\n# Polygon (list of coordinate pairs)\ncustom_aoi = ee.Geometry.Polygon([\n    [[123.5, 9.5], [125.0, 9.5], [125.0, 11.0], [123.5, 11.0], [123.5, 9.5]]\n])\n\nprint(\"Geometries created! ✓\")\nprint(f\"Manila coordinates: {manila.coordinates().getInfo()}\")\nprint(f\"Bohol bbox area: {bohol_bbox.area().divide(1e6).getInfo():.2f} km²\")\n```\n\n### 2. Image\n\n**Single raster image with one or more bands:**\n\n```python\n# Load a Sentinel-2 image by ID\nsentinel2_image = ee.Image('COPERNICUS/S2_SR/20240315T015701_20240315T015659_T51PWN')\n\n# Examine properties\nprint(\"Image ID:\", sentinel2_image.id().getInfo())\nprint(\"Band names:\", sentinel2_image.bandNames().getInfo())\nprint(\"Cloud cover:\", sentinel2_image.get('CLOUDY_PIXEL_PERCENTAGE').getInfo(), \"%\")\n\n# Select specific bands\nrgb_bands = sentinel2_image.select(['B4', 'B3', 'B2'])  # Red, Green, Blue\n```\n\n**Image operations:**\n\n```python\n# Calculate NDVI for single image\nndvi = sentinel2_image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n\n# Add as band to original image\nimage_with_ndvi = sentinel2_image.addBands(ndvi)\n\nprint(\"NDVI band added! ✓\")\n```\n\n### 3. ImageCollection\n\n**Stack of images (time series):**\n\n```python\n# Load Sentinel-2 collection\ns2_collection = ee.ImageCollection('COPERNICUS/S2_SR')\n\n# Check collection size (can be huge!)\nprint(\"Total Sentinel-2 images in catalog:\", s2_collection.size().getInfo())\n# This will be millions!\n```\n\n**ImageCollection operations:**\n\n```python\n# Filter by date, location, and cloud cover\nfiltered = (s2_collection\n    .filterBounds(bohol_bbox)\n    .filterDate('2024-01-01', '2024-12-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30)))\n\nprint(f\"Filtered to {filtered.size().getInfo()} images over Bohol in 2024 with <30% clouds\")\n\n# Get image at specific index\nfirst_image = ee.Image(filtered.first())\nprint(\"First image date:\", first_image.date().format('YYYY-MM-dd').getInfo())\n```\n\n### 4. Feature & FeatureCollection\n\n**Vector data with attributes:**\n\n```python\n# Single feature (geometry + properties)\nmanila_feature = ee.Feature(\n    ee.Geometry.Point([121.0244, 14.5995]),\n    {'name': 'Manila', 'population': 1780148, 'country': 'Philippines'}\n)\n\nprint(\"Feature:\", manila_feature.getInfo())\n\n# Load feature collection (e.g., GADM administrative boundaries)\nphilippines = ee.FeatureCollection('FAO/GAUL/2015/level1').filter(\n    ee.Filter.eq('ADM0_NAME', 'Philippines')\n)\n\nprint(f\"Philippine provinces: {philippines.size().getInfo()}\")\n```\n\n---\n\n## Part 4: Filtering and Querying Data\n\n### Filter Types\n\nEarth Engine provides powerful filtering to reduce massive collections to relevant data.\n\n#### 1. Spatial Filtering\n\n**filterBounds() - Keep images intersecting a geometry:**\n\n```python\n# Define AOI\npalawan = ee.Geometry.Rectangle([117.5, 8.0, 119.5, 12.0])\n\n# Filter Sentinel-2 to Palawan\ns2_palawan = ee.ImageCollection('COPERNICUS/S2_SR').filterBounds(palawan)\n\nprint(f\"Total Sentinel-2 images over Palawan: {s2_palawan.size().getInfo()}\")\n```\n\n#### 2. Temporal Filtering\n\n**filterDate() - Keep images within date range:**\n\n```python\n# Dry season 2024\ndry_season = s2_palawan.filterDate('2024-01-01', '2024-05-31')\nprint(f\"Dry season images: {dry_season.size().getInfo()}\")\n\n# Wet season 2024\nwet_season = s2_palawan.filterDate('2024-06-01', '2024-11-30')\nprint(f\"Wet season images: {wet_season.size().getInfo()}\")\n```\n\n#### 3. Metadata Filtering\n\n**filter() - Custom filters on image properties:**\n\n```python\n# Low cloud cover\nclear_images = dry_season.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\nprint(f\"Clear images (<10% clouds): {clear_images.size().getInfo()}\")\n\n# Specific satellite\ns2a_only = dry_season.filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2A'))\nprint(f\"Sentinel-2A only: {s2a_only.size().getInfo()}\")\n\n# Multiple conditions\nbest_images = (dry_season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 5))\n    .filter(ee.Filter.eq('SPACECRAFT_NAME', 'Sentinel-2B'))\n)\nprint(f\"Best images (S-2B, <5% clouds): {best_images.size().getInfo()}\")\n```\n\n### Chain Filters for Precision\n\n**Combine multiple filters:**\n\n```python\n# Define AOI for Bohol\nbohol_aoi = ee.Geometry.Rectangle([123.8, 9.6, 124.6, 10.2])\n\n# Multi-filter pipeline\nbohol_images = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-03-01', '2024-05-31')  # Dry season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n    .select(['B2', 'B3', 'B4', 'B8', 'B11', 'B12', 'QA60']))  # Relevant bands\n\nprint(\"=\" * 50)\nprint(f\"Bohol Image Collection (Dry Season 2024)\")\nprint(\"=\" * 50)\nprint(f\"  Total images: {bohol_images.size().getInfo()}\")\nprint(f\"  Date range: {bohol_images.aggregate_min('system:time_start').getInfo()} to {bohol_images.aggregate_max('system:time_start').getInfo()}\")\nprint(\"=\" * 50)\n```\n\n---\n\n## Part 5: Working with Sentinel Data in GEE\n\n### Sentinel-2 Surface Reflectance\n\n**Collection ID:** `COPERNICUS/S2_SR`\n\n**Key information:**\n\n- **Level:** Level-2A (atmospherically corrected surface reflectance)\n- **Bands:** 13 spectral bands (B1-B12, plus QA60)\n- **Resolution:** 10m (B2-B4, B8), 20m (B5-B7, B8A, B11-B12), 60m (B1, B9, B10)\n- **Revisit:** 5 days (constellation)\n- **Updates:** Near real-time (within days of acquisition)\n\n**Band naming in GEE:**\n\n| Band | Name | Wavelength | Resolution | Use |\n|------|------|------------|------------|-----|\n| B2 | Blue | 490 nm | 10m | Atmospheric, water |\n| B3 | Green | 560 nm | 10m | Vegetation, water |\n| B4 | Red | 665 nm | 10m | Vegetation discrimination |\n| B8 | NIR | 842 nm | 10m | Biomass, vegetation |\n| B11 | SWIR1 | 1610 nm | 20m | Moisture, soil/vegetation |\n| B12 | SWIR2 | 2190 nm | 20m | Moisture, geology |\n| QA60 | Quality | - | 60m | Cloud mask |\n\n**Load and visualize:**\n\n```python\n# Load collection\ns2 = ee.ImageCollection('COPERNICUS/S2_SR')\n\n# Filter to area and time\nimage = (s2\n    .filterBounds(ee.Geometry.Point([124.0, 10.0]))  # Bohol\n    .filterDate('2024-03-01', '2024-03-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n    .first())\n\n# Visualize with geemap (interactive mapping)\nimport geemap\n\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nvis_params = {\n    'bands': ['B4', 'B3', 'B2'],\n    'min': 0,\n    'max': 3000,\n    'gamma': 1.4\n}\nMap.addLayer(image, vis_params, 'Sentinel-2 True Color')\nMap\n```\n\n### Sentinel-1 SAR\n\n**Collection ID:** `COPERNICUS/S1_GRD`\n\n**Key information:**\n\n- **Level:** Level-1 Ground Range Detected (GRD)\n- **Polarization:** VV, VH (or HH, HV depending on mode)\n- **Resolution:** 10m (IW mode)\n- **Revisit:** 6-12 days\n- **Advantages:** All-weather, day-night imaging\n\n**Load Sentinel-1:**\n\n```python\n# Load Sentinel-1 collection\ns1 = ee.ImageCollection('COPERNICUS/S1_GRD')\n\n# Filter for ascending pass, IW mode, VV+VH polarization\ns1_filtered = (s1\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-06-01', '2024-08-31')  # Wet season\n    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VV'))\n    .filter(ee.Filter.listContains('transmitterReceiverPolarisation', 'VH'))\n    .filter(ee.Filter.eq('instrumentMode', 'IW'))\n    .filter(ee.Filter.eq('orbitProperties_pass', 'ASCENDING'))\n    .select(['VV', 'VH']))\n\nprint(f\"Sentinel-1 images: {s1_filtered.size().getInfo()}\")\n\n# Visualize\ns1_image = s1_filtered.median()  # Median composite\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(s1_image, {'bands': ['VV'], 'min': -25, 'max': 0}, 'S1 VV')\nMap.addLayer(s1_image, {'bands': ['VH'], 'min': -30, 'max': -5}, 'S1 VH')\nMap\n```\n\n---\n\n## Part 6: Cloud Masking and Preprocessing\n\n### Why Cloud Masking?\n\n**Problems with clouds:**\n\n- Obscure ground features\n- Contaminate spectral indices\n- Reduce classification accuracy\n- Create artifacts in composites\n\n**Solution:** Use quality assessment (QA) bands to identify and mask clouds.\n\n### Sentinel-2 Cloud Masking\n\n**Sentinel-2 includes QA60 band:**\n\n- Bit 10: Opaque clouds\n- Bit 11: Cirrus clouds\n\n**Cloud masking function:**\n\n```python\ndef mask_s2_clouds(image):\n    \"\"\"Mask clouds using QA60 band.\"\"\"\n    qa = image.select('QA60')\n\n    # Bits 10 and 11 are clouds and cirrus\n    cloud_bit_mask = 1 << 10\n    cirrus_bit_mask = 1 << 11\n\n    # Both flags should be zero = clear\n    mask = (qa.bitwiseAnd(cloud_bit_mask).eq(0)\n            .And(qa.bitwiseAnd(cirrus_bit_mask).eq(0)))\n\n    # Return masked image, scaled to reflectance (0-1)\n    return image.updateMask(mask).divide(10000)\n\n# Apply to collection\ns2_masked = bohol_images.map(mask_s2_clouds)\n\nprint(\"Cloud masking applied! ✓\")\n```\n\n::: {.callout-note}\n## Understanding Bitwise Operations\n\n**QA60 band stores flags as bits:**\n\n```\nQA60 = 1024 (binary: 10000000000)\n         Bit 10 is set → Cloud present\n\nBit mask:\ncloud_bit_mask = 1 << 10 = 1024\nqa.bitwiseAnd(cloud_bit_mask) extracts bit 10\n.eq(0) checks if bit is 0 (no cloud)\n```\n\nThis efficient encoding allows multiple flags in one band!\n:::\n\n### Advanced Cloud Masking with SCL\n\n**Scene Classification Layer (SCL) band provides detailed classification:**\n\n```python\ndef mask_s2_clouds_scl(image):\n    \"\"\"Advanced cloud masking using SCL band.\"\"\"\n    scl = image.select('SCL')\n\n    # SCL values:\n    # 3 = cloud shadows\n    # 8 = cloud medium probability\n    # 9 = cloud high probability\n    # 10 = thin cirrus\n    # 11 = snow/ice\n\n    # Keep only vegetation (4), bare soil (5), water (6)\n    mask = scl.eq(4).Or(scl.eq(5)).Or(scl.eq(6))\n\n    return image.updateMask(mask).divide(10000)\n\n# Note: Need to load SCL band\ns2_with_scl = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-03-01', '2024-05-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 20))\n    .select(['B2', 'B3', 'B4', 'B8', 'SCL']))\n\ns2_masked_scl = s2_with_scl.map(mask_s2_clouds_scl)\n```\n\n---\n\n## Part 7: Creating Temporal Composites\n\n### Why Composites?\n\n**Challenges in tropical regions (like Philippines):**\n\n- Frequent cloud cover (>60% annual average)\n- Difficult to find single cloud-free scene\n- Monsoon seasons worsen problem\n\n**Solution: Temporal compositing**\n\nCombine multiple images over time to create cloud-free mosaic.\n\n### Composite Methods\n\n#### 1. Median Composite\n\n**Most common - robust to outliers:**\n\n```python\n# Create median composite (dry season 2024)\ncomposite_median = s2_masked.median()\n\nprint(\"Median composite created! ✓\")\n\n# Visualize\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nvis_params = {\n    'bands': ['B4', 'B3', 'B2'],\n    'min': 0,\n    'max': 0.3,\n    'gamma': 1.4\n}\nMap.addLayer(composite_median, vis_params, 'Median Composite (Dry Season)')\nMap\n```\n\n**Why median?**\n\n- Middle value of sorted pixel values over time\n- Removes clouds (typically brightest values)\n- Removes shadows (typically darkest values)\n- Preserves realistic surface reflectance\n\n#### 2. Mean Composite\n\n**Average of all pixels:**\n\n```python\ncomposite_mean = s2_masked.mean()\n\n# Smoother than median, but sensitive to remaining clouds\n```\n\n#### 3. Greenest Pixel Composite\n\n**Select pixel with highest NDVI (most vegetated):**\n\n```python\ndef add_ndvi(image):\n    \"\"\"Add NDVI band to image.\"\"\"\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n    return image.addBands(ndvi)\n\n# Add NDVI to all images\ns2_with_ndvi = s2_masked.map(add_ndvi)\n\n# Get maximum NDVI composite (greenest pixel)\ncomposite_max_ndvi = s2_with_ndvi.qualityMosaic('NDVI')\n\nMap.addLayer(composite_max_ndvi, vis_params, 'Greenest Pixel Composite')\n```\n\n### Multi-temporal Analysis\n\n**Compare dry vs. wet season:**\n\n```python\n# Dry season composite (Jan-May)\ndry_season = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-01-01', '2024-05-31')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .map(mask_s2_clouds)\n    .median())\n\n# Wet season composite (Jun-Nov)\nwet_season = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(bohol_aoi)\n    .filterDate('2024-06-01', '2024-11-30')\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .map(mask_s2_clouds)\n    .median())\n\n# Calculate NDVI for both\ndry_ndvi = dry_season.normalizedDifference(['B8', 'B4'])\nwet_ndvi = wet_season.normalizedDifference(['B8', 'B4'])\n\n# NDVI difference (wet - dry)\nndvi_change = wet_ndvi.subtract(dry_ndvi)\n\n# Visualize\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(dry_season, vis_params, 'Dry Season')\nMap.addLayer(wet_season, vis_params, 'Wet Season')\nMap.addLayer(ndvi_change, {'min': -0.3, 'max': 0.3, 'palette': ['red', 'white', 'green']},\n             'NDVI Change (Wet-Dry)')\nMap\n```\n\n::: {.philippine-context}\n**Interpretation for Philippines:**\n\n- **Green areas (positive change):** Rice paddies planted during wet season, increased vegetation vigor\n- **Red areas (negative change):** Areas with less vegetation in wet season (possibly fallow, harvested, or flooded)\n- **White areas (no change):** Stable land cover (evergreen forest, urban)\n:::\n\n---\n\n## Part 8: Calculating Spectral Indices at Scale\n\n### NDVI (Vegetation Health)\n\n```python\ndef calculate_ndvi(image):\n    \"\"\"Calculate NDVI for an image.\"\"\"\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n    return image.addBands(ndvi)\n\n# Apply to collection\ns2_with_ndvi = s2_masked.map(calculate_ndvi)\n\n# Get NDVI composite\nndvi_composite = s2_with_ndvi.select('NDVI').median()\n\n# Visualize\nndvi_params = {\n    'min': 0,\n    'max': 1,\n    'palette': ['red', 'yellow', 'green']\n}\nMap = geemap.Map(center=[10.0, 124.0], zoom=9)\nMap.addLayer(ndvi_composite, ndvi_params, 'NDVI Composite')\nMap\n```\n\n### NDWI (Water Bodies)\n\n```python\ndef calculate_ndwi(image):\n    \"\"\"Calculate NDWI for water detection.\"\"\"\n    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n    return image.addBands(ndwi)\n\ns2_with_ndwi = s2_masked.map(calculate_ndwi)\nndwi_composite = s2_with_ndwi.select('NDWI').median()\n\n# Extract water bodies (NDWI > 0.3)\nwater_mask = ndwi_composite.gt(0.3)\n\nMap.addLayer(water_mask.selfMask(), {'palette': 'blue'}, 'Water Bodies')\n```\n\n### Multiple Indices\n\n```python\ndef add_indices(image):\n    \"\"\"Add multiple spectral indices.\"\"\"\n    # NDVI\n    ndvi = image.normalizedDifference(['B8', 'B4']).rename('NDVI')\n\n    # NDWI\n    ndwi = image.normalizedDifference(['B3', 'B8']).rename('NDWI')\n\n    # NDBI (Built-up)\n    ndbi = image.normalizedDifference(['B11', 'B8']).rename('NDBI')\n\n    # EVI (Enhanced Vegetation Index)\n    evi = image.expression(\n        '2.5 * ((NIR - RED) / (NIR + 6 * RED - 7.5 * BLUE + 1))',\n        {\n            'NIR': image.select('B8'),\n            'RED': image.select('B4'),\n            'BLUE': image.select('B2')\n        }\n    ).rename('EVI')\n\n    return image.addBands([ndvi, ndwi, ndbi, evi])\n\n# Apply to collection\ns2_with_indices = s2_masked.map(add_indices)\n\n# Create composite with all indices\nmulti_index_composite = s2_with_indices.median()\n\nprint(\"Bands in composite:\", multi_index_composite.bandNames().getInfo())\n```\n\n---\n\n## Part 9: Exporting Data from Earth Engine\n\n### Export to Google Drive\n\n**Why export?**\n\n- Use data outside Earth Engine\n- Train ML models locally or in Colab\n- Share processed results\n- Create high-resolution figures\n\n**Export image:**\n\n```python\n# Define export region (use AOI)\nexport_region = bohol_aoi\n\n# Export composite to Drive\nexport_task = ee.batch.Export.image.toDrive(\n    image=composite_median.select(['B2', 'B3', 'B4', 'B8']),\n    description='Bohol_S2_Median_Dry2024',\n    folder='CopPhil_Training',\n    fileNamePrefix='bohol_s2_composite',\n    region=export_region,\n    scale=10,  # Resolution in meters\n    crs='EPSG:32651',  # UTM Zone 51N\n    maxPixels=1e9,\n    fileFormat='GeoTIFF'\n)\n\n# Start export task\nexport_task.start()\n\nprint(\"Export task started! ✓\")\nprint(\"Check status at: https://code.earthengine.google.com/tasks\")\n```\n\n**Monitor export:**\n\n```python\nimport time\n\n# Check task status\ntask_id = export_task.id\nprint(f\"Task ID: {task_id}\")\n\n# Poll until complete (check every 30 seconds)\nwhile export_task.active():\n    print(f\"  Status: {export_task.status()['state']} ...\")\n    time.sleep(30)\n\nprint(f\"✓ Export complete! Status: {export_task.status()['state']}\")\n```\n\n### Export Options\n\n**1. Export to Google Drive (easiest):**\n\n```python\nee.batch.Export.image.toDrive()\n```\n\n**2. Export to Cloud Storage:**\n\n```python\nee.batch.Export.image.toCloudStorage(\n    image=image,\n    bucket='your-gcs-bucket',\n    fileNamePrefix='path/to/file',\n    ...\n)\n```\n\n**3. Export to Asset (for reuse in GEE):**\n\n```python\nee.batch.Export.image.toAsset(\n    image=image,\n    description='MyAsset',\n    assetId='users/your-username/your-asset-name',\n    ...\n)\n```\n\n### Export FeatureCollection (Vector)\n\n**Export classification results or statistics:**\n\n```python\n# Create sample points with NDVI values\nsample_points = ndvi_composite.sample(\n    region=bohol_aoi,\n    scale=100,\n    numPixels=1000,\n    geometries=True\n)\n\n# Export to Drive\nexport_vector = ee.batch.Export.table.toDrive(\n    collection=sample_points,\n    description='Bohol_NDVI_Samples',\n    folder='CopPhil_Training',\n    fileFormat='CSV'\n)\n\nexport_vector.start()\nprint(\"Vector export started! ✓\")\n```\n\n---\n\n## Part 10: Best Practices and Limitations\n\n### Best Practices\n\n::: {.callout-tip}\n## GEE Workflow Tips\n\n1. **Filter aggressively:** Reduce collection size before processing\n2. **Use Cloud masking:** Always mask clouds for optical data\n3. **Scale matters:** Choose appropriate scale for export (don't over-sample)\n4. **Test on small areas:** Prototype with small AOI before scaling up\n5. **Monitor quotas:** Be aware of computation and storage limits\n6. **Reproducibility:** Save scripts, document parameters\n7. **Leverage built-in functions:** Don't reinvent the wheel\n:::\n\n### Computational Limits\n\n**Earth Engine has quotas (free tier):**\n\n- **Simultaneous requests:** Limited concurrent computations\n- **Export size:** Max 100,000 pixels per dimension\n- **Asset storage:** Limited space for uploaded/exported assets\n- **Processing time:** Long-running tasks may timeout\n\n**Solutions:**\n\n- Break large exports into tiles\n- Use reduce() operations instead of getInfo() for large data\n- Export to Asset for intermediate results\n- Consider upgrading to commercial tier for production workflows\n\n### Limitations for AI/ML\n\n**What GEE does well:**\n\n- Data access and pre-processing\n- Large-scale feature extraction\n- Random Forest / CART classification\n- Pixel-based analysis\n\n**What GEE struggles with:**\n\n- Training deep learning models (CNNs, U-Net, LSTMs)\n- Custom loss functions and optimizers\n- GPU-accelerated training\n- Complex model architectures requiring TensorFlow/PyTorch\n\n::: {.callout-note}\n## Recommended Workflow for Deep Learning\n\n1. **Use GEE for:** Data discovery, filtering, cloud masking, compositing, exporting training patches\n2. **Use Python (Colab/local) for:** Training CNNs/U-Nets with TensorFlow or PyTorch\n3. **Return to GEE for:** Applying trained model at scale (if feasible) or export tiles for prediction\n:::\n\n---\n\n## Part 11: Complete Example: Philippine Land Cover Composite\n\n**Scenario:** Create cloud-free RGB and NDVI composites for entire Palawan province.\n\n```python\n# 1. Define AOI (Palawan province)\npalawan = ee.Geometry.Rectangle([117.5, 8.0, 119.5, 12.0])\n\n# 2. Load and filter Sentinel-2\ns2_palawan = (ee.ImageCollection('COPERNICUS/S2_SR')\n    .filterBounds(palawan)\n    .filterDate('2024-01-01', '2024-05-31')  # Dry season\n    .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n    .select(['B2', 'B3', 'B4', 'B8', 'QA60']))\n\nprint(f\"Images in collection: {s2_palawan.size().getInfo()}\")\n\n# 3. Apply cloud masking\ndef mask_clouds(image):\n    qa = image.select('QA60')\n    cloud_mask = qa.bitwiseAnd(1 << 10).eq(0).And(qa.bitwiseAnd(1 << 11).eq(0))\n    return image.updateMask(cloud_mask).divide(10000)\n\ns2_masked = s2_palawan.map(mask_clouds)\n\n# 4. Create median composite\ncomposite = s2_masked.median()\n\n# 5. Calculate NDVI\nndvi = composite.normalizedDifference(['B8', 'B4']).rename('NDVI')\ncomposite_with_ndvi = composite.addBands(ndvi)\n\n# 6. Visualize\nMap = geemap.Map(center=[10.0, 118.5], zoom=8)\n\nrgb_vis = {'bands': ['B4', 'B3', 'B2'], 'min': 0, 'max': 0.3, 'gamma': 1.4}\nndvi_vis = {'bands': ['NDVI'], 'min': 0, 'max': 1, 'palette': ['brown', 'yellow', 'green', 'darkgreen']}\n\nMap.addLayer(composite, rgb_vis, 'Palawan True Color')\nMap.addLayer(composite_with_ndvi, ndvi_vis, 'Palawan NDVI')\nMap\n\n# 7. Export to Drive\nexport_rgb = ee.batch.Export.image.toDrive(\n    image=composite.select(['B4', 'B3', 'B2']),\n    description='Palawan_RGB_DryS2024',\n    folder='CopPhil_Training',\n    region=palawan,\n    scale=10,\n    maxPixels=1e10,\n    fileFormat='GeoTIFF'\n)\n\nexport_ndvi = ee.batch.Export.image.toDrive(\n    image=ndvi,\n    description='Palawan_NDVI_DryS2024',\n    folder='CopPhil_Training',\n    region=palawan,\n    scale=10,\n    maxPixels=1e10,\n    fileFormat='GeoTIFF'\n)\n\nexport_rgb.start()\nexport_ndvi.start()\n\nprint(\"=\" * 60)\nprint(\"PALAWAN LAND COVER COMPOSITE - EXPORT STARTED\")\nprint(\"=\" * 60)\nprint(\"RGB Composite: Check Google Drive in ~10-30 minutes\")\nprint(\"NDVI Layer: Check Google Drive in ~10-30 minutes\")\nprint(\"Monitor at: https://code.earthengine.google.com/tasks\")\nprint(\"=\" * 60)\n```\n\n---\n\n## Key Takeaways\n\n::: {.callout-important}\n## Session 4 Summary\n\n**Google Earth Engine:**\n- Cloud platform with petabytes of EO data\n- No downloading required - process in cloud\n- Free for research/education\n\n**Core Concepts:**\n- Image / ImageCollection for rasters\n- Feature / FeatureCollection for vectors\n- Geometry for locations and AOIs\n\n**Key Operations:**\n- Filter by bounds, date, metadata\n- Cloud masking using QA bands\n- Temporal composites (median, mean)\n- Spectral indices (NDVI, NDWI)\n- Export to Drive/Cloud Storage\n\n**Workflow:**\n1. Define AOI\n2. Filter collection\n3. Mask clouds\n4. Create composite\n5. Calculate indices\n6. Visualize\n7. Export\n\n**Best for:** Pre-processing, data access, Random Forest, large-area mapping\n\n**Use Python/TensorFlow for:** Deep learning model training\n\n**Next steps:** Apply these skills in Days 2-4 for land cover classification, flood mapping, and time series analysis!\n:::\n\n---\n\n## Practice Exercises\n\n::: {.callout-tip}\n## Try These Challenges\n\n**Exercise 1: Your Province Composite**\n\nCreate a cloud-free Sentinel-2 composite for your home province using the complete workflow above.\n\n**Exercise 2: Multi-temporal NDVI Analysis**\n\nCalculate NDVI composites for each month of 2024 over an agricultural area. Create a time series chart.\n\n**Exercise 3: Water Body Extraction**\n\nUse NDWI to extract all water bodies in a coastal province. Export as vector (polygons).\n\n**Exercise 4: SAR Flood Detection**\n\nCompare Sentinel-1 VV polarization before and after a typhoon to detect flooded areas.\n\n**Exercise 5: Export Training Data**\n\nCreate stratified random samples of different land cover classes and export as CSV for ML training.\n\n**Bonus: Integrate with Session 3**\n\nExport a GEE composite, then load it in Python (Session 3 techniques) to perform additional analysis with Rasterio.\n:::\n\n---\n\n## Further Reading\n\n### Official Documentation\n- [Earth Engine Guides](https://developers.google.com/earth-engine/guides)\n- [Python API Introduction](https://developers.google.com/earth-engine/tutorials/community/intro-to-python-api)\n- [Sentinel-2 in GEE](https://developers.google.com/earth-engine/datasets/catalog/COPERNICUS_S2_SR)\n- [Sentinel-1 Algorithms](https://developers.google.com/earth-engine/guides/sentinel1)\n\n### Tutorials\n- [End-to-End GEE Course](https://courses.spatialthoughts.com/end-to-end-gee.html)\n- [GBIF GEE Python Primer](https://data-blog.gbif.org/post/2025-01-29-understanding-google-earth-engine-gee-and-its-python-api-a-primer-for-gbif-users/)\n- [GEE Community Tutorials](https://developers.google.com/earth-engine/tutorials/community/explore)\n\n### Tools\n- [geemap Library](https://geemap.org/) - Interactive mapping in Python\n- [eemont](https://github.com/davemlz/eemont) - Extended functionality for GEE Python\n- [Awesome Earth Engine](https://github.com/giswqs/Awesome-GEE) - Curated resources\n\n---\n\n## Jupyter Notebook\n\n::: {.callout-note}\n## Access the Interactive Notebook\n\nA complete Jupyter notebook with all Google Earth Engine examples from this session is available:\n\n**[Open Notebook 2: Google Earth Engine →](../notebooks/notebook2.qmd)**\n\nThis notebook includes:\n- All code examples ready to run\n- Philippine case studies\n- Additional exercises\n- Export workflows\n- Troubleshooting guide\n:::\n\n---\n\n::: {.session-nav}\n::: {.session-nav-link href=\"session3.qmd\"}\n::: {.session-nav-label}\n← Previous\n:::\n::: {.session-nav-title}\nSession 3: Python for Geospatial Data\n:::\n:::\n::: {.session-nav-link href=\"../index.qmd\"}\n::: {.session-nav-label}\nDay 1 Complete!\n:::\n::: {.session-nav-title}\nBack to Home →\n:::\n:::\n:::\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["include-code-files"],"css":["../styles/custom.css"],"toc":true,"toc-depth":3,"number-sections":false,"output-file":"session4.html"},"language":{"toc-title-document":"Contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Instructor","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Date","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","comments":{"hypothesis":false,"utterances":{"repo":"copphil-training/day1"}},"theme":{"light":["cosmo","../styles/custom.scss"],"dark":["darkly","../styles/custom.scss"]},"toc-expand":2,"toc-title":"On This Page","code-copy":true,"smooth-scroll":true,"anchor-sections":true,"fig-cap-location":"bottom","tbl-cap-location":"top","citations-hover":true,"footnotes-hover":true,"title":"Session 4: Introduction to Google Earth Engine","subtitle":"Harness cloud computing power to access and process petabytes of Earth observation data","date":"last-modified"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}
{"title":"Glossary","markdown":{"yaml":{"title":"Glossary","subtitle":"Earth Observation & AI/ML Terms","date":"last-modified"},"headingText":"How to Use This Glossary","containsRefs":false,"markdown":"\n\n\nThis glossary defines key terms used throughout the CoPhil EO AI/ML Training Programme. Terms are organized alphabetically within categories for easy reference.\n\n**Categories:**\n- [Earth Observation Terms](#earth-observation-terms)\n- [AI/ML Terms](#aiml-terms)\n- [Geospatial Data Terms](#geospatial-data-terms)\n- [Satellite & Sensor Terms](#satellite-sensor-terms)\n- [Philippine EO Organizations](#philippine-eo-organizations)\n- [Technical Acronyms](#technical-acronyms)\n\n---\n\n## Earth Observation Terms\n\n### Absorption Band\nWavelength region where atmospheric gases (water vapor, oxygen, CO2) absorb electromagnetic radiation, limiting remote sensing capabilities.\n\n### Backscatter\nThe portion of radar energy reflected back to the sensor from a target. Used in SAR imaging to detect surface properties and moisture.\n\n### Cloud Masking\nThe process of identifying and removing cloud-contaminated pixels from optical satellite imagery to improve data quality.\n\n### Composite Image\nA single image created by combining multiple images from different dates, often using statistical methods (median, mean) to reduce noise and clouds.\n\n### Earth Observation (EO)\nThe gathering of information about Earth's physical, chemical, and biological systems through remote sensing technologies, primarily satellites.\n\n### False Color Composite\nAn image display where spectral bands are assigned to RGB colors differently than natural vision (e.g., NIR-Red-Green), revealing features invisible to the human eye.\n\n### Ground Truth\nField-collected reference data used to validate remote sensing classifications and train machine learning models.\n\n### Image Collection\nA set of satellite images covering the same geographic area at different times, used for time series analysis.\n\n### Pixel\nThe smallest unit in a raster image, representing a specific ground area (spatial resolution) and spectral value.\n\n### Preprocessing\nSteps taken to correct raw satellite data before analysis, including atmospheric correction, geometric correction, and radiometric calibration.\n\n### Remote Sensing\nThe science of obtaining information about objects or areas from a distance, typically using sensors on satellites or aircraft.\n\n### Revisit Time\nThe frequency with which a satellite can observe the same location on Earth (e.g., Sentinel-2 has 5-day revisit with 3 satellites).\n\n### Spectral Signature\nThe unique reflectance pattern of an object across different wavelengths, used to identify materials and land cover types.\n\n### True Color Composite\nAn image display using red, green, and blue bands to create a natural-looking image similar to human vision.\n\n---\n\n## AI/ML Terms\n\n### Activation Function\nMathematical function in neural networks that introduces non-linearity (e.g., ReLU, Sigmoid, Tanh), enabling learning of complex patterns.\n\n### Artificial Intelligence (AI)\nComputer systems capable of performing tasks that typically require human intelligence, including perception, reasoning, and decision-making.\n\n### Backpropagation\nAlgorithm for training neural networks by calculating gradients of loss and adjusting weights to minimize error.\n\n### Batch Size\nNumber of training samples processed before updating model weights. Smaller batches = more updates but noisier; larger batches = smoother but fewer updates.\n\n### Classification\nSupervised learning task of assigning input data to predefined categories (e.g., forest, water, urban).\n\n### Clustering\nUnsupervised learning technique that groups similar data points together without predefined labels (e.g., K-means, DBSCAN).\n\n### Confusion Matrix\nTable showing predicted vs. actual classifications, used to calculate accuracy, precision, recall, and F1-score.\n\n### Convolutional Neural Network (CNN)\nDeep learning architecture specialized for image analysis, using convolutional layers to detect spatial patterns.\n\n### Data Augmentation\nTechnique to artificially increase training data by applying transformations (rotation, flipping, scaling) to existing samples.\n\n### Deep Learning\nSubset of machine learning using multi-layer neural networks to learn hierarchical representations of data.\n\n### Epoch\nOne complete pass through the entire training dataset during model training.\n\n### Feature Engineering\nThe process of creating new input variables from raw data to improve model performance.\n\n### Feature Extraction\nIdentifying and extracting relevant patterns or characteristics from raw data for use in machine learning models.\n\n### Ground Truth Labels\nVerified, accurate labels for training data, typically from field surveys or expert interpretation.\n\n### Hyperparameter\nModel configuration setting chosen before training (e.g., learning rate, number of layers) that affects model performance.\n\n### Loss Function\nMathematical function measuring the difference between predicted and actual values, used to guide model training.\n\n### Machine Learning (ML)\nSubset of AI enabling systems to learn and improve from experience without explicit programming.\n\n### Neural Network\nComputing system inspired by biological brains, consisting of interconnected nodes (neurons) organized in layers.\n\n### Overfitting\nWhen a model learns training data too well, including noise, resulting in poor performance on new data.\n\n### Precision\nProportion of positive predictions that are actually correct. Precision = TP / (TP + FP).\n\n### Random Forest\nEnsemble learning method using multiple decision trees to improve prediction accuracy and reduce overfitting.\n\n### Recall (Sensitivity)\nProportion of actual positives correctly identified. Recall = TP / (TP + FN).\n\n### Regression\nSupervised learning task of predicting continuous numerical values (e.g., crop yield, temperature).\n\n### Supervised Learning\nMachine learning where models learn from labeled training data (input-output pairs).\n\n### Support Vector Machine (SVM)\nClassification algorithm that finds the optimal hyperplane separating different classes in feature space.\n\n### Training Set\nPortion of data used to train a machine learning model (typically 70-80% of total data).\n\n### Transfer Learning\nReusing a pre-trained model on a new but related task, reducing training time and data requirements.\n\n### Underfitting\nWhen a model is too simple to capture the underlying patterns in data, resulting in poor performance.\n\n### Unsupervised Learning\nMachine learning where models find patterns in unlabeled data without predefined categories.\n\n### Validation Set\nData used to evaluate model performance during training and tune hyperparameters (typically 10-15% of data).\n\n---\n\n## Geospatial Data Terms\n\n### Affine Transformation\nMathematical operation describing the relationship between pixel coordinates and geographic coordinates in raster data.\n\n### Bounding Box\nRectangular area defined by minimum and maximum coordinates [minX, minY, maxX, maxY], used to specify geographic extents.\n\n### Coordinate Reference System (CRS)\nSystem defining how coordinates relate to real-world locations, including datum and projection (e.g., WGS84, UTM).\n\n### Digital Elevation Model (DEM)\nRaster representation of terrain elevation, with each pixel value representing height above a reference level.\n\n### Feature\nIn geospatial terms, a vector object (point, line, or polygon) with associated attributes.\n\n### GeoJSON\nOpen standard JSON format for encoding geographic data structures, widely used for web mapping.\n\n### GeoPackage\nOpen format for geospatial data storage in SQLite database, supporting both vector and raster data.\n\n### Geometry\nThe spatial component of a geographic feature, defining its shape and location (point, line, polygon).\n\n### GeoTIFF\nRaster image format with embedded geographic metadata (CRS, extent, resolution), standard for geospatial raster data.\n\n### NoData Value\nSpecial value in raster data indicating missing or invalid data (e.g., -9999, NaN).\n\n### Pixel Resolution (Spatial Resolution)\nGround area represented by one pixel (e.g., 10m means each pixel covers 10m × 10m on the ground).\n\n### Projection\nMathematical transformation converting 3D Earth coordinates to 2D map coordinates (e.g., Mercator, UTM).\n\n### Raster Data\nGrid-based spatial data where each cell (pixel) contains a value, used for continuous phenomena (elevation, temperature, imagery).\n\n### Reproject\nConverting geospatial data from one coordinate reference system to another.\n\n### Shapefile\nPopular vector data format for GIS, consisting of multiple files (.shp, .shx, .dbf, .prj).\n\n### Spatial Join\nCombining attributes from two geospatial datasets based on their spatial relationship (intersection, within, etc.).\n\n### Vector Data\nSpatial data representing discrete features as points, lines, or polygons with associated attributes.\n\n### Well-Known Text (WKT)\nText markup language for representing vector geometry and spatial reference systems.\n\n---\n\n## Satellite & Sensor Terms\n\n### Active Sensor\nSensor that emits its own energy and measures the reflected signal (e.g., SAR, LiDAR).\n\n### Aperture\nOpening in a sensor that controls the amount of light collected, affecting image brightness and quality.\n\n### Atmospheric Correction\nProcessing step removing atmospheric effects (scattering, absorption) to retrieve surface reflectance.\n\n### C-band\nRadar frequency band (4-8 GHz, wavelength 3.75-7.5 cm) used by Sentinel-1, good for vegetation and soil moisture.\n\n### Electromagnetic Spectrum\nRange of all electromagnetic radiation wavelengths, from radio waves to gamma rays, including visible light.\n\n### Geometric Correction\nCorrecting image distortions caused by sensor viewing angle, terrain, and Earth's curvature.\n\n### Level 1C (L1C)\nSentinel-2 product with Top-of-Atmosphere (TOA) reflectance, geometrically corrected.\n\n### Level 2A (L2A)\nSentinel-2 product with Bottom-of-Atmosphere (BOA) surface reflectance, atmospherically corrected.\n\n### LiDAR\nLight Detection and Ranging - active sensor using laser pulses to measure distance, creating high-resolution 3D point clouds.\n\n### Multispectral\nImaging system capturing data in multiple (typically 3-15) wavelength bands across visible and infrared spectrum.\n\n### Near Infrared (NIR)\nElectromagnetic radiation with wavelengths 0.7-1.4 μm, strongly reflected by healthy vegetation.\n\n### Optical Sensor\nPassive sensor detecting reflected sunlight in visible and infrared wavelengths (e.g., Sentinel-2, Landsat).\n\n### Orbit\nPath of a satellite around Earth, characterized by altitude, inclination, and period.\n\n### Panchromatic\nSingle-band imagery capturing all visible wavelengths, typically at higher spatial resolution than multispectral bands.\n\n### Passive Sensor\nSensor detecting naturally available energy, typically reflected sunlight (e.g., optical cameras).\n\n### Polarization\nOrientation of radar waves (HH, VV, HV, VH), providing information about surface structure and moisture.\n\n### Radiometric Calibration\nConverting raw sensor digital numbers to physical units (radiance or reflectance).\n\n### SAR (Synthetic Aperture Radar)\nActive microwave imaging system creating high-resolution images independent of sunlight and clouds.\n\n### Short-Wave Infrared (SWIR)\nElectromagnetic radiation with wavelengths 1.4-3.0 μm, useful for detecting moisture and minerals.\n\n### Spectral Resolution\nAbility to distinguish between different wavelengths, determined by number and width of spectral bands.\n\n### Sun-Synchronous Orbit\nSatellite orbit maintaining constant local solar time, ensuring consistent illumination conditions.\n\n### Swath Width\nWidth of the ground strip imaged by a satellite in a single pass (e.g., Sentinel-2 has 290 km swath).\n\n### Temporal Resolution\nFrequency of repeat observations over the same location (synonymous with revisit time).\n\n### Thermal Infrared (TIR)\nElectromagnetic radiation with wavelengths 8-14 μm, measuring heat emitted by Earth's surface.\n\n---\n\n## Philippine EO Organizations\n\n### CoPhil Programme\nEU-Philippines Copernicus Capacity Support Programme - partnership to strengthen Philippine EO capabilities, establish a Copernicus Mirror Site, and develop AI/ML capacity.\n\n### DENR\nDepartment of Environment and Natural Resources - responsible for forest monitoring, land cover mapping, and natural resource management using EO data.\n\n### DOST\nDepartment of Science and Technology - leads science and technology advancement, co-chairs CoPhil programme, operates PAGASA and ASTI.\n\n### DOST-ASTI\nAdvanced Science and Technology Institute - ICT research and development, AI platforms (SkAI-Pinas, DIMER, AIPI).\n\n### LiPAD\nLiDAR Portal for Archiving and Distribution - repository of high-resolution elevation data for the Philippines.\n\n### NAMRIA\nNational Mapping and Resource Information Authority - official mapping agency, operates GeoPortal and Resource Data Analysis Center.\n\n### NDRRMC\nNational Disaster Risk Reduction and Management Council - coordinates disaster response, uses EO data for assessment and planning.\n\n### PAGASA\nPhilippine Atmospheric, Geophysical and Astronomical Services Administration - weather, climate, and astronomical services.\n\n### PhilGIS\nPhilippine GIS Data Clearinghouse - repository of geospatial datasets for the Philippines.\n\n### PhilSA\nPhilippine Space Agency - national space authority, co-chairs CoPhil programme, operates SIYASAT portal and develops Copernicus Mirror Site.\n\n### SIYASAT Portal\nPhilSA's secure data archive for NovaSAR-1 data and maritime monitoring products.\n\n---\n\n## Technical Acronyms\n\n### AI\nArtificial Intelligence - computer systems performing tasks requiring human intelligence.\n\n### API\nApplication Programming Interface - set of functions allowing software to interact with services (e.g., Earth Engine Python API).\n\n### ASTER\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer - NASA sensor providing multispectral imagery.\n\n### BOA\nBottom of Atmosphere - surface reflectance after atmospheric correction (Level 2A products).\n\n### CCA\nClimate Change Adaptation - strategies and actions to adjust to climate change impacts.\n\n### CNN\nConvolutional Neural Network - deep learning architecture for image analysis.\n\n### CRS\nCoordinate Reference System - defines how coordinates relate to Earth's surface.\n\n### DEM\nDigital Elevation Model - raster representation of terrain elevation.\n\n### DL\nDeep Learning - subset of ML using multi-layer neural networks.\n\n### DRR\nDisaster Risk Reduction - strategies to minimize disaster impacts.\n\n### EO\nEarth Observation - gathering information about Earth through remote sensing.\n\n### ESA\nEuropean Space Agency - operates Copernicus Sentinel missions.\n\n### EVI\nEnhanced Vegetation Index - vegetation index less sensitive to atmospheric effects than NDVI.\n\n### GEE\nGoogle Earth Engine - cloud platform for planetary-scale geospatial analysis.\n\n### GIS\nGeographic Information System - software for capturing, managing, and analyzing spatial data.\n\n### GPU\nGraphics Processing Unit - hardware accelerating deep learning computations.\n\n### GNSS\nGlobal Navigation Satellite System - satellite-based positioning (GPS, Galileo, GLONASS).\n\n### HDF\nHierarchical Data Format - file format for storing large scientific datasets.\n\n### IW\nInterferometric Wide Swath - Sentinel-1 acquisition mode with 250 km swath.\n\n### JAXA\nJapan Aerospace Exploration Agency - operates Japanese Earth observation satellites.\n\n### LiDAR\nLight Detection and Ranging - laser-based remote sensing for elevation mapping.\n\n### LULC\nLand Use Land Cover - classification of Earth's surface into categories (forest, urban, agriculture, etc.).\n\n### ML\nMachine Learning - algorithms enabling systems to learn from data.\n\n### MODIS\nModerate Resolution Imaging Spectroradiometer - NASA sensor providing daily global coverage.\n\n### NASA\nNational Aeronautics and Space Administration - operates Landsat and other EO missions.\n\n### NDBI\nNormalized Difference Built-up Index - spectral index for detecting built-up areas.\n\n### NDVI\nNormalized Difference Vegetation Index - spectral index measuring vegetation health/density.\n\n### NDWI\nNormalized Difference Water Index - spectral index for detecting water bodies.\n\n### NIR\nNear Infrared - electromagnetic radiation beyond visible red (0.7-1.4 μm).\n\n### NRM\nNatural Resource Management - sustainable management of natural resources using EO monitoring.\n\n### RGB\nRed-Green-Blue - color model using three primary colors, or the corresponding image bands.\n\n### RF\nRandom Forest - ensemble machine learning algorithm using multiple decision trees.\n\n### RL\nReinforcement Learning - ML paradigm where agents learn through interaction with environment.\n\n### SAR\nSynthetic Aperture Radar - active microwave imaging system.\n\n### SCL\nScene Classification Layer - Sentinel-2 cloud and land cover classification mask.\n\n### SNAP\nSentinel Application Platform - ESA's free software for processing Sentinel data.\n\n### SWIR\nShort-Wave Infrared - electromagnetic radiation with wavelengths 1.4-3.0 μm.\n\n### SVM\nSupport Vector Machine - classification algorithm finding optimal separating hyperplane.\n\n### TIR\nThermal Infrared - electromagnetic radiation measuring surface temperature (8-14 μm).\n\n### TOA\nTop of Atmosphere - apparent reflectance before atmospheric correction (Level 1C products).\n\n### USGS\nUnited States Geological Survey - distributes Landsat and other EO data.\n\n### UTM\nUniversal Transverse Mercator - widely-used projected coordinate system dividing Earth into zones.\n\n### WGS84\nWorld Geodetic System 1984 - global geographic coordinate system (EPSG:4326).\n\n---\n\n## Spectral Indices\n\n### NDVI (Normalized Difference Vegetation Index)\n**Formula:** (NIR - Red) / (NIR + Red)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- High values (0.6-0.9): Dense vegetation\n- Moderate (0.2-0.5): Sparse vegetation\n- Near zero: Bare soil, rock\n- Negative: Water, clouds\n\n**Sentinel-2 Bands:** (B8 - B4) / (B8 + B4)\n\n---\n\n### NDWI (Normalized Difference Water Index)\n**McFeeters Formula:** (Green - NIR) / (Green + NIR)\n\n**Gao Formula:** (NIR - SWIR) / (NIR + SWIR)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- Positive values: Water bodies\n- Negative: Land surfaces\n\n**Sentinel-2 (McFeeters):** (B3 - B8) / (B3 + B8)\n\n**Sentinel-2 (Gao):** (B8 - B11) / (B8 + B11)\n\n---\n\n### NDBI (Normalized Difference Built-up Index)\n**Formula:** (SWIR - NIR) / (SWIR + NIR)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- Positive values: Built-up areas\n- Negative: Vegetation, water\n\n**Sentinel-2:** (B11 - B8) / (B11 + B8)\n\n---\n\n### EVI (Enhanced Vegetation Index)\n**Formula:** 2.5 × ((NIR - Red) / (NIR + 6×Red - 7.5×Blue + 1))\n\n**Range:** -1 to +1\n\n**Advantages:** Less sensitive to atmospheric effects and soil background than NDVI\n\n**Sentinel-2:** 2.5 × ((B8 - B4) / (B8 + 6×B4 - 7.5×B2 + 1))\n\n---\n\n## Quick Reference Tables\n\n### Sentinel-2 Band Summary\n\n| Band | Name | Wavelength (nm) | Resolution (m) | Typical Use |\n|------|------|-----------------|----------------|-------------|\n| B1 | Coastal aerosol | 443 | 60 | Atmospheric correction |\n| B2 | Blue | 490 | 10 | Bathymetry, soil/vegetation |\n| B3 | Green | 560 | 10 | Peak vegetation sensitivity |\n| B4 | Red | 665 | 10 | Vegetation discrimination |\n| B5 | Red Edge 1 | 705 | 20 | Vegetation health |\n| B6 | Red Edge 2 | 740 | 20 | Vegetation stress |\n| B7 | Red Edge 3 | 783 | 20 | Vegetation stress |\n| B8 | NIR | 842 | 10 | Biomass, water bodies |\n| B8A | Narrow NIR | 865 | 20 | Atmospheric correction |\n| B9 | Water vapor | 945 | 60 | Atmospheric correction |\n| B11 | SWIR 1 | 1610 | 20 | Moisture, soil/vegetation |\n| B12 | SWIR 2 | 2190 | 20 | Moisture, burned areas |\n\n---\n\n### Common CRS for Philippines\n\n| Name | EPSG Code | Type | Use Case |\n|------|-----------|------|----------|\n| WGS84 | 4326 | Geographic | Global datasets, web maps |\n| UTM Zone 50N | 32650 | Projected | Western Mindanao |\n| UTM Zone 51N | 32651 | Projected | Luzon, Visayas, most of Philippines |\n| UTM Zone 52N | 32652 | Projected | Eastern Mindanao |\n| PRS92 | 4683 | Geographic | Philippine Reference System |\n\n---\n\n## Related Resources\n\nFor more detailed information:\n\n- [Setup Guide](setup.qmd) - Technical setup instructions\n- [Cheat Sheets](cheatsheets.qmd) - Quick reference commands\n- [FAQ](faq.qmd) - Common questions and troubleshooting\n- [Philippine EO Resources](philippine-eo.qmd) - Organizations and platforms\n\n---\n\n*This glossary will be expanded in subsequent training days. Suggest additional terms via training@philsa.gov.ph*\n","srcMarkdownNoYaml":"\n\n## How to Use This Glossary\n\nThis glossary defines key terms used throughout the CoPhil EO AI/ML Training Programme. Terms are organized alphabetically within categories for easy reference.\n\n**Categories:**\n- [Earth Observation Terms](#earth-observation-terms)\n- [AI/ML Terms](#aiml-terms)\n- [Geospatial Data Terms](#geospatial-data-terms)\n- [Satellite & Sensor Terms](#satellite-sensor-terms)\n- [Philippine EO Organizations](#philippine-eo-organizations)\n- [Technical Acronyms](#technical-acronyms)\n\n---\n\n## Earth Observation Terms\n\n### Absorption Band\nWavelength region where atmospheric gases (water vapor, oxygen, CO2) absorb electromagnetic radiation, limiting remote sensing capabilities.\n\n### Backscatter\nThe portion of radar energy reflected back to the sensor from a target. Used in SAR imaging to detect surface properties and moisture.\n\n### Cloud Masking\nThe process of identifying and removing cloud-contaminated pixels from optical satellite imagery to improve data quality.\n\n### Composite Image\nA single image created by combining multiple images from different dates, often using statistical methods (median, mean) to reduce noise and clouds.\n\n### Earth Observation (EO)\nThe gathering of information about Earth's physical, chemical, and biological systems through remote sensing technologies, primarily satellites.\n\n### False Color Composite\nAn image display where spectral bands are assigned to RGB colors differently than natural vision (e.g., NIR-Red-Green), revealing features invisible to the human eye.\n\n### Ground Truth\nField-collected reference data used to validate remote sensing classifications and train machine learning models.\n\n### Image Collection\nA set of satellite images covering the same geographic area at different times, used for time series analysis.\n\n### Pixel\nThe smallest unit in a raster image, representing a specific ground area (spatial resolution) and spectral value.\n\n### Preprocessing\nSteps taken to correct raw satellite data before analysis, including atmospheric correction, geometric correction, and radiometric calibration.\n\n### Remote Sensing\nThe science of obtaining information about objects or areas from a distance, typically using sensors on satellites or aircraft.\n\n### Revisit Time\nThe frequency with which a satellite can observe the same location on Earth (e.g., Sentinel-2 has 5-day revisit with 3 satellites).\n\n### Spectral Signature\nThe unique reflectance pattern of an object across different wavelengths, used to identify materials and land cover types.\n\n### True Color Composite\nAn image display using red, green, and blue bands to create a natural-looking image similar to human vision.\n\n---\n\n## AI/ML Terms\n\n### Activation Function\nMathematical function in neural networks that introduces non-linearity (e.g., ReLU, Sigmoid, Tanh), enabling learning of complex patterns.\n\n### Artificial Intelligence (AI)\nComputer systems capable of performing tasks that typically require human intelligence, including perception, reasoning, and decision-making.\n\n### Backpropagation\nAlgorithm for training neural networks by calculating gradients of loss and adjusting weights to minimize error.\n\n### Batch Size\nNumber of training samples processed before updating model weights. Smaller batches = more updates but noisier; larger batches = smoother but fewer updates.\n\n### Classification\nSupervised learning task of assigning input data to predefined categories (e.g., forest, water, urban).\n\n### Clustering\nUnsupervised learning technique that groups similar data points together without predefined labels (e.g., K-means, DBSCAN).\n\n### Confusion Matrix\nTable showing predicted vs. actual classifications, used to calculate accuracy, precision, recall, and F1-score.\n\n### Convolutional Neural Network (CNN)\nDeep learning architecture specialized for image analysis, using convolutional layers to detect spatial patterns.\n\n### Data Augmentation\nTechnique to artificially increase training data by applying transformations (rotation, flipping, scaling) to existing samples.\n\n### Deep Learning\nSubset of machine learning using multi-layer neural networks to learn hierarchical representations of data.\n\n### Epoch\nOne complete pass through the entire training dataset during model training.\n\n### Feature Engineering\nThe process of creating new input variables from raw data to improve model performance.\n\n### Feature Extraction\nIdentifying and extracting relevant patterns or characteristics from raw data for use in machine learning models.\n\n### Ground Truth Labels\nVerified, accurate labels for training data, typically from field surveys or expert interpretation.\n\n### Hyperparameter\nModel configuration setting chosen before training (e.g., learning rate, number of layers) that affects model performance.\n\n### Loss Function\nMathematical function measuring the difference between predicted and actual values, used to guide model training.\n\n### Machine Learning (ML)\nSubset of AI enabling systems to learn and improve from experience without explicit programming.\n\n### Neural Network\nComputing system inspired by biological brains, consisting of interconnected nodes (neurons) organized in layers.\n\n### Overfitting\nWhen a model learns training data too well, including noise, resulting in poor performance on new data.\n\n### Precision\nProportion of positive predictions that are actually correct. Precision = TP / (TP + FP).\n\n### Random Forest\nEnsemble learning method using multiple decision trees to improve prediction accuracy and reduce overfitting.\n\n### Recall (Sensitivity)\nProportion of actual positives correctly identified. Recall = TP / (TP + FN).\n\n### Regression\nSupervised learning task of predicting continuous numerical values (e.g., crop yield, temperature).\n\n### Supervised Learning\nMachine learning where models learn from labeled training data (input-output pairs).\n\n### Support Vector Machine (SVM)\nClassification algorithm that finds the optimal hyperplane separating different classes in feature space.\n\n### Training Set\nPortion of data used to train a machine learning model (typically 70-80% of total data).\n\n### Transfer Learning\nReusing a pre-trained model on a new but related task, reducing training time and data requirements.\n\n### Underfitting\nWhen a model is too simple to capture the underlying patterns in data, resulting in poor performance.\n\n### Unsupervised Learning\nMachine learning where models find patterns in unlabeled data without predefined categories.\n\n### Validation Set\nData used to evaluate model performance during training and tune hyperparameters (typically 10-15% of data).\n\n---\n\n## Geospatial Data Terms\n\n### Affine Transformation\nMathematical operation describing the relationship between pixel coordinates and geographic coordinates in raster data.\n\n### Bounding Box\nRectangular area defined by minimum and maximum coordinates [minX, minY, maxX, maxY], used to specify geographic extents.\n\n### Coordinate Reference System (CRS)\nSystem defining how coordinates relate to real-world locations, including datum and projection (e.g., WGS84, UTM).\n\n### Digital Elevation Model (DEM)\nRaster representation of terrain elevation, with each pixel value representing height above a reference level.\n\n### Feature\nIn geospatial terms, a vector object (point, line, or polygon) with associated attributes.\n\n### GeoJSON\nOpen standard JSON format for encoding geographic data structures, widely used for web mapping.\n\n### GeoPackage\nOpen format for geospatial data storage in SQLite database, supporting both vector and raster data.\n\n### Geometry\nThe spatial component of a geographic feature, defining its shape and location (point, line, polygon).\n\n### GeoTIFF\nRaster image format with embedded geographic metadata (CRS, extent, resolution), standard for geospatial raster data.\n\n### NoData Value\nSpecial value in raster data indicating missing or invalid data (e.g., -9999, NaN).\n\n### Pixel Resolution (Spatial Resolution)\nGround area represented by one pixel (e.g., 10m means each pixel covers 10m × 10m on the ground).\n\n### Projection\nMathematical transformation converting 3D Earth coordinates to 2D map coordinates (e.g., Mercator, UTM).\n\n### Raster Data\nGrid-based spatial data where each cell (pixel) contains a value, used for continuous phenomena (elevation, temperature, imagery).\n\n### Reproject\nConverting geospatial data from one coordinate reference system to another.\n\n### Shapefile\nPopular vector data format for GIS, consisting of multiple files (.shp, .shx, .dbf, .prj).\n\n### Spatial Join\nCombining attributes from two geospatial datasets based on their spatial relationship (intersection, within, etc.).\n\n### Vector Data\nSpatial data representing discrete features as points, lines, or polygons with associated attributes.\n\n### Well-Known Text (WKT)\nText markup language for representing vector geometry and spatial reference systems.\n\n---\n\n## Satellite & Sensor Terms\n\n### Active Sensor\nSensor that emits its own energy and measures the reflected signal (e.g., SAR, LiDAR).\n\n### Aperture\nOpening in a sensor that controls the amount of light collected, affecting image brightness and quality.\n\n### Atmospheric Correction\nProcessing step removing atmospheric effects (scattering, absorption) to retrieve surface reflectance.\n\n### C-band\nRadar frequency band (4-8 GHz, wavelength 3.75-7.5 cm) used by Sentinel-1, good for vegetation and soil moisture.\n\n### Electromagnetic Spectrum\nRange of all electromagnetic radiation wavelengths, from radio waves to gamma rays, including visible light.\n\n### Geometric Correction\nCorrecting image distortions caused by sensor viewing angle, terrain, and Earth's curvature.\n\n### Level 1C (L1C)\nSentinel-2 product with Top-of-Atmosphere (TOA) reflectance, geometrically corrected.\n\n### Level 2A (L2A)\nSentinel-2 product with Bottom-of-Atmosphere (BOA) surface reflectance, atmospherically corrected.\n\n### LiDAR\nLight Detection and Ranging - active sensor using laser pulses to measure distance, creating high-resolution 3D point clouds.\n\n### Multispectral\nImaging system capturing data in multiple (typically 3-15) wavelength bands across visible and infrared spectrum.\n\n### Near Infrared (NIR)\nElectromagnetic radiation with wavelengths 0.7-1.4 μm, strongly reflected by healthy vegetation.\n\n### Optical Sensor\nPassive sensor detecting reflected sunlight in visible and infrared wavelengths (e.g., Sentinel-2, Landsat).\n\n### Orbit\nPath of a satellite around Earth, characterized by altitude, inclination, and period.\n\n### Panchromatic\nSingle-band imagery capturing all visible wavelengths, typically at higher spatial resolution than multispectral bands.\n\n### Passive Sensor\nSensor detecting naturally available energy, typically reflected sunlight (e.g., optical cameras).\n\n### Polarization\nOrientation of radar waves (HH, VV, HV, VH), providing information about surface structure and moisture.\n\n### Radiometric Calibration\nConverting raw sensor digital numbers to physical units (radiance or reflectance).\n\n### SAR (Synthetic Aperture Radar)\nActive microwave imaging system creating high-resolution images independent of sunlight and clouds.\n\n### Short-Wave Infrared (SWIR)\nElectromagnetic radiation with wavelengths 1.4-3.0 μm, useful for detecting moisture and minerals.\n\n### Spectral Resolution\nAbility to distinguish between different wavelengths, determined by number and width of spectral bands.\n\n### Sun-Synchronous Orbit\nSatellite orbit maintaining constant local solar time, ensuring consistent illumination conditions.\n\n### Swath Width\nWidth of the ground strip imaged by a satellite in a single pass (e.g., Sentinel-2 has 290 km swath).\n\n### Temporal Resolution\nFrequency of repeat observations over the same location (synonymous with revisit time).\n\n### Thermal Infrared (TIR)\nElectromagnetic radiation with wavelengths 8-14 μm, measuring heat emitted by Earth's surface.\n\n---\n\n## Philippine EO Organizations\n\n### CoPhil Programme\nEU-Philippines Copernicus Capacity Support Programme - partnership to strengthen Philippine EO capabilities, establish a Copernicus Mirror Site, and develop AI/ML capacity.\n\n### DENR\nDepartment of Environment and Natural Resources - responsible for forest monitoring, land cover mapping, and natural resource management using EO data.\n\n### DOST\nDepartment of Science and Technology - leads science and technology advancement, co-chairs CoPhil programme, operates PAGASA and ASTI.\n\n### DOST-ASTI\nAdvanced Science and Technology Institute - ICT research and development, AI platforms (SkAI-Pinas, DIMER, AIPI).\n\n### LiPAD\nLiDAR Portal for Archiving and Distribution - repository of high-resolution elevation data for the Philippines.\n\n### NAMRIA\nNational Mapping and Resource Information Authority - official mapping agency, operates GeoPortal and Resource Data Analysis Center.\n\n### NDRRMC\nNational Disaster Risk Reduction and Management Council - coordinates disaster response, uses EO data for assessment and planning.\n\n### PAGASA\nPhilippine Atmospheric, Geophysical and Astronomical Services Administration - weather, climate, and astronomical services.\n\n### PhilGIS\nPhilippine GIS Data Clearinghouse - repository of geospatial datasets for the Philippines.\n\n### PhilSA\nPhilippine Space Agency - national space authority, co-chairs CoPhil programme, operates SIYASAT portal and develops Copernicus Mirror Site.\n\n### SIYASAT Portal\nPhilSA's secure data archive for NovaSAR-1 data and maritime monitoring products.\n\n---\n\n## Technical Acronyms\n\n### AI\nArtificial Intelligence - computer systems performing tasks requiring human intelligence.\n\n### API\nApplication Programming Interface - set of functions allowing software to interact with services (e.g., Earth Engine Python API).\n\n### ASTER\nAdvanced Spaceborne Thermal Emission and Reflection Radiometer - NASA sensor providing multispectral imagery.\n\n### BOA\nBottom of Atmosphere - surface reflectance after atmospheric correction (Level 2A products).\n\n### CCA\nClimate Change Adaptation - strategies and actions to adjust to climate change impacts.\n\n### CNN\nConvolutional Neural Network - deep learning architecture for image analysis.\n\n### CRS\nCoordinate Reference System - defines how coordinates relate to Earth's surface.\n\n### DEM\nDigital Elevation Model - raster representation of terrain elevation.\n\n### DL\nDeep Learning - subset of ML using multi-layer neural networks.\n\n### DRR\nDisaster Risk Reduction - strategies to minimize disaster impacts.\n\n### EO\nEarth Observation - gathering information about Earth through remote sensing.\n\n### ESA\nEuropean Space Agency - operates Copernicus Sentinel missions.\n\n### EVI\nEnhanced Vegetation Index - vegetation index less sensitive to atmospheric effects than NDVI.\n\n### GEE\nGoogle Earth Engine - cloud platform for planetary-scale geospatial analysis.\n\n### GIS\nGeographic Information System - software for capturing, managing, and analyzing spatial data.\n\n### GPU\nGraphics Processing Unit - hardware accelerating deep learning computations.\n\n### GNSS\nGlobal Navigation Satellite System - satellite-based positioning (GPS, Galileo, GLONASS).\n\n### HDF\nHierarchical Data Format - file format for storing large scientific datasets.\n\n### IW\nInterferometric Wide Swath - Sentinel-1 acquisition mode with 250 km swath.\n\n### JAXA\nJapan Aerospace Exploration Agency - operates Japanese Earth observation satellites.\n\n### LiDAR\nLight Detection and Ranging - laser-based remote sensing for elevation mapping.\n\n### LULC\nLand Use Land Cover - classification of Earth's surface into categories (forest, urban, agriculture, etc.).\n\n### ML\nMachine Learning - algorithms enabling systems to learn from data.\n\n### MODIS\nModerate Resolution Imaging Spectroradiometer - NASA sensor providing daily global coverage.\n\n### NASA\nNational Aeronautics and Space Administration - operates Landsat and other EO missions.\n\n### NDBI\nNormalized Difference Built-up Index - spectral index for detecting built-up areas.\n\n### NDVI\nNormalized Difference Vegetation Index - spectral index measuring vegetation health/density.\n\n### NDWI\nNormalized Difference Water Index - spectral index for detecting water bodies.\n\n### NIR\nNear Infrared - electromagnetic radiation beyond visible red (0.7-1.4 μm).\n\n### NRM\nNatural Resource Management - sustainable management of natural resources using EO monitoring.\n\n### RGB\nRed-Green-Blue - color model using three primary colors, or the corresponding image bands.\n\n### RF\nRandom Forest - ensemble machine learning algorithm using multiple decision trees.\n\n### RL\nReinforcement Learning - ML paradigm where agents learn through interaction with environment.\n\n### SAR\nSynthetic Aperture Radar - active microwave imaging system.\n\n### SCL\nScene Classification Layer - Sentinel-2 cloud and land cover classification mask.\n\n### SNAP\nSentinel Application Platform - ESA's free software for processing Sentinel data.\n\n### SWIR\nShort-Wave Infrared - electromagnetic radiation with wavelengths 1.4-3.0 μm.\n\n### SVM\nSupport Vector Machine - classification algorithm finding optimal separating hyperplane.\n\n### TIR\nThermal Infrared - electromagnetic radiation measuring surface temperature (8-14 μm).\n\n### TOA\nTop of Atmosphere - apparent reflectance before atmospheric correction (Level 1C products).\n\n### USGS\nUnited States Geological Survey - distributes Landsat and other EO data.\n\n### UTM\nUniversal Transverse Mercator - widely-used projected coordinate system dividing Earth into zones.\n\n### WGS84\nWorld Geodetic System 1984 - global geographic coordinate system (EPSG:4326).\n\n---\n\n## Spectral Indices\n\n### NDVI (Normalized Difference Vegetation Index)\n**Formula:** (NIR - Red) / (NIR + Red)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- High values (0.6-0.9): Dense vegetation\n- Moderate (0.2-0.5): Sparse vegetation\n- Near zero: Bare soil, rock\n- Negative: Water, clouds\n\n**Sentinel-2 Bands:** (B8 - B4) / (B8 + B4)\n\n---\n\n### NDWI (Normalized Difference Water Index)\n**McFeeters Formula:** (Green - NIR) / (Green + NIR)\n\n**Gao Formula:** (NIR - SWIR) / (NIR + SWIR)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- Positive values: Water bodies\n- Negative: Land surfaces\n\n**Sentinel-2 (McFeeters):** (B3 - B8) / (B3 + B8)\n\n**Sentinel-2 (Gao):** (B8 - B11) / (B8 + B11)\n\n---\n\n### NDBI (Normalized Difference Built-up Index)\n**Formula:** (SWIR - NIR) / (SWIR + NIR)\n\n**Range:** -1 to +1\n\n**Interpretation:**\n- Positive values: Built-up areas\n- Negative: Vegetation, water\n\n**Sentinel-2:** (B11 - B8) / (B11 + B8)\n\n---\n\n### EVI (Enhanced Vegetation Index)\n**Formula:** 2.5 × ((NIR - Red) / (NIR + 6×Red - 7.5×Blue + 1))\n\n**Range:** -1 to +1\n\n**Advantages:** Less sensitive to atmospheric effects and soil background than NDVI\n\n**Sentinel-2:** 2.5 × ((B8 - B4) / (B8 + 6×B4 - 7.5×B2 + 1))\n\n---\n\n## Quick Reference Tables\n\n### Sentinel-2 Band Summary\n\n| Band | Name | Wavelength (nm) | Resolution (m) | Typical Use |\n|------|------|-----------------|----------------|-------------|\n| B1 | Coastal aerosol | 443 | 60 | Atmospheric correction |\n| B2 | Blue | 490 | 10 | Bathymetry, soil/vegetation |\n| B3 | Green | 560 | 10 | Peak vegetation sensitivity |\n| B4 | Red | 665 | 10 | Vegetation discrimination |\n| B5 | Red Edge 1 | 705 | 20 | Vegetation health |\n| B6 | Red Edge 2 | 740 | 20 | Vegetation stress |\n| B7 | Red Edge 3 | 783 | 20 | Vegetation stress |\n| B8 | NIR | 842 | 10 | Biomass, water bodies |\n| B8A | Narrow NIR | 865 | 20 | Atmospheric correction |\n| B9 | Water vapor | 945 | 60 | Atmospheric correction |\n| B11 | SWIR 1 | 1610 | 20 | Moisture, soil/vegetation |\n| B12 | SWIR 2 | 2190 | 20 | Moisture, burned areas |\n\n---\n\n### Common CRS for Philippines\n\n| Name | EPSG Code | Type | Use Case |\n|------|-----------|------|----------|\n| WGS84 | 4326 | Geographic | Global datasets, web maps |\n| UTM Zone 50N | 32650 | Projected | Western Mindanao |\n| UTM Zone 51N | 32651 | Projected | Luzon, Visayas, most of Philippines |\n| UTM Zone 52N | 32652 | Projected | Eastern Mindanao |\n| PRS92 | 4683 | Geographic | Philippine Reference System |\n\n---\n\n## Related Resources\n\nFor more detailed information:\n\n- [Setup Guide](setup.qmd) - Technical setup instructions\n- [Cheat Sheets](cheatsheets.qmd) - Quick reference commands\n- [FAQ](faq.qmd) - Common questions and troubleshooting\n- [Philippine EO Resources](philippine-eo.qmd) - Organizations and platforms\n\n---\n\n*This glossary will be expanded in subsequent training days. Suggest additional terms via training@philsa.gov.ph*\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":true,"freeze":"auto","echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"wrap","code-link":true,"code-line-numbers":false,"code-tools":true,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":true,"link-external-newwindow":true,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","filters":["include-code-files"],"css":["../styles/custom.css","../styles/phase2-enhancements.css"],"toc":true,"toc-depth":3,"number-sections":false,"output-file":"glossary.html"},"language":{"toc-title-document":"Contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Instructor","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Date","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.8.25","comments":{"hypothesis":false,"utterances":{"repo":"copphil-training/course-site"}},"theme":{"light":["cosmo","../styles/custom.scss"],"dark":["darkly","../styles/custom.scss"]},"toc-expand":2,"toc-title":"On This Page","code-copy":true,"smooth-scroll":true,"anchor-sections":true,"fig-cap-location":"bottom","tbl-cap-location":"top","citations-hover":true,"footnotes-hover":true,"title":"Glossary","subtitle":"Earth Observation & AI/ML Terms","date":"last-modified"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}